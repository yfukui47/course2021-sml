{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4dOTzVWYB8wM"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yfukui47/course2021-sml/blob/main/%E8%A1%A8%E6%83%85%E6%8E%A8%E5%AE%9A%E7%B2%BE%E5%BA%A6%E7%A2%BA%E8%AA%8D(2_%E5%96%9C%E3%81%A8%E3%81%9D%E3%82%8C%E4%BB%A5%E5%A4%96).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch7QhC-aB8wI"
      },
      "source": [
        "# 音声による表情推定分類器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovFKq7VJB8wJ",
        "outputId": "d52e1a89-ee43-4494-cd0d-f52d0ac458a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 必要ライブラリの導入\n",
        "\n",
        "!pip install japanize_matplotlib | tail -n 1\n",
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed japanize-matplotlib-1.1.3\n",
            "Successfully installed torchviz-0.0.2\n",
            "Successfully installed torchinfo-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuXbWMV0B8wK"
      },
      "source": [
        "# 必要ライブラリのインポート\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "from IPython.display import display"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HGKvQdjB8wK"
      },
      "source": [
        "# torch関連ライブラリのインポート\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from torchviz import make_dot"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xktdy7SfB8wK"
      },
      "source": [
        "# デフォルトフォントサイズ変更\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# デフォルトグラフサイズ変更\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "# デフォルトで方眼表示ON\n",
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "# numpyの表示桁数設定\n",
        "np.set_printoptions(suppress=True, precision=4)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmcpTYteB8wL"
      },
      "source": [
        "## プロトタイプ出力CSVファイルの加工"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXtUTacMB8wM"
      },
      "source": [
        "### データ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf9prBqZmi-H",
        "outputId": "e8f43319-c594-456f-acce-052283a4e7bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "rzmaiElWmn2W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "再実行の場合はここから"
      ],
      "metadata": {
        "id": "GPxg8657LszK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ファイル読み込み\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/表情/ CSV/output_5f_3s.csv\")   ## 精度: 0.50794 / ２分類\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/表情/ CSV/output_5f_5s.csv\")   ## 精度: 0.68254 / ２分類\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/表情/ CSV/output_5f_7s.csv\")   ## 精度: 0.70588 / 1分類 NG\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/表情/ CSV/output_5f_10s.csv\")  ## 精度: 0.55556 / ２分類\n",
        "\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/表情/ CSV/output_10f_3s.csv\")  ## 精度: 0.61905 / ２分類\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/表情/ CSV/output_10f_5s.csv\")  ## 精度: 0.47619 / 1分類 NG\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/表情/ CSV/output_10f_7s.csv\")  ## 精度: 0.70588 / ２分類\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/表情/ CSV/output_10f_10s.csv\") ## 精度: 0.75000 / ２分類\n",
        "\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/表情/ CSV/output_20f_3s.csv\")  ## 精度: 0.60317 / ２分類\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/表情/ CSV/output_20f_5s.csv\")  ## 精度: 0.49206 / ２分類\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/表情/ CSV/output_20f_7s.csv\")  ## 精度: 0.72549 / 1分類 NG\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/表情/ CSV/output_20f_10s.csv\") ## 精度: 0.77778 / ２分類  ★\n",
        "\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "10MaJS_CCk1I",
        "outputId": "eda3efad-a0a5-4672-9a5f-79cb7e4d19b8"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      filename  fps       timestamp  smile_flg  smile_confidence  \\\n",
              "0  FFQFAKXyRCU   10         0:00:00      False         94.755348   \n",
              "1  FFQFAKXyRCU   10  0:00:00.100000      False         94.717186   \n",
              "2  FFQFAKXyRCU   10  0:00:00.200000      False         94.736214   \n",
              "\n",
              "   primalExpression       calm       sad  confused      fear  ...  \\\n",
              "0                 1  88.602562  2.179124  9.866685  5.925173  ...   \n",
              "1                 1  89.892105  2.185883  8.393709  5.948472  ...   \n",
              "2                 1  89.737099  2.179730  8.402431  5.941079  ...   \n",
              "\n",
              "   original_duration  balance  f0_mean  f0_std f0_median  f0_min f0_max  \\\n",
              "0               10.0      0.8   150.06    78.8     121.3    79.0  406.0   \n",
              "1               10.0      0.8   150.06    78.8     121.3    79.0  406.0   \n",
              "2               10.0      0.8   150.06    78.8     121.3    79.0  406.0   \n",
              "\n",
              "   f0_quantile25  f0_quan75  result_flg  \n",
              "0           95.0      172.0        True  \n",
              "1           95.0      172.0        True  \n",
              "2           95.0      172.0        True  \n",
              "\n",
              "[3 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae1d7681-0c33-448b-9e68-90f75b6f3955\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>fps</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>smile_flg</th>\n",
              "      <th>smile_confidence</th>\n",
              "      <th>primalExpression</th>\n",
              "      <th>calm</th>\n",
              "      <th>sad</th>\n",
              "      <th>confused</th>\n",
              "      <th>fear</th>\n",
              "      <th>...</th>\n",
              "      <th>original_duration</th>\n",
              "      <th>balance</th>\n",
              "      <th>f0_mean</th>\n",
              "      <th>f0_std</th>\n",
              "      <th>f0_median</th>\n",
              "      <th>f0_min</th>\n",
              "      <th>f0_max</th>\n",
              "      <th>f0_quantile25</th>\n",
              "      <th>f0_quan75</th>\n",
              "      <th>result_flg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FFQFAKXyRCU</td>\n",
              "      <td>10</td>\n",
              "      <td>0:00:00</td>\n",
              "      <td>False</td>\n",
              "      <td>94.755348</td>\n",
              "      <td>1</td>\n",
              "      <td>88.602562</td>\n",
              "      <td>2.179124</td>\n",
              "      <td>9.866685</td>\n",
              "      <td>5.925173</td>\n",
              "      <td>...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>150.06</td>\n",
              "      <td>78.8</td>\n",
              "      <td>121.3</td>\n",
              "      <td>79.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FFQFAKXyRCU</td>\n",
              "      <td>10</td>\n",
              "      <td>0:00:00.100000</td>\n",
              "      <td>False</td>\n",
              "      <td>94.717186</td>\n",
              "      <td>1</td>\n",
              "      <td>89.892105</td>\n",
              "      <td>2.185883</td>\n",
              "      <td>8.393709</td>\n",
              "      <td>5.948472</td>\n",
              "      <td>...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>150.06</td>\n",
              "      <td>78.8</td>\n",
              "      <td>121.3</td>\n",
              "      <td>79.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FFQFAKXyRCU</td>\n",
              "      <td>10</td>\n",
              "      <td>0:00:00.200000</td>\n",
              "      <td>False</td>\n",
              "      <td>94.736214</td>\n",
              "      <td>1</td>\n",
              "      <td>89.737099</td>\n",
              "      <td>2.179730</td>\n",
              "      <td>8.402431</td>\n",
              "      <td>5.941079</td>\n",
              "      <td>...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>150.06</td>\n",
              "      <td>78.8</td>\n",
              "      <td>121.3</td>\n",
              "      <td>79.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 41 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae1d7681-0c33-448b-9e68-90f75b6f3955')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae1d7681-0c33-448b-9e68-90f75b6f3955 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae1d7681-0c33-448b-9e68-90f75b6f3955');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#行列数の確認\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7CmSMlXo9ea",
        "outputId": "aad1d49a-4bdc-4c7e-ae2f-3c62461051bb"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9030, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7HaHFLepTyj",
        "outputId": "d0573f7a-73b6-4f6a-c4b7-81af41ed16e4"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filename               False\n",
            "fps                    False\n",
            "timestamp              False\n",
            "smile_flg              False\n",
            "smile_confidence       False\n",
            "primalExpression       False\n",
            "calm                   False\n",
            "sad                    False\n",
            "confused               False\n",
            "fear                   False\n",
            "angry                  False\n",
            "disgusted              False\n",
            "surprised              False\n",
            "happy                  False\n",
            "AgeRange               False\n",
            "Eyeglasses             False\n",
            "Gender                 False\n",
            "Mustache               False\n",
            "Sunglasses             False\n",
            "row_no                 False\n",
            "talk_length            False\n",
            "positive               False\n",
            "negative               False\n",
            "neutral                False\n",
            "mixed                  False\n",
            "non_negative           False\n",
            "number_of_syllables     True\n",
            "number_of_pauses        True\n",
            "rate_of_speech          True\n",
            "articulation_rate       True\n",
            "speaking_duration       True\n",
            "original_duration       True\n",
            "balance                 True\n",
            "f0_mean                 True\n",
            "f0_std                  True\n",
            "f0_median               True\n",
            "f0_min                  True\n",
            "f0_max                  True\n",
            "f0_quantile25           True\n",
            "f0_quan75               True\n",
            "result_flg             False\n",
            "dtype: bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvqNijfCnmg5",
        "outputId": "9d6c2e98-860f-4b46-a149-f366feaba06e"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filename                0\n",
            "fps                     0\n",
            "timestamp               0\n",
            "smile_flg               0\n",
            "smile_confidence        0\n",
            "primalExpression        0\n",
            "calm                    0\n",
            "sad                     0\n",
            "confused                0\n",
            "fear                    0\n",
            "angry                   0\n",
            "disgusted               0\n",
            "surprised               0\n",
            "happy                   0\n",
            "AgeRange                0\n",
            "Eyeglasses              0\n",
            "Gender                  0\n",
            "Mustache                0\n",
            "Sunglasses              0\n",
            "row_no                  0\n",
            "talk_length             0\n",
            "positive                0\n",
            "negative                0\n",
            "neutral                 0\n",
            "mixed                   0\n",
            "non_negative            0\n",
            "number_of_syllables    70\n",
            "number_of_pauses       70\n",
            "rate_of_speech         70\n",
            "articulation_rate      70\n",
            "speaking_duration      70\n",
            "original_duration      70\n",
            "balance                70\n",
            "f0_mean                70\n",
            "f0_std                 70\n",
            "f0_median              70\n",
            "f0_min                 70\n",
            "f0_max                 70\n",
            "f0_quantile25          70\n",
            "f0_quan75              70\n",
            "result_flg              0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC5eeKLFKfcR",
        "outputId": "bd581f82-4b58-4241-f792-80c092d9028f"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "filename                object\n",
              "fps                      int64\n",
              "timestamp               object\n",
              "smile_flg                 bool\n",
              "smile_confidence       float64\n",
              "primalExpression         int64\n",
              "calm                   float64\n",
              "sad                    float64\n",
              "confused               float64\n",
              "fear                   float64\n",
              "angry                  float64\n",
              "disgusted              float64\n",
              "surprised              float64\n",
              "happy                  float64\n",
              "AgeRange                object\n",
              "Eyeglasses                bool\n",
              "Gender                  object\n",
              "Mustache                  bool\n",
              "Sunglasses                bool\n",
              "row_no                   int64\n",
              "talk_length              int64\n",
              "positive               float64\n",
              "negative               float64\n",
              "neutral                float64\n",
              "mixed                  float64\n",
              "non_negative           float64\n",
              "number_of_syllables    float64\n",
              "number_of_pauses       float64\n",
              "rate_of_speech         float64\n",
              "articulation_rate      float64\n",
              "speaking_duration      float64\n",
              "original_duration      float64\n",
              "balance                float64\n",
              "f0_mean                float64\n",
              "f0_std                 float64\n",
              "f0_median              float64\n",
              "f0_min                 float64\n",
              "f0_max                 float64\n",
              "f0_quantile25          float64\n",
              "f0_quan75              float64\n",
              "result_flg                bool\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "v9MrKUKuouhR"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3-CQj2IwFvd",
        "outputId": "19b38495-bb2b-4874-9a32-d7e960277d00"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['filename', 'fps', 'timestamp', 'smile_flg', 'smile_confidence',\n",
              "       'primalExpression', 'calm', 'sad', 'confused', 'fear', 'angry',\n",
              "       'disgusted', 'surprised', 'happy', 'AgeRange', 'Eyeglasses', 'Gender',\n",
              "       'Mustache', 'Sunglasses', 'row_no', 'talk_length', 'positive',\n",
              "       'negative', 'neutral', 'mixed', 'non_negative', 'number_of_syllables',\n",
              "       'number_of_pauses', 'rate_of_speech', 'articulation_rate',\n",
              "       'speaking_duration', 'original_duration', 'balance', 'f0_mean',\n",
              "       'f0_std', 'f0_median', 'f0_min', 'f0_max', 'f0_quantile25', 'f0_quan75',\n",
              "       'result_flg'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('calm : ' + str(df['calm'].sum()))\n",
        "print('sad  : ' + str(df['sad'].sum()))\n",
        "print('confused : ' + str(df['confused'].sum()))\n",
        "print('fear :' + str(df['fear'].sum()))\n",
        "print('angry  :' + str(df['angry'].sum()))\n",
        "print('disgusted : ' + str(df['disgusted'].sum()))\n",
        "print('surprised :' + str(df['surprised'].sum()))\n",
        "print('happy  :' + str(df['happy'].sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7ZCPV0Y1VvC",
        "outputId": "d7b3a28c-5713-4fd5-e0f7-ecd00176243b"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calm : 417716.16335795075\n",
            "sad  : 24702.631155252457\n",
            "confused : 338783.5075135082\n",
            "fear :60522.23049736023\n",
            "angry  :15188.361362971365\n",
            "disgusted : 35311.621327742934\n",
            "surprised :90429.29935598373\n",
            "happy  :13835.355259204283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#表情別AI推定量合計\n",
        "name = ['calm', 'sad', 'confused', 'fear', 'angry','disgusted', 'surprised', 'happy']\n",
        "score = [df['calm'].sum()/1000\n",
        "          ,df['sad'].sum()/1000\n",
        "          ,df['confused'].sum()/1000\n",
        "          ,df['fear'].sum()/1000\n",
        "          ,df['angry'].sum()/1000\n",
        "          ,df['disgusted'].sum()/1000\n",
        "          ,df['surprised'].sum()/1000\n",
        "          ,df['happy'].sum()/1000]\n",
        "df_count = pd.DataFrame(score,index=name) \n"
      ],
      "metadata": {
        "id": "k14NltiM5Nqt"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_count.plot.bar()   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "V_eHib5QJipR",
        "outputId": "8fa015ed-6cd2-455c-dbe8-78dddea8b628"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f783767cbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#正解ラベル数比較\n",
        "import seaborn as sns\n",
        "sns.countplot(x=\"primalExpression\", data=df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "ayGT15x-3rqN",
        "outputId": "aca10fcd-ad17-44d6-c849-d5e6beac7f88"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f78375885d0>"
            ]
          },
          "metadata": {},
          "execution_count": 131
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = df.groupby(['positive','negative', 'neutral', 'mixed', 'non_negative','number_of_syllables',\n",
        "                     'number_of_pauses', 'rate_of_speech', 'articulation_rate',\n",
        "                     'speaking_duration', 'original_duration', 'balance', 'f0_mean',\n",
        "                     'f0_std', 'f0_median', 'f0_min', 'f0_max', 'f0_quantile25', 'f0_quan75']).mean().reset_index()\n",
        "                    #  'f0_std', 'f0_median', 'f0_min', 'f0_max', 'f0_quantile25', 'f0_quan75'], as_index=False)\n",
        "\n",
        "result.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgNlyBVIMh33",
        "outputId": "b946efb0-86f0-45fa-c72e-936f67bd03f5"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "lzEJnysbkcaV",
        "outputId": "0e38f221-4d06-4df1-ae32-30148b4db1ca"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   positive  negative   neutral     mixed  non_negative  number_of_syllables  \\\n",
              "0  0.000150  0.001103  0.998741  0.000006      0.998897                 19.0   \n",
              "1  0.000201  0.860960  0.138764  0.000075      0.139040                 27.0   \n",
              "2  0.000217  0.000166  0.999613  0.000005      0.999834                 18.0   \n",
              "3  0.000275  0.968899  0.027058  0.003768      0.031101                 21.0   \n",
              "4  0.000372  0.020208  0.977962  0.001458      0.979792                 23.0   \n",
              "\n",
              "   number_of_pauses  rate_of_speech  articulation_rate  speaking_duration  \\\n",
              "0               1.0             4.0                5.0                3.9   \n",
              "1               5.0             3.0                4.0                6.1   \n",
              "2               3.0             3.0                4.0                4.1   \n",
              "3               4.0             3.0                4.0                5.3   \n",
              "4               2.0             4.0                5.0                4.6   \n",
              "\n",
              "   ...     angry  disgusted  surprised     happy  Eyeglasses  Mustache  \\\n",
              "0  ...  1.162335   3.726363   7.403264  1.057426    0.928571       0.0   \n",
              "1  ...  3.187314   5.164883  10.153709  2.103233    1.000000       0.0   \n",
              "2  ...  1.199638   3.676051   7.289922  0.552628    0.928571       0.0   \n",
              "3  ...  2.068666   7.652417  12.320524  1.736997    0.971429       0.0   \n",
              "4  ...  1.314073   3.016328   7.801524  0.470987    0.971429       0.0   \n",
              "\n",
              "   Sunglasses  row_no  talk_length  result_flg  \n",
              "0         0.0     4.0         40.0         1.0  \n",
              "1         0.0   115.0         61.0         1.0  \n",
              "2         0.0    13.0         39.0         1.0  \n",
              "3         0.0    22.0         50.0         1.0  \n",
              "4         0.0    23.0         31.0         1.0  \n",
              "\n",
              "[5 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52138d40-ebed-44a6-b449-38d101a29a77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>mixed</th>\n",
              "      <th>non_negative</th>\n",
              "      <th>number_of_syllables</th>\n",
              "      <th>number_of_pauses</th>\n",
              "      <th>rate_of_speech</th>\n",
              "      <th>articulation_rate</th>\n",
              "      <th>speaking_duration</th>\n",
              "      <th>...</th>\n",
              "      <th>angry</th>\n",
              "      <th>disgusted</th>\n",
              "      <th>surprised</th>\n",
              "      <th>happy</th>\n",
              "      <th>Eyeglasses</th>\n",
              "      <th>Mustache</th>\n",
              "      <th>Sunglasses</th>\n",
              "      <th>row_no</th>\n",
              "      <th>talk_length</th>\n",
              "      <th>result_flg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.001103</td>\n",
              "      <td>0.998741</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.998897</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>...</td>\n",
              "      <td>1.162335</td>\n",
              "      <td>3.726363</td>\n",
              "      <td>7.403264</td>\n",
              "      <td>1.057426</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000201</td>\n",
              "      <td>0.860960</td>\n",
              "      <td>0.138764</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.139040</td>\n",
              "      <td>27.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>...</td>\n",
              "      <td>3.187314</td>\n",
              "      <td>5.164883</td>\n",
              "      <td>10.153709</td>\n",
              "      <td>2.103233</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000217</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.999613</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.999834</td>\n",
              "      <td>18.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>...</td>\n",
              "      <td>1.199638</td>\n",
              "      <td>3.676051</td>\n",
              "      <td>7.289922</td>\n",
              "      <td>0.552628</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000275</td>\n",
              "      <td>0.968899</td>\n",
              "      <td>0.027058</td>\n",
              "      <td>0.003768</td>\n",
              "      <td>0.031101</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.3</td>\n",
              "      <td>...</td>\n",
              "      <td>2.068666</td>\n",
              "      <td>7.652417</td>\n",
              "      <td>12.320524</td>\n",
              "      <td>1.736997</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000372</td>\n",
              "      <td>0.020208</td>\n",
              "      <td>0.977962</td>\n",
              "      <td>0.001458</td>\n",
              "      <td>0.979792</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.6</td>\n",
              "      <td>...</td>\n",
              "      <td>1.314073</td>\n",
              "      <td>3.016328</td>\n",
              "      <td>7.801524</td>\n",
              "      <td>0.470987</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52138d40-ebed-44a6-b449-38d101a29a77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52138d40-ebed-44a6-b449-38d101a29a77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52138d40-ebed-44a6-b449-38d101a29a77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flBmxFjmi-vu",
        "outputId": "5bf41a30-b0fa-4866-c4ab-5a386ccdc1f6"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['positive', 'negative', 'neutral', 'mixed', 'non_negative',\n",
              "       'number_of_syllables', 'number_of_pauses', 'rate_of_speech',\n",
              "       'articulation_rate', 'speaking_duration', 'original_duration',\n",
              "       'balance', 'f0_mean', 'f0_std', 'f0_median', 'f0_min', 'f0_max',\n",
              "       'f0_quantile25', 'f0_quan75', 'fps', 'smile_flg', 'smile_confidence',\n",
              "       'primalExpression', 'calm', 'sad', 'confused', 'fear', 'angry',\n",
              "       'disgusted', 'surprised', 'happy', 'Eyeglasses', 'Mustache',\n",
              "       'Sunglasses', 'row_no', 'talk_length', 'result_flg'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['recoginition_Sum1'] = result['happy'] + result['surprised']\n",
        "result['recoginition_Sum2'] = result['fear'] + result['angry']\n",
        "result['recoginition_Sum3'] = result['sad'] + result['disgusted']\n",
        "result['recoginition_Sum'] = result['happy'] + result['surprised'] + result['sad'] + result['disgusted'] + result['fear'] + result['angry'] + result['calm'] + result['confused']"
      ],
      "metadata": {
        "id": "D-_6XI40k59f"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#正解ラベル準備\n",
        "#sad\n",
        "result.loc[(result['recoginition_Sum3']%result['recoginition_Sum'] > 5) | (result['negative'] > 0.3), 'Answer'] = 2\n",
        "#fear\n",
        "result.loc[(result['recoginition_Sum2']%result['recoginition_Sum'] > 6) & (result['negative'] > 0.3), 'Answer'] = 4\n",
        "#disgusted\n",
        "result.loc[(result['recoginition_Sum3']%result['recoginition_Sum'] > 6) & (result['negative'] > 0.3), 'Answer'] = 6\n",
        "#angry\n",
        "result.loc[(result['recoginition_Sum2']%result['recoginition_Sum'] > 9) & (result['negative'] > 0.5), 'Answer'] = 5\n",
        "#Surprised\n",
        "result.loc[(result['recoginition_Sum1']%result['recoginition_Sum'] > 3) & (result['positive'] > 0.1), 'Answer'] = 7\n",
        "#Happy\n",
        "result.loc[(result['recoginition_Sum1']%result['recoginition_Sum'] > 12) | (result['positive'] > 0.25), 'Answer'] = 8\n",
        "# result.loc[(result['recoginition_Sum1']%result['recoginition_Sum'] > 6) & (result['positive'] > 0.15), 'Answer'] = 8\n",
        "#Calm\n",
        "result.loc[(result['calm']> 75) | (result['neutral'] > 0.75), 'Answer'] = 1\n",
        "#Confused\n",
        "result.loc[(result['confused']> 50) | (result['mixed'] > 0.1), 'Answer'] = 3\n"
      ],
      "metadata": {
        "id": "PNp9NiFboae6"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=\"Answer\", data=result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "fBXd0ZEA147t",
        "outputId": "f50af114-efda-49f4-a8cf-379a04a78b87"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f78374ad190>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5dbUcQiB2LO",
        "outputId": "1b1c79e2-a348-4336-a821-82162be3df9e"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive               0\n",
            "negative               0\n",
            "neutral                0\n",
            "mixed                  0\n",
            "non_negative           0\n",
            "number_of_syllables    0\n",
            "number_of_pauses       0\n",
            "rate_of_speech         0\n",
            "articulation_rate      0\n",
            "speaking_duration      0\n",
            "original_duration      0\n",
            "balance                0\n",
            "f0_mean                0\n",
            "f0_std                 0\n",
            "f0_median              0\n",
            "f0_min                 0\n",
            "f0_max                 0\n",
            "f0_quantile25          0\n",
            "f0_quan75              0\n",
            "fps                    0\n",
            "smile_flg              0\n",
            "smile_confidence       0\n",
            "primalExpression       0\n",
            "calm                   0\n",
            "sad                    0\n",
            "confused               0\n",
            "fear                   0\n",
            "angry                  0\n",
            "disgusted              0\n",
            "surprised              0\n",
            "happy                  0\n",
            "Eyeglasses             0\n",
            "Mustache               0\n",
            "Sunglasses             0\n",
            "row_no                 0\n",
            "talk_length            0\n",
            "result_flg             0\n",
            "recoginition_Sum1      0\n",
            "recoginition_Sum2      0\n",
            "recoginition_Sum3      0\n",
            "recoginition_Sum       0\n",
            "Answer                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result = []\n",
        "result.columns"
      ],
      "metadata": {
        "id": "R914so90psve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d28ed697-daa0-4c88-ffc6-11c85a601061"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['positive', 'negative', 'neutral', 'mixed', 'non_negative',\n",
              "       'number_of_syllables', 'number_of_pauses', 'rate_of_speech',\n",
              "       'articulation_rate', 'speaking_duration', 'original_duration',\n",
              "       'balance', 'f0_mean', 'f0_std', 'f0_median', 'f0_min', 'f0_max',\n",
              "       'f0_quantile25', 'f0_quan75', 'fps', 'smile_flg', 'smile_confidence',\n",
              "       'primalExpression', 'calm', 'sad', 'confused', 'fear', 'angry',\n",
              "       'disgusted', 'surprised', 'happy', 'Eyeglasses', 'Mustache',\n",
              "       'Sunglasses', 'row_no', 'talk_length', 'result_flg',\n",
              "       'recoginition_Sum1', 'recoginition_Sum2', 'recoginition_Sum3',\n",
              "       'recoginition_Sum', 'Answer'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = result"
      ],
      "metadata": {
        "id": "TNgAqSj9w5-_"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['fps', 'smile_flg', 'smile_confidence','primalExpression', \n",
        "              'calm', 'sad', 'confused', 'fear', 'angry','disgusted', 'surprised', \n",
        "              'happy', 'Eyeglasses', 'Mustache','Sunglasses', 'row_no','result_flg',\n",
        "              'recoginition_Sum1', 'recoginition_Sum2', 'recoginition_Sum3','recoginition_Sum'], axis=1)\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8NnYFgFw_Rx",
        "outputId": "eee52630-dc3f-4b2f-88a6-a238108d11e3"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['positive', 'negative', 'neutral', 'mixed', 'non_negative',\n",
              "       'number_of_syllables', 'number_of_pauses', 'rate_of_speech',\n",
              "       'articulation_rate', 'speaking_duration', 'original_duration',\n",
              "       'balance', 'f0_mean', 'f0_std', 'f0_median', 'f0_min', 'f0_max',\n",
              "       'f0_quantile25', 'f0_quan75', 'talk_length', 'Answer'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##前処理"
      ],
      "metadata": {
        "id": "jUfcc36tjGFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#正解ラベルの置換(4分類)\n",
        "# 1:'calm', '2:sad', '3:confused', '4:fear', '5:angry','6:disgusted', '7:surprised', '8:happy',\n",
        "# df.loc[df['Answer'] == 1, 'A'] = int(4)\n",
        "# df.loc[df['Answer'] == 2, 'A'] = int(3)\n",
        "# df.loc[df['Answer'] == 3, 'A'] = int(2)\n",
        "# df.loc[df['Answer'] == 4, 'A'] = int(2)\n",
        "# df.loc[df['Answer'] == 5, 'A'] = int(2)\n",
        "# df.loc[df['Answer'] == 6, 'A'] = int(3)\n",
        "# df.loc[df['Answer'] == 7, 'A'] = int(1)\n",
        "# df.loc[df['Answer'] == 8, 'A'] = int(1)"
      ],
      "metadata": {
        "id": "XYdlztd2jv1S"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 喜とそれ以外\n",
        "#正解ラベルの置換（２分類） : \n",
        "# 1:'calm', '2:sad', '3:confused', '4:fear', '5:angry','6:disgusted', '7:surprised', '8:happy',\n",
        "df.loc[df['Answer'] == 1, 'A'] = int(0)\n",
        "df.loc[df['Answer'] == 2, 'A'] = int(0)\n",
        "df.loc[df['Answer'] == 3, 'A'] = int(0)\n",
        "df.loc[df['Answer'] == 4, 'A'] = int(0)\n",
        "df.loc[df['Answer'] == 5, 'A'] = int(0)\n",
        "df.loc[df['Answer'] == 6, 'A'] = int(0)\n",
        "df.loc[df['Answer'] == 7, 'A'] = int(1)\n",
        "df.loc[df['Answer'] == 8, 'A'] = int(1)"
      ],
      "metadata": {
        "id": "Xg5_M4wLm7Cx"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ans = df['A']\n",
        "# df_ans= df.drop(['positive', 'negative', 'neutral', 'mixed','non_negative', 'number_of_syllables',\n",
        "#            'number_of_pauses','rate_of_speech', 'articulation_rate', 'speaking_duration',\n",
        "#            'original_duration', 'balance', 'f0_mean', 'f0_std', 'f0_median','f0_min', 'f0_max', \n",
        "#            'f0_quantile25', 'f0_quan75'], axis=1)\n",
        "df_input = df.drop(['Answer','A'], axis=1)"
      ],
      "metadata": {
        "id": "uqCuXMHOzcJT"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ans.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8RIsofMjZxl",
        "outputId": "b57ceb18-f7d4-47b6-bfa1-ffccc4876f2a"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_input.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "uB5C5jKf3wVY",
        "outputId": "dec32bce-af38-4674-973a-88539faadc79"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   positive  negative   neutral     mixed  non_negative  number_of_syllables  \\\n",
              "0  0.000150  0.001103  0.998741  0.000006      0.998897                 19.0   \n",
              "1  0.000201  0.860960  0.138764  0.000075      0.139040                 27.0   \n",
              "2  0.000217  0.000166  0.999613  0.000005      0.999834                 18.0   \n",
              "\n",
              "   number_of_pauses  rate_of_speech  articulation_rate  speaking_duration  \\\n",
              "0               1.0             4.0                5.0                3.9   \n",
              "1               5.0             3.0                4.0                6.1   \n",
              "2               3.0             3.0                4.0                4.1   \n",
              "\n",
              "   original_duration  balance  f0_mean  f0_std  f0_median  f0_min  f0_max  \\\n",
              "0                4.8      0.8   206.28   99.79      179.1    83.0   394.0   \n",
              "1                9.3      0.7   141.84   36.22      132.7    81.0   254.0   \n",
              "2                6.0      0.7   140.84   48.82      130.0    81.0   392.0   \n",
              "\n",
              "   f0_quantile25  f0_quan75  talk_length  \n",
              "0          115.0      293.0         40.0  \n",
              "1          116.0      168.0         61.0  \n",
              "2          108.0      176.0         39.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-750656d1-a0fd-4e38-bff2-a1bec00591ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>mixed</th>\n",
              "      <th>non_negative</th>\n",
              "      <th>number_of_syllables</th>\n",
              "      <th>number_of_pauses</th>\n",
              "      <th>rate_of_speech</th>\n",
              "      <th>articulation_rate</th>\n",
              "      <th>speaking_duration</th>\n",
              "      <th>original_duration</th>\n",
              "      <th>balance</th>\n",
              "      <th>f0_mean</th>\n",
              "      <th>f0_std</th>\n",
              "      <th>f0_median</th>\n",
              "      <th>f0_min</th>\n",
              "      <th>f0_max</th>\n",
              "      <th>f0_quantile25</th>\n",
              "      <th>f0_quan75</th>\n",
              "      <th>talk_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.001103</td>\n",
              "      <td>0.998741</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.998897</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>206.28</td>\n",
              "      <td>99.79</td>\n",
              "      <td>179.1</td>\n",
              "      <td>83.0</td>\n",
              "      <td>394.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>293.0</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000201</td>\n",
              "      <td>0.860960</td>\n",
              "      <td>0.138764</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.139040</td>\n",
              "      <td>27.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>9.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>141.84</td>\n",
              "      <td>36.22</td>\n",
              "      <td>132.7</td>\n",
              "      <td>81.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>61.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000217</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.999613</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.999834</td>\n",
              "      <td>18.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>140.84</td>\n",
              "      <td>48.82</td>\n",
              "      <td>130.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>392.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-750656d1-a0fd-4e38-bff2-a1bec00591ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-750656d1-a0fd-4e38-bff2-a1bec00591ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-750656d1-a0fd-4e38-bff2-a1bec00591ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_org = df_ans.to_numpy()\n",
        "x_org = df_input.to_numpy()"
      ],
      "metadata": {
        "id": "uYA5sLBsw_BU"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('元データ',y_org.shape,x_org.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0r0jJHmyMXO",
        "outputId": "df511e42-ae5b-4b0b-81fe-66debf8c6c10"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "元データ (128,) (128, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dOTzVWYB8wM"
      },
      "source": [
        "### 訓練データ・検証データの分割"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#割合設定\n",
        "train_counts = len(x_org) * 0.6\n",
        "test_counts = len(x_org) * 0.4\n",
        "print(train_counts,test_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVBINcT6DUYR",
        "outputId": "f8fb526e-2ab9-4534-99a2-61e7e8e07f70"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76.8 51.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m016TNL9B8wU"
      },
      "source": [
        "## 入力変数の２０次元化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI61G1-GB8wU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d0c9e1-5674-4eb2-d1fa-dc4dc8e28a97"
      },
      "source": [
        "# 訓練データ、検証データに分割 (シャフルも同時に実施)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_org, y_org, train_size=int(train_counts), test_size=int(test_counts), \n",
        "    random_state=123)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# 入力次元数\n",
        "n_input = x_train.shape[1]"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(76, 20) (51, 20) (76,) (51,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データを正解値ごとに分割\n",
        "x_t0 = x_train[y_train == 1]\n",
        "x_t1 = x_train[y_train == 2]\n",
        "x_t2 = x_train[y_train == 3]\n",
        "x_t3 = x_train[y_train == 4]\n",
        "# x_t4 = x_train[y_train == 5]\n",
        "# x_t5 = x_train[y_train == 6]\n",
        "# x_t6 = x_train[y_train == 7]\n",
        "# x_t7 = x_train[y_train == 8]\n"
      ],
      "metadata": {
        "id": "rZUXoUkWLNoU"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習用パラメータ設定\n",
        "\n",
        "# 入力次元数\n",
        "n_input = x_train.shape[1]\n",
        "\n",
        "# 出力次元数\n",
        "# 分類先クラス数　今回はXXXXになる\n",
        "n_output = len(list(set(y_train))) + 2\n",
        "# n_output = len(list(set(y_train)))\n",
        "\n",
        "# 結果確認\n",
        "print(f'n_input: {n_input}  n_output: {n_output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MOp9nCcctPb",
        "outputId": "b4d82e44-1a0d-497a-ca8e-7d1d1dedfa22"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_input: 20  n_output: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKNGGkyZdMNf"
      },
      "source": [
        "### モデル確認"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # モデル内のパラメータの確認\n",
        "# # l1.weightが行列にl1.biasがベクトルになっている\n",
        "\n",
        "# for parameter in net.named_parameters():\n",
        "#     print(parameter)"
      ],
      "metadata": {
        "id": "NJQB0SMxdIaN"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの定義\n",
        "# 19入力9出力のロジスティック回帰モデル\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_input, n_output):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_input, n_output)\n",
        "                \n",
        "        # 初期値を全部1にする    \n",
        "        self.l1.weight.data.fill_(1.0)\n",
        "        self.l1.bias.data.fill_(1.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.l1(x)\n",
        "        return x1\n",
        "    \n",
        "# インスタンスの生成\n",
        "# net = Net(n_input, n_output + 1)       \n",
        "net = Net(n_input, n_output)    "
      ],
      "metadata": {
        "id": "ieFeWz-KcybP"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの概要表示\n",
        "\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dMgIPO2c443",
        "outputId": "bff8d08b-d778-4e16-845f-519a3e6b1aa1"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (l1): Linear(in_features=20, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルのサマリー表示\n",
        "\n",
        "summary(net, (20,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb6LK7h2c69B",
        "outputId": "9421fe84-20d0-46a8-dbef-abb1674458a4"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Net                                      [4]                       --\n",
              "├─Linear: 1-1                            [4]                       84\n",
              "==========================================================================================\n",
              "Total params: 84\n",
              "Trainable params: 84\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_org.shape"
      ],
      "metadata": {
        "id": "lrSBRIwhlazG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3264bddc-81b1-49ec-d950-4344ef337453"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_org"
      ],
      "metadata": {
        "id": "49PsB-xQ9R0m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d657993d-aa2f-485d-de15-f52f9f65d685"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0.0001,   0.0011,   0.9987, ..., 115.    , 293.    ,  40.    ],\n",
              "       [  0.0002,   0.861 ,   0.1388, ..., 116.    , 168.    ,  61.    ],\n",
              "       [  0.0002,   0.0002,   0.9996, ..., 108.    , 176.    ,  39.    ],\n",
              "       ...,\n",
              "       [  0.8956,   0.0007,   0.1037, ...,  92.    , 163.    ,  60.    ],\n",
              "       [  0.9598,   0.0012,   0.0388, ..., 100.    , 184.    ,  41.    ],\n",
              "       [  0.9954,   0.0003,   0.0043, ..., 111.    , 221.    ,  24.    ]])"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_org.shape"
      ],
      "metadata": {
        "id": "a8kqMkV5lflT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb86e5f-37fc-48df-9fb6-0783e9f92c76"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128,)"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziivFupuB8wU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb3efea-7151-463f-9d4f-e57602549804"
      },
      "source": [
        "print('入力データ(x)')\n",
        "print(x_train[:5,:])\n",
        "print(f'入力次元数: {n_input}')"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "入力データ(x)\n",
            "[[  0.0038   0.8525   0.1437   0.0001   0.1475  35.       2.       4.\n",
            "    5.       6.5      8.       0.8    175.32    70.96   170.      82.\n",
            "  399.     107.     240.      63.    ]\n",
            " [  0.0066   0.4748   0.5182   0.0003   0.5252  20.       4.       3.\n",
            "    5.       4.2      6.       0.7    214.8     87.89   185.1     82.\n",
            "  399.     142.     298.      37.    ]\n",
            " [  0.617    0.0144   0.3473   0.0212   0.9856  21.       2.       3.\n",
            "    6.       3.8      6.2      0.6    135.4     47.24   116.1     79.\n",
            "  390.     106.     159.      35.    ]\n",
            " [  0.1028   0.5024   0.3943   0.0006   0.4976  22.       1.       4.\n",
            "    5.       4.7      5.5      0.9    106.18    35.06    92.3     73.\n",
            "  294.      88.     112.      47.    ]\n",
            " [  0.0008   0.1991   0.8      0.       0.8009  30.       2.       4.\n",
            "    5.       5.7      7.       0.8    170.49    79.26   141.4     80.\n",
            "  400.     109.     202.      51.    ]]\n",
            "入力次元数: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "K9sQuuReGHLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "818438af-133f-4f5a-f7a4-e1f4ef515034"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0.0038,   0.8525,   0.1437, ..., 107.    , 240.    ,  63.    ],\n",
              "       [  0.0066,   0.4748,   0.5182, ..., 142.    , 298.    ,  37.    ],\n",
              "       [  0.617 ,   0.0144,   0.3473, ..., 106.    , 159.    ,  35.    ],\n",
              "       ...,\n",
              "       [  0.04  ,   0.0072,   0.9526, ..., 100.    , 243.    ,  39.    ],\n",
              "       [  0.0067,   0.0062,   0.987 , ..., 139.    , 243.    ,  37.    ],\n",
              "       [  0.1611,   0.4143,   0.1631, ...,  91.    , 220.    ,  54.    ]])"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "nYrJ8LyyhNWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9af78cd-6c31-4328-cc6c-8833b81ae648"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train= x_train.astype(float)\n",
        "# y_train= y_train.astype(float)\n",
        "x_test= x_test.astype(float)\n",
        "# y_test= y_test.astype(float)"
      ],
      "metadata": {
        "id": "pIQ3n9g6F99o"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "z6yJRXeKhP1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19de0fd6-24fc-4859-e231-d3f95dd4e2a5"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFZ-B_yyB8wU"
      },
      "source": [
        "# 入力データ x_train と正解データ y_train のテンソル変数化\n",
        "inputs = torch.tensor(x_train).float()\n",
        "labels = torch.tensor(y_train).long()\n",
        "\n",
        "# 検証用データのテンソル変数化\n",
        "inputs_test = torch.tensor(x_test).float()\n",
        "labels_test = torch.tensor(y_test).long()"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DORSG_Q2B8wU"
      },
      "source": [
        "# 学習率\n",
        "lr = 0.001\n",
        "\n",
        "# 初期化\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化アルゴリズム: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 10000\n",
        "\n",
        "# 評価結果記録用\n",
        "history = np.zeros((0,5))"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Y4gM9OQgB8wV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e52f4b-f85c-43e1-9579-9ce9bac935ee"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # 訓練フェーズ\n",
        "    \n",
        "    #勾配の初期化\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 予測計算\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # 損失計算\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # 勾配計算\n",
        "    loss.backward()\n",
        "    \n",
        "    # パラメータ修正\n",
        "    optimizer.step()\n",
        "\n",
        "    #予測値算出\n",
        "    predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "    # 損失と精度の計算\n",
        "    train_loss = loss.item()\n",
        "    train_acc = (predicted == labels).sum()  / len(labels)\n",
        "\n",
        "    #予測フェーズ\n",
        "\n",
        "    # 予測計算\n",
        "    outputs_test = net(inputs_test)\n",
        "\n",
        "    # 損失計算\n",
        "    loss_test = criterion(outputs_test, labels_test)\n",
        "\n",
        "    # 予測ラベル算出\n",
        "    predicted_test = torch.max(outputs_test, 1)[1]\n",
        "\n",
        "    # 損失と精度の計算\n",
        "    val_loss =  loss_test.item()\n",
        "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
        "    \n",
        "    if ( epoch % 10 == 0):\n",
        "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
        "        item = np.array([epoch , train_loss, train_acc, val_loss, val_acc])\n",
        "        history = np.vstack((history, item))"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/10000], loss: 1.38629 acc: 0.75000 val_loss: 22.65546, val_acc: 0.82353\n",
            "Epoch [10/10000], loss: 18.72375 acc: 0.75000 val_loss: 36.85330, val_acc: 0.17647\n",
            "Epoch [20/10000], loss: 80.74631 acc: 0.75000 val_loss: 38.61015, val_acc: 0.82353\n",
            "Epoch [30/10000], loss: 23.21649 acc: 0.75000 val_loss: 20.94051, val_acc: 0.17647\n",
            "Epoch [40/10000], loss: 85.23680 acc: 0.75000 val_loss: 42.17952, val_acc: 0.82353\n",
            "Epoch [50/10000], loss: 24.73075 acc: 0.75000 val_loss: 15.18611, val_acc: 0.17647\n",
            "Epoch [60/10000], loss: 83.88705 acc: 0.75000 val_loss: 41.33286, val_acc: 0.82353\n",
            "Epoch [70/10000], loss: 24.36383 acc: 0.75000 val_loss: 15.86285, val_acc: 0.17647\n",
            "Epoch [80/10000], loss: 83.92032 acc: 0.75000 val_loss: 41.53117, val_acc: 0.82353\n",
            "Epoch [90/10000], loss: 24.17282 acc: 0.75000 val_loss: 16.04045, val_acc: 0.19608\n",
            "Epoch [100/10000], loss: 81.92419 acc: 0.75000 val_loss: 40.19409, val_acc: 0.82353\n",
            "Epoch [110/10000], loss: 22.15831 acc: 0.75000 val_loss: 22.25888, val_acc: 0.19608\n",
            "Epoch [120/10000], loss: 81.54085 acc: 0.75000 val_loss: 40.07666, val_acc: 0.82353\n",
            "Epoch [130/10000], loss: 21.72098 acc: 0.75000 val_loss: 23.26559, val_acc: 0.19608\n",
            "Epoch [140/10000], loss: 79.62543 acc: 0.75000 val_loss: 38.80019, val_acc: 0.82353\n",
            "Epoch [150/10000], loss: 19.82311 acc: 0.75000 val_loss: 29.10755, val_acc: 0.19608\n",
            "Epoch [160/10000], loss: 79.09945 acc: 0.75000 val_loss: 38.57474, val_acc: 0.82353\n",
            "Epoch [170/10000], loss: 19.28852 acc: 0.75000 val_loss: 30.43858, val_acc: 0.19608\n",
            "Epoch [180/10000], loss: 77.23631 acc: 0.75000 val_loss: 37.33775, val_acc: 0.82353\n",
            "Epoch [190/10000], loss: 17.42948 acc: 0.75000 val_loss: 36.15362, val_acc: 0.19608\n",
            "Epoch [200/10000], loss: 76.68515 acc: 0.75000 val_loss: 37.09320, val_acc: 0.82353\n",
            "Epoch [210/10000], loss: 16.87633 acc: 0.75000 val_loss: 37.54660, val_acc: 0.19608\n",
            "Epoch [220/10000], loss: 74.83396 acc: 0.75000 val_loss: 35.86525, val_acc: 0.82353\n",
            "Epoch [230/10000], loss: 15.02611 acc: 0.75000 val_loss: 43.23256, val_acc: 0.19608\n",
            "Epoch [240/10000], loss: 74.27692 acc: 0.75000 val_loss: 35.61627, val_acc: 0.82353\n",
            "Epoch [250/10000], loss: 14.46856 acc: 0.75000 val_loss: 44.64004, val_acc: 0.19608\n",
            "Epoch [260/10000], loss: 72.42877 acc: 0.75000 val_loss: 34.39057, val_acc: 0.82353\n",
            "Epoch [270/10000], loss: 12.62977 acc: 0.75000 val_loss: 48.26079, val_acc: 0.19608\n",
            "Epoch [280/10000], loss: 71.85386 acc: 0.75000 val_loss: 34.10241, val_acc: 0.82353\n",
            "Epoch [290/10000], loss: 12.63528 acc: 0.73684 val_loss: 42.01525, val_acc: 0.21569\n",
            "Epoch [300/10000], loss: 72.95016 acc: 0.75000 val_loss: 35.04245, val_acc: 0.82353\n",
            "Epoch [310/10000], loss: 13.00093 acc: 0.72368 val_loss: 39.68207, val_acc: 0.27451\n",
            "Epoch [320/10000], loss: 32.55849 acc: 0.75000 val_loss: 8.43429, val_acc: 0.66667\n",
            "Epoch [330/10000], loss: 13.99858 acc: 0.75000 val_loss: 45.25377, val_acc: 0.19608\n",
            "Epoch [340/10000], loss: 71.62408 acc: 0.75000 val_loss: 33.96834, val_acc: 0.82353\n",
            "Epoch [350/10000], loss: 12.59943 acc: 0.73684 val_loss: 45.52153, val_acc: 0.19608\n",
            "Epoch [360/10000], loss: 72.30898 acc: 0.75000 val_loss: 34.60483, val_acc: 0.82353\n",
            "Epoch [370/10000], loss: 13.23583 acc: 0.73684 val_loss: 43.33784, val_acc: 0.19608\n",
            "Epoch [380/10000], loss: 72.85126 acc: 0.75000 val_loss: 35.13354, val_acc: 0.82353\n",
            "Epoch [390/10000], loss: 13.53112 acc: 0.73684 val_loss: 41.05189, val_acc: 0.25490\n",
            "Epoch [400/10000], loss: 64.38027 acc: 0.75000 val_loss: 28.78842, val_acc: 0.82353\n",
            "Epoch [410/10000], loss: 16.45473 acc: 0.39474 val_loss: 44.95567, val_acc: 0.82353\n",
            "Epoch [420/10000], loss: 14.53858 acc: 0.75000 val_loss: 43.15317, val_acc: 0.17647\n",
            "Epoch [430/10000], loss: 72.93745 acc: 0.75000 val_loss: 34.86476, val_acc: 0.82353\n",
            "Epoch [440/10000], loss: 13.03551 acc: 0.75000 val_loss: 47.62491, val_acc: 0.17647\n",
            "Epoch [450/10000], loss: 71.79261 acc: 0.75000 val_loss: 34.16718, val_acc: 0.82353\n",
            "Epoch [460/10000], loss: 12.31722 acc: 0.73684 val_loss: 45.77286, val_acc: 0.19608\n",
            "Epoch [470/10000], loss: 71.97775 acc: 0.75000 val_loss: 34.43074, val_acc: 0.82353\n",
            "Epoch [480/10000], loss: 12.92057 acc: 0.73684 val_loss: 43.42813, val_acc: 0.17647\n",
            "Epoch [490/10000], loss: 72.59491 acc: 0.75000 val_loss: 35.01608, val_acc: 0.82353\n",
            "Epoch [500/10000], loss: 13.53642 acc: 0.73684 val_loss: 41.38456, val_acc: 0.23529\n",
            "Epoch [510/10000], loss: 73.15598 acc: 0.75000 val_loss: 35.55881, val_acc: 0.82353\n",
            "Epoch [520/10000], loss: 13.77332 acc: 0.73684 val_loss: 40.01828, val_acc: 0.27451\n",
            "Epoch [530/10000], loss: 71.21223 acc: 0.75000 val_loss: 34.19275, val_acc: 0.82353\n",
            "Epoch [540/10000], loss: 11.70724 acc: 0.53947 val_loss: 23.97104, val_acc: 0.82353\n",
            "Epoch [550/10000], loss: 15.95956 acc: 0.75000 val_loss: 37.13402, val_acc: 0.15686\n",
            "Epoch [560/10000], loss: 72.10793 acc: 0.75000 val_loss: 34.48597, val_acc: 0.82353\n",
            "Epoch [570/10000], loss: 12.21136 acc: 0.73684 val_loss: 45.51038, val_acc: 0.17647\n",
            "Epoch [580/10000], loss: 71.84946 acc: 0.75000 val_loss: 34.41927, val_acc: 0.82353\n",
            "Epoch [590/10000], loss: 12.79336 acc: 0.73684 val_loss: 43.02926, val_acc: 0.17647\n",
            "Epoch [600/10000], loss: 72.46864 acc: 0.75000 val_loss: 35.00607, val_acc: 0.82353\n",
            "Epoch [610/10000], loss: 13.41383 acc: 0.73684 val_loss: 40.90790, val_acc: 0.23529\n",
            "Epoch [620/10000], loss: 73.08498 acc: 0.75000 val_loss: 35.59067, val_acc: 0.82353\n",
            "Epoch [630/10000], loss: 14.00195 acc: 0.73684 val_loss: 39.13079, val_acc: 0.27451\n",
            "Epoch [640/10000], loss: 73.18328 acc: 0.75000 val_loss: 35.78241, val_acc: 0.82353\n",
            "Epoch [650/10000], loss: 13.53464 acc: 0.73684 val_loss: 38.41978, val_acc: 0.29412\n",
            "Epoch [660/10000], loss: 28.79549 acc: 0.75000 val_loss: 10.45856, val_acc: 0.54902\n",
            "Epoch [670/10000], loss: 7.31726 acc: 0.65789 val_loss: 11.58952, val_acc: 0.82353\n",
            "Epoch [680/10000], loss: 45.01145 acc: 0.26316 val_loss: 56.46101, val_acc: 0.82353\n",
            "Epoch [690/10000], loss: 42.02810 acc: 0.75000 val_loss: 12.08164, val_acc: 0.82353\n",
            "Epoch [700/10000], loss: 43.03358 acc: 0.26316 val_loss: 57.02329, val_acc: 0.82353\n",
            "Epoch [710/10000], loss: 42.64583 acc: 0.75000 val_loss: 12.66731, val_acc: 0.82353\n",
            "Epoch [720/10000], loss: 41.01967 acc: 0.26316 val_loss: 57.61206, val_acc: 0.82353\n",
            "Epoch [730/10000], loss: 43.26735 acc: 0.75000 val_loss: 13.25570, val_acc: 0.82353\n",
            "Epoch [740/10000], loss: 39.00899 acc: 0.26316 val_loss: 58.19131, val_acc: 0.82353\n",
            "Epoch [750/10000], loss: 43.80585 acc: 0.75000 val_loss: 13.78270, val_acc: 0.82353\n",
            "Epoch [760/10000], loss: 37.71630 acc: 0.26316 val_loss: 58.24440, val_acc: 0.82353\n",
            "Epoch [770/10000], loss: 43.13665 acc: 0.75000 val_loss: 13.46927, val_acc: 0.78431\n",
            "Epoch [780/10000], loss: 13.26427 acc: 0.55263 val_loss: 25.41743, val_acc: 0.82353\n",
            "Epoch [790/10000], loss: 39.35348 acc: 0.75000 val_loss: 10.79047, val_acc: 0.74510\n",
            "Epoch [800/10000], loss: 40.78985 acc: 0.26316 val_loss: 57.72505, val_acc: 0.82353\n",
            "Epoch [810/10000], loss: 43.34768 acc: 0.75000 val_loss: 13.40490, val_acc: 0.82353\n",
            "Epoch [820/10000], loss: 38.61737 acc: 0.26316 val_loss: 58.33918, val_acc: 0.82353\n",
            "Epoch [830/10000], loss: 43.84048 acc: 0.75000 val_loss: 13.89768, val_acc: 0.82353\n",
            "Epoch [840/10000], loss: 37.61613 acc: 0.26316 val_loss: 58.31721, val_acc: 0.82353\n",
            "Epoch [850/10000], loss: 43.07476 acc: 0.75000 val_loss: 13.52183, val_acc: 0.78431\n",
            "Epoch [860/10000], loss: 13.30856 acc: 0.53947 val_loss: 26.52084, val_acc: 0.82353\n",
            "Epoch [870/10000], loss: 43.52990 acc: 0.75000 val_loss: 13.59694, val_acc: 0.82353\n",
            "Epoch [880/10000], loss: 38.40753 acc: 0.26316 val_loss: 58.41924, val_acc: 0.82353\n",
            "Epoch [890/10000], loss: 43.82041 acc: 0.75000 val_loss: 13.94002, val_acc: 0.82353\n",
            "Epoch [900/10000], loss: 37.66595 acc: 0.26316 val_loss: 58.32681, val_acc: 0.82353\n",
            "Epoch [910/10000], loss: 42.93411 acc: 0.75000 val_loss: 13.49009, val_acc: 0.78431\n",
            "Epoch [920/10000], loss: 14.64417 acc: 0.50000 val_loss: 31.95022, val_acc: 0.82353\n",
            "Epoch [930/10000], loss: 10.24086 acc: 0.56579 val_loss: 20.39963, val_acc: 0.82353\n",
            "Epoch [940/10000], loss: 7.64011 acc: 0.71053 val_loss: 24.68467, val_acc: 0.31373\n",
            "Epoch [950/10000], loss: 71.34210 acc: 0.75000 val_loss: 34.27205, val_acc: 0.82353\n",
            "Epoch [960/10000], loss: 12.19113 acc: 0.73684 val_loss: 43.23328, val_acc: 0.17647\n",
            "Epoch [970/10000], loss: 71.85084 acc: 0.75000 val_loss: 34.77663, val_acc: 0.82353\n",
            "Epoch [980/10000], loss: 12.79726 acc: 0.73684 val_loss: 40.76700, val_acc: 0.19608\n",
            "Epoch [990/10000], loss: 72.47379 acc: 0.75000 val_loss: 35.36624, val_acc: 0.82353\n",
            "Epoch [1000/10000], loss: 13.42096 acc: 0.73684 val_loss: 38.56355, val_acc: 0.21569\n",
            "Epoch [1010/10000], loss: 73.09432 acc: 0.75000 val_loss: 35.95399, val_acc: 0.82353\n",
            "Epoch [1020/10000], loss: 14.02030 acc: 0.73684 val_loss: 36.67147, val_acc: 0.23529\n",
            "Epoch [1030/10000], loss: 73.32343 acc: 0.75000 val_loss: 36.24521, val_acc: 0.82353\n",
            "Epoch [1040/10000], loss: 13.80872 acc: 0.73684 val_loss: 36.60935, val_acc: 0.31373\n",
            "Epoch [1050/10000], loss: 71.99950 acc: 0.75000 val_loss: 35.35167, val_acc: 0.82353\n",
            "Epoch [1060/10000], loss: 8.86684 acc: 0.71053 val_loss: 16.81791, val_acc: 0.41176\n",
            "Epoch [1070/10000], loss: 37.13967 acc: 0.75000 val_loss: 10.15717, val_acc: 0.74510\n",
            "Epoch [1080/10000], loss: 42.48087 acc: 0.75000 val_loss: 12.80054, val_acc: 0.82353\n",
            "Epoch [1090/10000], loss: 41.81561 acc: 0.26316 val_loss: 57.55935, val_acc: 0.82353\n",
            "Epoch [1100/10000], loss: 42.84703 acc: 0.75000 val_loss: 13.19926, val_acc: 0.82353\n",
            "Epoch [1110/10000], loss: 39.80089 acc: 0.26316 val_loss: 58.14779, val_acc: 0.82353\n",
            "Epoch [1120/10000], loss: 43.46350 acc: 0.75000 val_loss: 13.78390, val_acc: 0.82353\n",
            "Epoch [1130/10000], loss: 37.85360 acc: 0.26316 val_loss: 58.61612, val_acc: 0.82353\n",
            "Epoch [1140/10000], loss: 43.46152 acc: 0.75000 val_loss: 13.91040, val_acc: 0.82353\n",
            "Epoch [1150/10000], loss: 37.99515 acc: 0.26316 val_loss: 58.25023, val_acc: 0.82353\n",
            "Epoch [1160/10000], loss: 40.91951 acc: 0.75000 val_loss: 12.52097, val_acc: 0.76471\n",
            "Epoch [1170/10000], loss: 19.55942 acc: 0.40789 val_loss: 46.05807, val_acc: 0.82353\n",
            "Epoch [1180/10000], loss: 14.68754 acc: 0.75000 val_loss: 37.27470, val_acc: 0.23529\n",
            "Epoch [1190/10000], loss: 72.96828 acc: 0.75000 val_loss: 35.99134, val_acc: 0.82353\n",
            "Epoch [1200/10000], loss: 13.88966 acc: 0.73684 val_loss: 36.19510, val_acc: 0.23529\n",
            "Epoch [1210/10000], loss: 73.18563 acc: 0.75000 val_loss: 36.27374, val_acc: 0.82353\n",
            "Epoch [1220/10000], loss: 13.68327 acc: 0.73684 val_loss: 36.14891, val_acc: 0.27451\n",
            "Epoch [1230/10000], loss: 72.31065 acc: 0.75000 val_loss: 35.72139, val_acc: 0.82353\n",
            "Epoch [1240/10000], loss: 10.60006 acc: 0.71053 val_loss: 30.62094, val_acc: 0.33333\n",
            "Epoch [1250/10000], loss: 48.00987 acc: 0.75000 val_loss: 17.29354, val_acc: 0.82353\n",
            "Epoch [1260/10000], loss: 38.52023 acc: 0.26316 val_loss: 58.55392, val_acc: 0.82353\n",
            "Epoch [1270/10000], loss: 43.55988 acc: 0.75000 val_loss: 14.03237, val_acc: 0.82353\n",
            "Epoch [1280/10000], loss: 38.02393 acc: 0.26316 val_loss: 58.42930, val_acc: 0.82353\n",
            "Epoch [1290/10000], loss: 42.90308 acc: 0.75000 val_loss: 13.72135, val_acc: 0.78431\n",
            "Epoch [1300/10000], loss: 33.34843 acc: 0.27632 val_loss: 55.68534, val_acc: 0.82353\n",
            "Epoch [1310/10000], loss: 36.22628 acc: 0.75000 val_loss: 10.23948, val_acc: 0.72549\n",
            "Epoch [1320/10000], loss: 62.48539 acc: 0.75000 val_loss: 28.16121, val_acc: 0.82353\n",
            "Epoch [1330/10000], loss: 42.98312 acc: 0.75000 val_loss: 13.46465, val_acc: 0.82353\n",
            "Epoch [1340/10000], loss: 39.85310 acc: 0.26316 val_loss: 58.22441, val_acc: 0.82353\n",
            "Epoch [1350/10000], loss: 43.34052 acc: 0.75000 val_loss: 13.85649, val_acc: 0.82353\n",
            "Epoch [1360/10000], loss: 37.95384 acc: 0.26316 val_loss: 58.63832, val_acc: 0.82353\n",
            "Epoch [1370/10000], loss: 43.25386 acc: 0.75000 val_loss: 13.91991, val_acc: 0.82353\n",
            "Epoch [1380/10000], loss: 38.28852 acc: 0.26316 val_loss: 58.26624, val_acc: 0.82353\n",
            "Epoch [1390/10000], loss: 41.22966 acc: 0.75000 val_loss: 12.82821, val_acc: 0.76471\n",
            "Epoch [1400/10000], loss: 33.77624 acc: 0.27632 val_loss: 56.20221, val_acc: 0.82353\n",
            "Epoch [1410/10000], loss: 40.31355 acc: 0.75000 val_loss: 12.23405, val_acc: 0.76471\n",
            "Epoch [1420/10000], loss: 33.90244 acc: 0.27632 val_loss: 56.51001, val_acc: 0.82353\n",
            "Epoch [1430/10000], loss: 40.77383 acc: 0.75000 val_loss: 12.41494, val_acc: 0.76471\n",
            "Epoch [1440/10000], loss: 35.65883 acc: 0.25000 val_loss: 57.61191, val_acc: 0.82353\n",
            "Epoch [1450/10000], loss: 43.08534 acc: 0.75000 val_loss: 13.88661, val_acc: 0.82353\n",
            "Epoch [1460/10000], loss: 38.11416 acc: 0.26316 val_loss: 58.08440, val_acc: 0.82353\n",
            "Epoch [1470/10000], loss: 39.76862 acc: 0.75000 val_loss: 12.09615, val_acc: 0.76471\n",
            "Epoch [1480/10000], loss: 33.92381 acc: 0.27632 val_loss: 56.33617, val_acc: 0.82353\n",
            "Epoch [1490/10000], loss: 40.34525 acc: 0.75000 val_loss: 12.29510, val_acc: 0.76471\n",
            "Epoch [1500/10000], loss: 33.78567 acc: 0.27632 val_loss: 56.58281, val_acc: 0.82353\n",
            "Epoch [1510/10000], loss: 40.80478 acc: 0.75000 val_loss: 12.47802, val_acc: 0.76471\n",
            "Epoch [1520/10000], loss: 36.36912 acc: 0.25000 val_loss: 58.02029, val_acc: 0.82353\n",
            "Epoch [1530/10000], loss: 43.10670 acc: 0.75000 val_loss: 13.96636, val_acc: 0.80392\n",
            "Epoch [1540/10000], loss: 38.09983 acc: 0.26316 val_loss: 58.07677, val_acc: 0.82353\n",
            "Epoch [1550/10000], loss: 39.55886 acc: 0.75000 val_loss: 12.04188, val_acc: 0.76471\n",
            "Epoch [1560/10000], loss: 31.99618 acc: 0.27632 val_loss: 56.12478, val_acc: 0.82353\n",
            "Epoch [1570/10000], loss: 40.47433 acc: 0.75000 val_loss: 12.37728, val_acc: 0.76471\n",
            "Epoch [1580/10000], loss: 33.86427 acc: 0.27632 val_loss: 56.78949, val_acc: 0.82353\n",
            "Epoch [1590/10000], loss: 41.46869 acc: 0.75000 val_loss: 12.90039, val_acc: 0.78431\n",
            "Epoch [1600/10000], loss: 38.45184 acc: 0.26316 val_loss: 58.57597, val_acc: 0.82353\n",
            "Epoch [1610/10000], loss: 42.78505 acc: 0.75000 val_loss: 13.86696, val_acc: 0.78431\n",
            "Epoch [1620/10000], loss: 33.38168 acc: 0.27632 val_loss: 56.17948, val_acc: 0.82353\n",
            "Epoch [1630/10000], loss: 39.47029 acc: 0.75000 val_loss: 11.98586, val_acc: 0.76471\n",
            "Epoch [1640/10000], loss: 33.63293 acc: 0.27632 val_loss: 56.60376, val_acc: 0.82353\n",
            "Epoch [1650/10000], loss: 40.56794 acc: 0.75000 val_loss: 12.45922, val_acc: 0.76471\n",
            "Epoch [1660/10000], loss: 34.05745 acc: 0.27632 val_loss: 57.00654, val_acc: 0.82353\n",
            "Epoch [1670/10000], loss: 42.96064 acc: 0.75000 val_loss: 13.91322, val_acc: 0.82353\n",
            "Epoch [1680/10000], loss: 38.38920 acc: 0.26316 val_loss: 58.51325, val_acc: 0.82353\n",
            "Epoch [1690/10000], loss: 42.46725 acc: 0.75000 val_loss: 13.75598, val_acc: 0.78431\n",
            "Epoch [1700/10000], loss: 32.13961 acc: 0.28947 val_loss: 56.01106, val_acc: 0.82353\n",
            "Epoch [1710/10000], loss: 39.49535 acc: 0.75000 val_loss: 12.00856, val_acc: 0.76471\n",
            "Epoch [1720/10000], loss: 33.37746 acc: 0.27632 val_loss: 56.70591, val_acc: 0.82353\n",
            "Epoch [1730/10000], loss: 40.69649 acc: 0.75000 val_loss: 12.55782, val_acc: 0.76471\n",
            "Epoch [1740/10000], loss: 35.42336 acc: 0.25000 val_loss: 57.81374, val_acc: 0.82353\n",
            "Epoch [1750/10000], loss: 43.08596 acc: 0.75000 val_loss: 14.09461, val_acc: 0.82353\n",
            "Epoch [1760/10000], loss: 38.42448 acc: 0.26316 val_loss: 58.39408, val_acc: 0.82353\n",
            "Epoch [1770/10000], loss: 41.08505 acc: 0.75000 val_loss: 13.03475, val_acc: 0.76471\n",
            "Epoch [1780/10000], loss: 29.06106 acc: 0.28947 val_loss: 55.69969, val_acc: 0.82353\n",
            "Epoch [1790/10000], loss: 39.64902 acc: 0.75000 val_loss: 12.05710, val_acc: 0.76471\n",
            "Epoch [1800/10000], loss: 33.93541 acc: 0.26316 val_loss: 57.13316, val_acc: 0.82353\n",
            "Epoch [1810/10000], loss: 42.97062 acc: 0.75000 val_loss: 14.02401, val_acc: 0.82353\n",
            "Epoch [1820/10000], loss: 38.47248 acc: 0.26316 val_loss: 58.56359, val_acc: 0.82353\n",
            "Epoch [1830/10000], loss: 42.41522 acc: 0.75000 val_loss: 13.82196, val_acc: 0.78431\n",
            "Epoch [1840/10000], loss: 31.27076 acc: 0.28947 val_loss: 55.98304, val_acc: 0.82353\n",
            "Epoch [1850/10000], loss: 37.34834 acc: 0.75000 val_loss: 11.00143, val_acc: 0.74510\n",
            "Epoch [1860/10000], loss: 41.36738 acc: 0.75000 val_loss: 12.75563, val_acc: 0.78431\n",
            "Epoch [1870/10000], loss: 40.20937 acc: 0.26316 val_loss: 58.37228, val_acc: 0.82353\n",
            "Epoch [1880/10000], loss: 43.13209 acc: 0.75000 val_loss: 14.11739, val_acc: 0.82353\n",
            "Epoch [1890/10000], loss: 38.06698 acc: 0.26316 val_loss: 58.69464, val_acc: 0.82353\n",
            "Epoch [1900/10000], loss: 42.79420 acc: 0.75000 val_loss: 14.02343, val_acc: 0.80392\n",
            "Epoch [1910/10000], loss: 37.84957 acc: 0.25000 val_loss: 57.91228, val_acc: 0.82353\n",
            "Epoch [1920/10000], loss: 39.17881 acc: 0.75000 val_loss: 12.05826, val_acc: 0.76471\n",
            "Epoch [1930/10000], loss: 33.84036 acc: 0.75000 val_loss: 9.35339, val_acc: 0.70588\n",
            "Epoch [1940/10000], loss: 42.29676 acc: 0.75000 val_loss: 13.37615, val_acc: 0.82353\n",
            "Epoch [1950/10000], loss: 40.23837 acc: 0.26316 val_loss: 58.35810, val_acc: 0.82353\n",
            "Epoch [1960/10000], loss: 42.96426 acc: 0.75000 val_loss: 13.99735, val_acc: 0.82353\n",
            "Epoch [1970/10000], loss: 38.30994 acc: 0.26316 val_loss: 58.79440, val_acc: 0.82353\n",
            "Epoch [1980/10000], loss: 42.90638 acc: 0.75000 val_loss: 14.09516, val_acc: 0.80392\n",
            "Epoch [1990/10000], loss: 38.57061 acc: 0.26316 val_loss: 58.42707, val_acc: 0.82353\n",
            "Epoch [2000/10000], loss: 40.67938 acc: 0.75000 val_loss: 12.94291, val_acc: 0.76471\n",
            "Epoch [2010/10000], loss: 19.01642 acc: 0.35526 val_loss: 44.84088, val_acc: 0.82353\n",
            "Epoch [2020/10000], loss: 34.50307 acc: 0.25000 val_loss: 57.84697, val_acc: 0.82353\n",
            "Epoch [2030/10000], loss: 42.77436 acc: 0.75000 val_loss: 13.94763, val_acc: 0.80392\n",
            "Epoch [2040/10000], loss: 38.18817 acc: 0.26316 val_loss: 58.66157, val_acc: 0.82353\n",
            "Epoch [2050/10000], loss: 42.63354 acc: 0.75000 val_loss: 14.00988, val_acc: 0.78431\n",
            "Epoch [2060/10000], loss: 36.07878 acc: 0.27632 val_loss: 56.80471, val_acc: 0.82353\n",
            "Epoch [2070/10000], loss: 37.03648 acc: 0.75000 val_loss: 11.01958, val_acc: 0.74510\n",
            "Epoch [2080/10000], loss: 70.46820 acc: 0.75000 val_loss: 34.74274, val_acc: 0.82353\n",
            "Epoch [2090/10000], loss: 12.91783 acc: 0.73684 val_loss: 35.57388, val_acc: 0.25490\n",
            "Epoch [2100/10000], loss: 72.56218 acc: 0.75000 val_loss: 36.41398, val_acc: 0.82353\n",
            "Epoch [2110/10000], loss: 13.07122 acc: 0.73684 val_loss: 34.83119, val_acc: 0.27451\n",
            "Epoch [2120/10000], loss: 70.90169 acc: 0.75000 val_loss: 35.26310, val_acc: 0.82353\n",
            "Epoch [2130/10000], loss: 9.03123 acc: 0.72368 val_loss: 13.32071, val_acc: 0.54902\n",
            "Epoch [2140/10000], loss: 40.35369 acc: 0.75000 val_loss: 12.46462, val_acc: 0.76471\n",
            "Epoch [2150/10000], loss: 38.83294 acc: 0.26316 val_loss: 58.77963, val_acc: 0.82353\n",
            "Epoch [2160/10000], loss: 42.99736 acc: 0.75000 val_loss: 14.21939, val_acc: 0.80392\n",
            "Epoch [2170/10000], loss: 38.52649 acc: 0.26316 val_loss: 58.58911, val_acc: 0.82353\n",
            "Epoch [2180/10000], loss: 42.20946 acc: 0.75000 val_loss: 13.86679, val_acc: 0.78431\n",
            "Epoch [2190/10000], loss: 26.76808 acc: 0.30263 val_loss: 53.75751, val_acc: 0.82353\n",
            "Epoch [2200/10000], loss: 41.39308 acc: 0.75000 val_loss: 13.00986, val_acc: 0.78431\n",
            "Epoch [2210/10000], loss: 39.59030 acc: 0.26316 val_loss: 58.62369, val_acc: 0.82353\n",
            "Epoch [2220/10000], loss: 43.00108 acc: 0.75000 val_loss: 14.24509, val_acc: 0.80392\n",
            "Epoch [2230/10000], loss: 38.49224 acc: 0.26316 val_loss: 58.63511, val_acc: 0.82353\n",
            "Epoch [2240/10000], loss: 42.32730 acc: 0.75000 val_loss: 13.95728, val_acc: 0.78431\n",
            "Epoch [2250/10000], loss: 27.36516 acc: 0.31579 val_loss: 54.09738, val_acc: 0.82353\n",
            "Epoch [2260/10000], loss: 71.80410 acc: 0.75000 val_loss: 35.77398, val_acc: 0.82353\n",
            "Epoch [2270/10000], loss: 13.00520 acc: 0.73684 val_loss: 35.25774, val_acc: 0.23529\n",
            "Epoch [2280/10000], loss: 72.64805 acc: 0.75000 val_loss: 36.52783, val_acc: 0.82353\n",
            "Epoch [2290/10000], loss: 13.20621 acc: 0.73684 val_loss: 34.28048, val_acc: 0.27451\n",
            "Epoch [2300/10000], loss: 72.10464 acc: 0.75000 val_loss: 36.23046, val_acc: 0.82353\n",
            "Epoch [2310/10000], loss: 11.74752 acc: 0.72368 val_loss: 27.52366, val_acc: 0.29412\n",
            "Epoch [2320/10000], loss: 8.09404 acc: 0.60526 val_loss: 10.18679, val_acc: 0.74510\n",
            "Epoch [2330/10000], loss: 11.58945 acc: 0.73684 val_loss: 39.85247, val_acc: 0.19608\n",
            "Epoch [2340/10000], loss: 71.47389 acc: 0.75000 val_loss: 35.44174, val_acc: 0.82353\n",
            "Epoch [2350/10000], loss: 12.42539 acc: 0.73684 val_loss: 37.20786, val_acc: 0.17647\n",
            "Epoch [2360/10000], loss: 72.09965 acc: 0.75000 val_loss: 36.03350, val_acc: 0.82353\n",
            "Epoch [2370/10000], loss: 13.04123 acc: 0.73684 val_loss: 35.10801, val_acc: 0.23529\n",
            "Epoch [2380/10000], loss: 72.59658 acc: 0.75000 val_loss: 36.52768, val_acc: 0.82353\n",
            "Epoch [2390/10000], loss: 13.12439 acc: 0.73684 val_loss: 34.32691, val_acc: 0.27451\n",
            "Epoch [2400/10000], loss: 71.98739 acc: 0.75000 val_loss: 36.17996, val_acc: 0.82353\n",
            "Epoch [2410/10000], loss: 10.56564 acc: 0.69737 val_loss: 22.98339, val_acc: 0.33333\n",
            "Epoch [2420/10000], loss: 8.60862 acc: 0.60526 val_loss: 16.93531, val_acc: 0.82353\n",
            "Epoch [2430/10000], loss: 40.51803 acc: 0.26316 val_loss: 58.37508, val_acc: 0.82353\n",
            "Epoch [2440/10000], loss: 42.67743 acc: 0.75000 val_loss: 14.02100, val_acc: 0.80392\n",
            "Epoch [2450/10000], loss: 38.60468 acc: 0.26316 val_loss: 58.83146, val_acc: 0.82353\n",
            "Epoch [2460/10000], loss: 42.66167 acc: 0.75000 val_loss: 14.16510, val_acc: 0.80392\n",
            "Epoch [2470/10000], loss: 38.59776 acc: 0.26316 val_loss: 58.40055, val_acc: 0.82353\n",
            "Epoch [2480/10000], loss: 38.92523 acc: 0.75000 val_loss: 12.21618, val_acc: 0.76471\n",
            "Epoch [2490/10000], loss: 32.47283 acc: 0.27632 val_loss: 56.87858, val_acc: 0.82353\n",
            "Epoch [2500/10000], loss: 40.43345 acc: 0.75000 val_loss: 12.65622, val_acc: 0.76471\n",
            "Epoch [2510/10000], loss: 34.46579 acc: 0.25000 val_loss: 57.71719, val_acc: 0.82353\n",
            "Epoch [2520/10000], loss: 42.52613 acc: 0.75000 val_loss: 13.98571, val_acc: 0.80392\n",
            "Epoch [2530/10000], loss: 38.43625 acc: 0.26316 val_loss: 58.82586, val_acc: 0.82353\n",
            "Epoch [2540/10000], loss: 42.54320 acc: 0.75000 val_loss: 14.15699, val_acc: 0.80392\n",
            "Epoch [2550/10000], loss: 37.92598 acc: 0.25000 val_loss: 57.85644, val_acc: 0.82353\n",
            "Epoch [2560/10000], loss: 30.89017 acc: 0.75000 val_loss: 9.60863, val_acc: 0.68627\n",
            "Epoch [2570/10000], loss: 13.13061 acc: 0.73684 val_loss: 33.95504, val_acc: 0.27451\n",
            "Epoch [2580/10000], loss: 71.98071 acc: 0.75000 val_loss: 36.25313, val_acc: 0.82353\n",
            "Epoch [2590/10000], loss: 10.96665 acc: 0.69737 val_loss: 23.08055, val_acc: 0.33333\n",
            "Epoch [2600/10000], loss: 40.53498 acc: 0.26316 val_loss: 58.41304, val_acc: 0.82353\n",
            "Epoch [2610/10000], loss: 42.67117 acc: 0.75000 val_loss: 14.12258, val_acc: 0.80392\n",
            "Epoch [2620/10000], loss: 38.45037 acc: 0.26316 val_loss: 58.82767, val_acc: 0.82353\n",
            "Epoch [2630/10000], loss: 42.49229 acc: 0.75000 val_loss: 14.16292, val_acc: 0.80392\n",
            "Epoch [2640/10000], loss: 37.35247 acc: 0.25000 val_loss: 57.30829, val_acc: 0.82353\n",
            "Epoch [2650/10000], loss: 20.01685 acc: 0.36842 val_loss: 45.70779, val_acc: 0.82353\n",
            "Epoch [2660/10000], loss: 62.02715 acc: 0.75000 val_loss: 28.46113, val_acc: 0.82353\n",
            "Epoch [2670/10000], loss: 21.84627 acc: 0.75000 val_loss: 15.48963, val_acc: 0.43137\n",
            "Epoch [2680/10000], loss: 7.78715 acc: 0.63158 val_loss: 15.68323, val_acc: 0.82353\n",
            "Epoch [2690/10000], loss: 40.80683 acc: 0.25000 val_loss: 58.93702, val_acc: 0.82353\n",
            "Epoch [2700/10000], loss: 43.32309 acc: 0.75000 val_loss: 14.13243, val_acc: 0.82353\n",
            "Epoch [2710/10000], loss: 42.54537 acc: 0.26316 val_loss: 57.81285, val_acc: 0.82353\n",
            "Epoch [2720/10000], loss: 41.49832 acc: 0.75000 val_loss: 12.94314, val_acc: 0.80392\n",
            "Epoch [2730/10000], loss: 43.36666 acc: 0.26316 val_loss: 57.56698, val_acc: 0.82353\n",
            "Epoch [2740/10000], loss: 41.69100 acc: 0.75000 val_loss: 13.23961, val_acc: 0.80392\n",
            "Epoch [2750/10000], loss: 41.41313 acc: 0.26316 val_loss: 58.13562, val_acc: 0.82353\n",
            "Epoch [2760/10000], loss: 42.29518 acc: 0.75000 val_loss: 13.81334, val_acc: 0.80392\n",
            "Epoch [2770/10000], loss: 39.43965 acc: 0.26316 val_loss: 58.69612, val_acc: 0.82353\n",
            "Epoch [2780/10000], loss: 42.73624 acc: 0.75000 val_loss: 14.27580, val_acc: 0.80392\n",
            "Epoch [2790/10000], loss: 38.53248 acc: 0.26316 val_loss: 58.59383, val_acc: 0.82353\n",
            "Epoch [2800/10000], loss: 40.59531 acc: 0.75000 val_loss: 13.24566, val_acc: 0.76471\n",
            "Epoch [2810/10000], loss: 8.24856 acc: 0.69737 val_loss: 10.01976, val_acc: 0.64706\n",
            "Epoch [2820/10000], loss: 12.96033 acc: 0.75000 val_loss: 39.08767, val_acc: 0.17647\n",
            "Epoch [2830/10000], loss: 70.95496 acc: 0.75000 val_loss: 35.12862, val_acc: 0.82353\n",
            "Epoch [2840/10000], loss: 11.81597 acc: 0.73684 val_loss: 38.64768, val_acc: 0.19608\n",
            "Epoch [2850/10000], loss: 71.47183 acc: 0.75000 val_loss: 35.63968, val_acc: 0.82353\n",
            "Epoch [2860/10000], loss: 12.40771 acc: 0.73684 val_loss: 36.42974, val_acc: 0.19608\n",
            "Epoch [2870/10000], loss: 72.06765 acc: 0.75000 val_loss: 36.20915, val_acc: 0.82353\n",
            "Epoch [2880/10000], loss: 12.97048 acc: 0.73684 val_loss: 34.51320, val_acc: 0.27451\n",
            "Epoch [2890/10000], loss: 72.16162 acc: 0.75000 val_loss: 36.39775, val_acc: 0.82353\n",
            "Epoch [2900/10000], loss: 12.53207 acc: 0.73684 val_loss: 33.57821, val_acc: 0.27451\n",
            "Epoch [2910/10000], loss: 30.17438 acc: 0.75000 val_loss: 9.58523, val_acc: 0.64706\n",
            "Epoch [2920/10000], loss: 8.79465 acc: 0.71053 val_loss: 11.60484, val_acc: 0.58824\n",
            "Epoch [2930/10000], loss: 9.45702 acc: 0.60526 val_loss: 23.07098, val_acc: 0.82353\n",
            "Epoch [2940/10000], loss: 73.67683 acc: 0.75000 val_loss: 37.00526, val_acc: 0.82353\n",
            "Epoch [2950/10000], loss: 13.15384 acc: 0.75000 val_loss: 38.39808, val_acc: 0.17647\n",
            "Epoch [2960/10000], loss: 71.55218 acc: 0.75000 val_loss: 35.57026, val_acc: 0.82353\n",
            "Epoch [2970/10000], loss: 11.68193 acc: 0.73684 val_loss: 39.27639, val_acc: 0.17647\n",
            "Epoch [2980/10000], loss: 71.25974 acc: 0.75000 val_loss: 35.48703, val_acc: 0.82353\n",
            "Epoch [2990/10000], loss: 12.18862 acc: 0.73684 val_loss: 36.96949, val_acc: 0.17647\n",
            "Epoch [3000/10000], loss: 71.84686 acc: 0.75000 val_loss: 36.05027, val_acc: 0.82353\n",
            "Epoch [3010/10000], loss: 12.76945 acc: 0.73684 val_loss: 34.94149, val_acc: 0.23529\n",
            "Epoch [3020/10000], loss: 72.22272 acc: 0.75000 val_loss: 36.45285, val_acc: 0.82353\n",
            "Epoch [3030/10000], loss: 12.67575 acc: 0.73684 val_loss: 33.99744, val_acc: 0.27451\n",
            "Epoch [3040/10000], loss: 63.33056 acc: 0.75000 val_loss: 29.81572, val_acc: 0.82353\n",
            "Epoch [3050/10000], loss: 35.58078 acc: 0.75000 val_loss: 9.81974, val_acc: 0.76471\n",
            "Epoch [3060/10000], loss: 43.18451 acc: 0.75000 val_loss: 14.15426, val_acc: 0.82353\n",
            "Epoch [3070/10000], loss: 42.40378 acc: 0.26316 val_loss: 57.87733, val_acc: 0.82353\n",
            "Epoch [3080/10000], loss: 41.41939 acc: 0.75000 val_loss: 13.05097, val_acc: 0.80392\n",
            "Epoch [3090/10000], loss: 42.80710 acc: 0.26316 val_loss: 57.73237, val_acc: 0.82353\n",
            "Epoch [3100/10000], loss: 41.74411 acc: 0.75000 val_loss: 13.45065, val_acc: 0.78431\n",
            "Epoch [3110/10000], loss: 40.90038 acc: 0.26316 val_loss: 58.28948, val_acc: 0.82353\n",
            "Epoch [3120/10000], loss: 42.31171 acc: 0.75000 val_loss: 14.00008, val_acc: 0.78431\n",
            "Epoch [3130/10000], loss: 39.03807 acc: 0.26316 val_loss: 58.68010, val_acc: 0.82353\n",
            "Epoch [3140/10000], loss: 42.15422 acc: 0.75000 val_loss: 14.10253, val_acc: 0.78431\n",
            "Epoch [3150/10000], loss: 18.42372 acc: 0.40789 val_loss: 41.05752, val_acc: 0.82353\n",
            "Epoch [3160/10000], loss: 15.30568 acc: 0.75000 val_loss: 30.97552, val_acc: 0.27451\n",
            "Epoch [3170/10000], loss: 71.39480 acc: 0.75000 val_loss: 35.70060, val_acc: 0.82353\n",
            "Epoch [3180/10000], loss: 12.47082 acc: 0.73684 val_loss: 35.76495, val_acc: 0.21569\n",
            "Epoch [3190/10000], loss: 72.05865 acc: 0.75000 val_loss: 36.32046, val_acc: 0.82353\n",
            "Epoch [3200/10000], loss: 12.71679 acc: 0.73684 val_loss: 34.21888, val_acc: 0.27451\n",
            "Epoch [3210/10000], loss: 69.64806 acc: 0.75000 val_loss: 34.60660, val_acc: 0.82353\n",
            "Epoch [3220/10000], loss: 22.17018 acc: 0.75000 val_loss: 15.84044, val_acc: 0.52941\n",
            "Epoch [3230/10000], loss: 21.18370 acc: 0.75000 val_loss: 17.07704, val_acc: 0.43137\n",
            "Epoch [3240/10000], loss: 42.59048 acc: 0.75000 val_loss: 13.85526, val_acc: 0.82353\n",
            "Epoch [3250/10000], loss: 44.03038 acc: 0.26316 val_loss: 57.52653, val_acc: 0.82353\n",
            "Epoch [3260/10000], loss: 41.51456 acc: 0.75000 val_loss: 13.30958, val_acc: 0.78431\n",
            "Epoch [3270/10000], loss: 41.39780 acc: 0.26316 val_loss: 58.13721, val_acc: 0.82353\n",
            "Epoch [3280/10000], loss: 42.10754 acc: 0.75000 val_loss: 13.87531, val_acc: 0.78431\n",
            "Epoch [3290/10000], loss: 39.52801 acc: 0.26316 val_loss: 58.59596, val_acc: 0.82353\n",
            "Epoch [3300/10000], loss: 42.17382 acc: 0.75000 val_loss: 14.11662, val_acc: 0.78431\n",
            "Epoch [3310/10000], loss: 25.45494 acc: 0.30263 val_loss: 51.19275, val_acc: 0.82353\n",
            "Epoch [3320/10000], loss: 73.05135 acc: 0.75000 val_loss: 36.89355, val_acc: 0.82353\n",
            "Epoch [3330/10000], loss: 11.86226 acc: 0.73684 val_loss: 36.59488, val_acc: 0.19608\n",
            "Epoch [3340/10000], loss: 71.72474 acc: 0.75000 val_loss: 36.02692, val_acc: 0.82353\n",
            "Epoch [3350/10000], loss: 12.59553 acc: 0.73684 val_loss: 35.00937, val_acc: 0.21569\n",
            "Epoch [3360/10000], loss: 71.82087 acc: 0.75000 val_loss: 36.21731, val_acc: 0.82353\n",
            "Epoch [3370/10000], loss: 11.29226 acc: 0.69737 val_loss: 21.82166, val_acc: 0.35294\n",
            "Epoch [3380/10000], loss: 19.40848 acc: 0.40789 val_loss: 43.96618, val_acc: 0.82353\n",
            "Epoch [3390/10000], loss: 7.97019 acc: 0.65789 val_loss: 12.12111, val_acc: 0.78431\n",
            "Epoch [3400/10000], loss: 41.99776 acc: 0.26316 val_loss: 57.90599, val_acc: 0.82353\n",
            "Epoch [3410/10000], loss: 41.23274 acc: 0.75000 val_loss: 13.13469, val_acc: 0.78431\n",
            "Epoch [3420/10000], loss: 41.58264 acc: 0.26316 val_loss: 58.06610, val_acc: 0.82353\n",
            "Epoch [3430/10000], loss: 41.95245 acc: 0.75000 val_loss: 13.77773, val_acc: 0.78431\n",
            "Epoch [3440/10000], loss: 40.07136 acc: 0.26316 val_loss: 58.47897, val_acc: 0.82353\n",
            "Epoch [3450/10000], loss: 42.17252 acc: 0.75000 val_loss: 14.11528, val_acc: 0.78431\n",
            "Epoch [3460/10000], loss: 32.83379 acc: 0.27632 val_loss: 56.59651, val_acc: 0.82353\n",
            "Epoch [3470/10000], loss: 11.67712 acc: 0.57895 val_loss: 25.89231, val_acc: 0.82353\n",
            "Epoch [3480/10000], loss: 7.76045 acc: 0.64474 val_loss: 8.71695, val_acc: 0.68627\n",
            "Epoch [3490/10000], loss: 43.10600 acc: 0.75000 val_loss: 14.21963, val_acc: 0.82353\n",
            "Epoch [3500/10000], loss: 42.29243 acc: 0.26316 val_loss: 57.91988, val_acc: 0.82353\n",
            "Epoch [3510/10000], loss: 41.31646 acc: 0.75000 val_loss: 13.19432, val_acc: 0.78431\n",
            "Epoch [3520/10000], loss: 42.09736 acc: 0.26316 val_loss: 57.92443, val_acc: 0.82353\n",
            "Epoch [3530/10000], loss: 41.81646 acc: 0.75000 val_loss: 13.70783, val_acc: 0.78431\n",
            "Epoch [3540/10000], loss: 40.23826 acc: 0.26316 val_loss: 58.42374, val_acc: 0.82353\n",
            "Epoch [3550/10000], loss: 42.09540 acc: 0.75000 val_loss: 14.08136, val_acc: 0.78431\n",
            "Epoch [3560/10000], loss: 29.35629 acc: 0.28947 val_loss: 53.81000, val_acc: 0.82353\n",
            "Epoch [3570/10000], loss: 32.39485 acc: 0.75000 val_loss: 8.95757, val_acc: 0.68627\n",
            "Epoch [3580/10000], loss: 10.90368 acc: 0.75000 val_loss: 43.28384, val_acc: 0.17647\n",
            "Epoch [3590/10000], loss: 72.00477 acc: 0.75000 val_loss: 35.98935, val_acc: 0.82353\n",
            "Epoch [3600/10000], loss: 12.15533 acc: 0.75000 val_loss: 40.38818, val_acc: 0.17647\n",
            "Epoch [3610/10000], loss: 70.99921 acc: 0.75000 val_loss: 35.39117, val_acc: 0.82353\n",
            "Epoch [3620/10000], loss: 11.84085 acc: 0.73684 val_loss: 36.66586, val_acc: 0.19608\n",
            "Epoch [3630/10000], loss: 71.75018 acc: 0.75000 val_loss: 36.07965, val_acc: 0.82353\n",
            "Epoch [3640/10000], loss: 12.49524 acc: 0.73684 val_loss: 35.35408, val_acc: 0.21569\n",
            "Epoch [3650/10000], loss: 71.10183 acc: 0.75000 val_loss: 35.70569, val_acc: 0.82353\n",
            "Epoch [3660/10000], loss: 27.89551 acc: 0.30263 val_loss: 53.01672, val_acc: 0.82353\n",
            "Epoch [3670/10000], loss: 36.16944 acc: 0.27632 val_loss: 58.16848, val_acc: 0.82353\n",
            "Epoch [3680/10000], loss: 42.02638 acc: 0.75000 val_loss: 13.95959, val_acc: 0.78431\n",
            "Epoch [3690/10000], loss: 39.34790 acc: 0.26316 val_loss: 58.37740, val_acc: 0.82353\n",
            "Epoch [3700/10000], loss: 39.33620 acc: 0.75000 val_loss: 12.64878, val_acc: 0.76471\n",
            "Epoch [3710/10000], loss: 46.59184 acc: 0.75000 val_loss: 17.17155, val_acc: 0.82353\n",
            "Epoch [3720/10000], loss: 40.50004 acc: 0.75000 val_loss: 12.74455, val_acc: 0.78431\n",
            "Epoch [3730/10000], loss: 43.45728 acc: 0.26316 val_loss: 57.61310, val_acc: 0.82353\n",
            "Epoch [3740/10000], loss: 41.39333 acc: 0.75000 val_loss: 13.49128, val_acc: 0.78431\n",
            "Epoch [3750/10000], loss: 38.60944 acc: 0.26316 val_loss: 58.46069, val_acc: 0.82353\n",
            "Epoch [3760/10000], loss: 41.87233 acc: 0.75000 val_loss: 13.97797, val_acc: 0.78431\n",
            "Epoch [3770/10000], loss: 18.28621 acc: 0.42105 val_loss: 41.91404, val_acc: 0.82353\n",
            "Epoch [3780/10000], loss: 15.03699 acc: 0.44737 val_loss: 39.92670, val_acc: 0.82353\n",
            "Epoch [3790/10000], loss: 37.95403 acc: 0.26316 val_loss: 58.83187, val_acc: 0.82353\n",
            "Epoch [3800/10000], loss: 41.64311 acc: 0.75000 val_loss: 13.51104, val_acc: 0.78431\n",
            "Epoch [3810/10000], loss: 42.82297 acc: 0.26316 val_loss: 57.74597, val_acc: 0.82353\n",
            "Epoch [3820/10000], loss: 41.49147 acc: 0.75000 val_loss: 13.64057, val_acc: 0.78431\n",
            "Epoch [3830/10000], loss: 39.17037 acc: 0.26316 val_loss: 58.28624, val_acc: 0.82353\n",
            "Epoch [3840/10000], loss: 39.67572 acc: 0.75000 val_loss: 12.81138, val_acc: 0.76471\n",
            "Epoch [3850/10000], loss: 18.22003 acc: 0.42105 val_loss: 41.77393, val_acc: 0.82353\n",
            "Epoch [3860/10000], loss: 31.88631 acc: 0.75000 val_loss: 9.03685, val_acc: 0.68627\n",
            "Epoch [3870/10000], loss: 32.14466 acc: 0.75000 val_loss: 8.38186, val_acc: 0.68627\n",
            "Epoch [3880/10000], loss: 36.75149 acc: 0.26316 val_loss: 59.16126, val_acc: 0.82353\n",
            "Epoch [3890/10000], loss: 43.19121 acc: 0.75000 val_loss: 14.27593, val_acc: 0.82353\n",
            "Epoch [3900/10000], loss: 41.94056 acc: 0.25000 val_loss: 58.92445, val_acc: 0.82353\n",
            "Epoch [3910/10000], loss: 42.62788 acc: 0.75000 val_loss: 14.05420, val_acc: 0.80392\n",
            "Epoch [3920/10000], loss: 43.44288 acc: 0.26316 val_loss: 57.71650, val_acc: 0.82353\n",
            "Epoch [3930/10000], loss: 41.28555 acc: 0.75000 val_loss: 13.47037, val_acc: 0.78431\n",
            "Epoch [3940/10000], loss: 38.55980 acc: 0.27632 val_loss: 58.18295, val_acc: 0.82353\n",
            "Epoch [3950/10000], loss: 41.33619 acc: 0.75000 val_loss: 13.67897, val_acc: 0.78431\n",
            "Epoch [3960/10000], loss: 58.57441 acc: 0.75000 val_loss: 26.19176, val_acc: 0.82353\n",
            "Epoch [3970/10000], loss: 37.19170 acc: 0.75000 val_loss: 11.22707, val_acc: 0.76471\n",
            "Epoch [3980/10000], loss: 12.88023 acc: 0.75000 val_loss: 38.09825, val_acc: 0.17647\n",
            "Epoch [3990/10000], loss: 71.34103 acc: 0.75000 val_loss: 35.68323, val_acc: 0.82353\n",
            "Epoch [4000/10000], loss: 12.36193 acc: 0.75000 val_loss: 38.41340, val_acc: 0.17647\n",
            "Epoch [4010/10000], loss: 71.47010 acc: 0.75000 val_loss: 35.90275, val_acc: 0.82353\n",
            "Epoch [4020/10000], loss: 11.97769 acc: 0.72368 val_loss: 32.11737, val_acc: 0.27451\n",
            "Epoch [4030/10000], loss: 8.86692 acc: 0.71053 val_loss: 10.92397, val_acc: 0.60784\n",
            "Epoch [4040/10000], loss: 20.81639 acc: 0.75000 val_loss: 17.47962, val_acc: 0.43137\n",
            "Epoch [4050/10000], loss: 9.99533 acc: 0.59211 val_loss: 21.38868, val_acc: 0.82353\n",
            "Epoch [4060/10000], loss: 24.69011 acc: 0.75000 val_loss: 11.50936, val_acc: 0.56863\n",
            "Epoch [4070/10000], loss: 42.48360 acc: 0.75000 val_loss: 13.58553, val_acc: 0.82353\n",
            "Epoch [4080/10000], loss: 37.39846 acc: 0.26316 val_loss: 59.32927, val_acc: 0.82353\n",
            "Epoch [4090/10000], loss: 43.27901 acc: 0.75000 val_loss: 14.35983, val_acc: 0.82353\n",
            "Epoch [4100/10000], loss: 41.77576 acc: 0.25000 val_loss: 58.96380, val_acc: 0.82353\n",
            "Epoch [4110/10000], loss: 42.65134 acc: 0.75000 val_loss: 14.11886, val_acc: 0.80392\n",
            "Epoch [4120/10000], loss: 43.14176 acc: 0.26316 val_loss: 57.74949, val_acc: 0.82353\n",
            "Epoch [4130/10000], loss: 41.31265 acc: 0.75000 val_loss: 13.54478, val_acc: 0.78431\n",
            "Epoch [4140/10000], loss: 31.96264 acc: 0.27632 val_loss: 56.36105, val_acc: 0.82353\n",
            "Epoch [4150/10000], loss: 8.99922 acc: 0.71053 val_loss: 11.11268, val_acc: 0.60784\n",
            "Epoch [4160/10000], loss: 63.81549 acc: 0.75000 val_loss: 29.92764, val_acc: 0.82353\n",
            "Epoch [4170/10000], loss: 48.57608 acc: 0.75000 val_loss: 18.33123, val_acc: 0.82353\n",
            "Epoch [4180/10000], loss: 29.60834 acc: 0.75000 val_loss: 8.48384, val_acc: 0.66667\n",
            "Epoch [4190/10000], loss: 14.12316 acc: 0.75000 val_loss: 34.74247, val_acc: 0.19608\n",
            "Epoch [4200/10000], loss: 73.54086 acc: 0.75000 val_loss: 37.13160, val_acc: 0.82353\n",
            "Epoch [4210/10000], loss: 13.71003 acc: 0.75000 val_loss: 35.66709, val_acc: 0.19608\n",
            "Epoch [4220/10000], loss: 71.61005 acc: 0.75000 val_loss: 35.84351, val_acc: 0.82353\n",
            "Epoch [4230/10000], loss: 11.83723 acc: 0.75000 val_loss: 37.21805, val_acc: 0.19608\n",
            "Epoch [4240/10000], loss: 71.24112 acc: 0.75000 val_loss: 35.70570, val_acc: 0.82353\n",
            "Epoch [4250/10000], loss: 11.18543 acc: 0.71053 val_loss: 24.49844, val_acc: 0.35294\n",
            "Epoch [4260/10000], loss: 11.84123 acc: 0.75000 val_loss: 37.09170, val_acc: 0.19608\n",
            "Epoch [4270/10000], loss: 71.21803 acc: 0.75000 val_loss: 35.70029, val_acc: 0.82353\n",
            "Epoch [4280/10000], loss: 11.18235 acc: 0.71053 val_loss: 24.34671, val_acc: 0.35294\n",
            "Epoch [4290/10000], loss: 12.17877 acc: 0.75000 val_loss: 38.82724, val_acc: 0.17647\n",
            "Epoch [4300/10000], loss: 71.15627 acc: 0.75000 val_loss: 35.65377, val_acc: 0.82353\n",
            "Epoch [4310/10000], loss: 11.21156 acc: 0.72368 val_loss: 24.99254, val_acc: 0.33333\n",
            "Epoch [4320/10000], loss: 11.16776 acc: 0.73684 val_loss: 29.54103, val_acc: 0.27451\n",
            "Epoch [4330/10000], loss: 71.07619 acc: 0.75000 val_loss: 35.58514, val_acc: 0.82353\n",
            "Epoch [4340/10000], loss: 11.85807 acc: 0.72368 val_loss: 33.29256, val_acc: 0.21569\n",
            "Epoch [4350/10000], loss: 49.29168 acc: 0.75000 val_loss: 19.21657, val_acc: 0.82353\n",
            "Epoch [4360/10000], loss: 9.70068 acc: 0.71053 val_loss: 12.27016, val_acc: 0.54902\n",
            "Epoch [4370/10000], loss: 8.10710 acc: 0.67105 val_loss: 11.54223, val_acc: 0.76471\n",
            "Epoch [4380/10000], loss: 17.45059 acc: 0.75000 val_loss: 24.80027, val_acc: 0.31373\n",
            "Epoch [4390/10000], loss: 13.22999 acc: 0.43421 val_loss: 39.20995, val_acc: 0.82353\n",
            "Epoch [4400/10000], loss: 13.63698 acc: 0.75000 val_loss: 36.40128, val_acc: 0.21569\n",
            "Epoch [4410/10000], loss: 73.27370 acc: 0.75000 val_loss: 36.91014, val_acc: 0.82353\n",
            "Epoch [4420/10000], loss: 13.28120 acc: 0.75000 val_loss: 37.10683, val_acc: 0.19608\n",
            "Epoch [4430/10000], loss: 72.69287 acc: 0.75000 val_loss: 36.64356, val_acc: 0.82353\n",
            "Epoch [4440/10000], loss: 12.74546 acc: 0.75000 val_loss: 38.27565, val_acc: 0.19608\n",
            "Epoch [4450/10000], loss: 71.14594 acc: 0.75000 val_loss: 35.62613, val_acc: 0.82353\n",
            "Epoch [4460/10000], loss: 11.15439 acc: 0.72368 val_loss: 24.68259, val_acc: 0.33333\n",
            "Epoch [4470/10000], loss: 12.27357 acc: 0.75000 val_loss: 38.78578, val_acc: 0.19608\n",
            "Epoch [4480/10000], loss: 71.04813 acc: 0.75000 val_loss: 35.57354, val_acc: 0.82353\n",
            "Epoch [4490/10000], loss: 10.88855 acc: 0.72368 val_loss: 20.38514, val_acc: 0.41176\n",
            "Epoch [4500/10000], loss: 8.19907 acc: 0.68421 val_loss: 10.88490, val_acc: 0.76471\n",
            "Epoch [4510/10000], loss: 43.74980 acc: 0.75000 val_loss: 14.76317, val_acc: 0.82353\n",
            "Epoch [4520/10000], loss: 39.20169 acc: 0.26316 val_loss: 58.44978, val_acc: 0.82353\n",
            "Epoch [4530/10000], loss: 41.98593 acc: 0.75000 val_loss: 13.81438, val_acc: 0.78431\n",
            "Epoch [4540/10000], loss: 41.17454 acc: 0.26316 val_loss: 57.92846, val_acc: 0.82353\n",
            "Epoch [4550/10000], loss: 41.18350 acc: 0.75000 val_loss: 13.56069, val_acc: 0.78431\n",
            "Epoch [4560/10000], loss: 9.10849 acc: 0.64474 val_loss: 14.99676, val_acc: 0.80392\n",
            "Epoch [4570/10000], loss: 40.73780 acc: 0.26316 val_loss: 57.95252, val_acc: 0.82353\n",
            "Epoch [4580/10000], loss: 41.02955 acc: 0.75000 val_loss: 13.48672, val_acc: 0.78431\n",
            "Epoch [4590/10000], loss: 20.50559 acc: 0.75000 val_loss: 18.57725, val_acc: 0.41176\n",
            "Epoch [4600/10000], loss: 64.38043 acc: 0.75000 val_loss: 30.34458, val_acc: 0.82353\n",
            "Epoch [4610/10000], loss: 14.80396 acc: 0.75000 val_loss: 32.54306, val_acc: 0.19608\n",
            "Epoch [4620/10000], loss: 73.08614 acc: 0.75000 val_loss: 36.80930, val_acc: 0.82353\n",
            "Epoch [4630/10000], loss: 13.03166 acc: 0.75000 val_loss: 37.76300, val_acc: 0.19608\n",
            "Epoch [4640/10000], loss: 72.68362 acc: 0.75000 val_loss: 36.67799, val_acc: 0.82353\n",
            "Epoch [4650/10000], loss: 12.59777 acc: 0.75000 val_loss: 38.35980, val_acc: 0.19608\n",
            "Epoch [4660/10000], loss: 70.86428 acc: 0.75000 val_loss: 35.44879, val_acc: 0.82353\n",
            "Epoch [4670/10000], loss: 8.43093 acc: 0.67105 val_loss: 10.24087, val_acc: 0.76471\n",
            "Epoch [4680/10000], loss: 15.65152 acc: 0.44737 val_loss: 40.41934, val_acc: 0.82353\n",
            "Epoch [4690/10000], loss: 67.47107 acc: 0.75000 val_loss: 32.51508, val_acc: 0.82353\n",
            "Epoch [4700/10000], loss: 9.60297 acc: 0.61842 val_loss: 20.51623, val_acc: 0.82353\n",
            "Epoch [4710/10000], loss: 43.97560 acc: 0.25000 val_loss: 58.53600, val_acc: 0.82353\n",
            "Epoch [4720/10000], loss: 44.76421 acc: 0.75000 val_loss: 15.35495, val_acc: 0.82353\n",
            "Epoch [4730/10000], loss: 36.81810 acc: 0.25000 val_loss: 59.48385, val_acc: 0.82353\n",
            "Epoch [4740/10000], loss: 43.27237 acc: 0.75000 val_loss: 14.42763, val_acc: 0.80392\n",
            "Epoch [4750/10000], loss: 42.28698 acc: 0.25000 val_loss: 59.10106, val_acc: 0.82353\n",
            "Epoch [4760/10000], loss: 42.92471 acc: 0.75000 val_loss: 14.43012, val_acc: 0.80392\n",
            "Epoch [4770/10000], loss: 41.45547 acc: 0.26316 val_loss: 57.81781, val_acc: 0.82353\n",
            "Epoch [4780/10000], loss: 40.56808 acc: 0.75000 val_loss: 13.20766, val_acc: 0.78431\n",
            "Epoch [4790/10000], loss: 61.14015 acc: 0.75000 val_loss: 27.95959, val_acc: 0.82353\n",
            "Epoch [4800/10000], loss: 7.81129 acc: 0.67105 val_loss: 9.00280, val_acc: 0.76471\n",
            "Epoch [4810/10000], loss: 33.17540 acc: 0.75000 val_loss: 8.66303, val_acc: 0.76471\n",
            "Epoch [4820/10000], loss: 43.39495 acc: 0.75000 val_loss: 14.36232, val_acc: 0.82353\n",
            "Epoch [4830/10000], loss: 37.64112 acc: 0.25000 val_loss: 59.40573, val_acc: 0.82353\n",
            "Epoch [4840/10000], loss: 43.53713 acc: 0.75000 val_loss: 14.66921, val_acc: 0.80392\n",
            "Epoch [4850/10000], loss: 39.34544 acc: 0.26316 val_loss: 58.12658, val_acc: 0.82353\n",
            "Epoch [4860/10000], loss: 41.58935 acc: 0.75000 val_loss: 13.67879, val_acc: 0.78431\n",
            "Epoch [4870/10000], loss: 37.78125 acc: 0.27632 val_loss: 57.51926, val_acc: 0.82353\n",
            "Epoch [4880/10000], loss: 39.75824 acc: 0.75000 val_loss: 12.76021, val_acc: 0.76471\n",
            "Epoch [4890/10000], loss: 8.40806 acc: 0.69737 val_loss: 9.73882, val_acc: 0.64706\n",
            "Epoch [4900/10000], loss: 64.85827 acc: 0.75000 val_loss: 30.62308, val_acc: 0.82353\n",
            "Epoch [4910/10000], loss: 29.81492 acc: 0.75000 val_loss: 8.56840, val_acc: 0.66667\n",
            "Epoch [4920/10000], loss: 14.50425 acc: 0.75000 val_loss: 33.64984, val_acc: 0.19608\n",
            "Epoch [4930/10000], loss: 73.69083 acc: 0.75000 val_loss: 37.27835, val_acc: 0.82353\n",
            "Epoch [4940/10000], loss: 13.62962 acc: 0.75000 val_loss: 36.02790, val_acc: 0.19608\n",
            "Epoch [4950/10000], loss: 71.31065 acc: 0.75000 val_loss: 35.65308, val_acc: 0.82353\n",
            "Epoch [4960/10000], loss: 12.02398 acc: 0.73684 val_loss: 37.22478, val_acc: 0.19608\n",
            "Epoch [4970/10000], loss: 61.47972 acc: 0.75000 val_loss: 28.34957, val_acc: 0.82353\n",
            "Epoch [4980/10000], loss: 49.83244 acc: 0.75000 val_loss: 19.29873, val_acc: 0.82353\n",
            "Epoch [4990/10000], loss: 13.70691 acc: 0.75000 val_loss: 36.08742, val_acc: 0.19608\n",
            "Epoch [5000/10000], loss: 72.98700 acc: 0.75000 val_loss: 36.79636, val_acc: 0.82353\n",
            "Epoch [5010/10000], loss: 13.50835 acc: 0.75000 val_loss: 36.32538, val_acc: 0.19608\n",
            "Epoch [5020/10000], loss: 71.08228 acc: 0.75000 val_loss: 35.52613, val_acc: 0.82353\n",
            "Epoch [5030/10000], loss: 11.01219 acc: 0.71053 val_loss: 24.14503, val_acc: 0.33333\n",
            "Epoch [5040/10000], loss: 13.12817 acc: 0.75000 val_loss: 37.63960, val_acc: 0.19608\n",
            "Epoch [5050/10000], loss: 72.63193 acc: 0.75000 val_loss: 36.63523, val_acc: 0.82353\n",
            "Epoch [5060/10000], loss: 11.68044 acc: 0.73684 val_loss: 35.76904, val_acc: 0.19608\n",
            "Epoch [5070/10000], loss: 61.59671 acc: 0.75000 val_loss: 28.41773, val_acc: 0.82353\n",
            "Epoch [5080/10000], loss: 42.16938 acc: 0.75000 val_loss: 13.83095, val_acc: 0.78431\n",
            "Epoch [5090/10000], loss: 42.46595 acc: 0.25000 val_loss: 58.88833, val_acc: 0.82353\n",
            "Epoch [5100/10000], loss: 41.08075 acc: 0.75000 val_loss: 13.43990, val_acc: 0.78431\n",
            "Epoch [5110/10000], loss: 9.72443 acc: 0.60526 val_loss: 17.65772, val_acc: 0.82353\n",
            "Epoch [5120/10000], loss: 36.69817 acc: 0.75000 val_loss: 10.70832, val_acc: 0.76471\n",
            "Epoch [5130/10000], loss: 39.44612 acc: 0.25000 val_loss: 59.59254, val_acc: 0.82353\n",
            "Epoch [5140/10000], loss: 43.23452 acc: 0.75000 val_loss: 14.52714, val_acc: 0.80392\n",
            "Epoch [5150/10000], loss: 40.11635 acc: 0.26316 val_loss: 58.00203, val_acc: 0.82353\n",
            "Epoch [5160/10000], loss: 41.61452 acc: 0.75000 val_loss: 13.76866, val_acc: 0.78431\n",
            "Epoch [5170/10000], loss: 28.71721 acc: 0.30263 val_loss: 51.80665, val_acc: 0.82353\n",
            "Epoch [5180/10000], loss: 36.10946 acc: 0.28947 val_loss: 57.41224, val_acc: 0.82353\n",
            "Epoch [5190/10000], loss: 40.69059 acc: 0.75000 val_loss: 13.18090, val_acc: 0.78431\n",
            "Epoch [5200/10000], loss: 56.18349 acc: 0.75000 val_loss: 24.27876, val_acc: 0.82353\n",
            "Epoch [5210/10000], loss: 13.66242 acc: 0.75000 val_loss: 35.80494, val_acc: 0.19608\n",
            "Epoch [5220/10000], loss: 71.02408 acc: 0.75000 val_loss: 35.47992, val_acc: 0.82353\n",
            "Epoch [5230/10000], loss: 11.11358 acc: 0.72368 val_loss: 26.08768, val_acc: 0.31373\n",
            "Epoch [5240/10000], loss: 8.11171 acc: 0.67105 val_loss: 9.08011, val_acc: 0.68627\n",
            "Epoch [5250/10000], loss: 9.83795 acc: 0.73684 val_loss: 19.17995, val_acc: 0.43137\n",
            "Epoch [5260/10000], loss: 43.83067 acc: 0.25000 val_loss: 58.63049, val_acc: 0.82353\n",
            "Epoch [5270/10000], loss: 43.63465 acc: 0.75000 val_loss: 14.74863, val_acc: 0.80392\n",
            "Epoch [5280/10000], loss: 38.91174 acc: 0.27632 val_loss: 58.12423, val_acc: 0.82353\n",
            "Epoch [5290/10000], loss: 41.51502 acc: 0.75000 val_loss: 13.64636, val_acc: 0.78431\n",
            "Epoch [5300/10000], loss: 35.18011 acc: 0.28947 val_loss: 57.22702, val_acc: 0.82353\n",
            "Epoch [5310/10000], loss: 17.82701 acc: 0.75000 val_loss: 24.21930, val_acc: 0.35294\n",
            "Epoch [5320/10000], loss: 8.50349 acc: 0.68421 val_loss: 10.69540, val_acc: 0.58824\n",
            "Epoch [5330/10000], loss: 33.18792 acc: 0.75000 val_loss: 8.73059, val_acc: 0.76471\n",
            "Epoch [5340/10000], loss: 44.49761 acc: 0.75000 val_loss: 15.20520, val_acc: 0.82353\n",
            "Epoch [5350/10000], loss: 37.01467 acc: 0.26316 val_loss: 59.05446, val_acc: 0.82353\n",
            "Epoch [5360/10000], loss: 42.37560 acc: 0.75000 val_loss: 13.94041, val_acc: 0.80392\n",
            "Epoch [5370/10000], loss: 41.70554 acc: 0.25000 val_loss: 59.03197, val_acc: 0.82353\n",
            "Epoch [5380/10000], loss: 41.14996 acc: 0.75000 val_loss: 13.46145, val_acc: 0.78431\n",
            "Epoch [5390/10000], loss: 29.24128 acc: 0.30263 val_loss: 52.43686, val_acc: 0.82353\n",
            "Epoch [5400/10000], loss: 8.81431 acc: 0.61842 val_loss: 15.45199, val_acc: 0.82353\n",
            "Epoch [5410/10000], loss: 39.93517 acc: 0.25000 val_loss: 58.61234, val_acc: 0.82353\n",
            "Epoch [5420/10000], loss: 41.46253 acc: 0.75000 val_loss: 13.65247, val_acc: 0.78431\n",
            "Epoch [5430/10000], loss: 27.60191 acc: 0.32895 val_loss: 50.76273, val_acc: 0.82353\n",
            "Epoch [5440/10000], loss: 73.22195 acc: 0.75000 val_loss: 37.01405, val_acc: 0.82353\n",
            "Epoch [5450/10000], loss: 13.39332 acc: 0.75000 val_loss: 36.65234, val_acc: 0.19608\n",
            "Epoch [5460/10000], loss: 70.81223 acc: 0.75000 val_loss: 35.35170, val_acc: 0.82353\n",
            "Epoch [5470/10000], loss: 8.47434 acc: 0.67105 val_loss: 11.96949, val_acc: 0.76471\n",
            "Epoch [5480/10000], loss: 70.94972 acc: 0.75000 val_loss: 35.38839, val_acc: 0.82353\n",
            "Epoch [5490/10000], loss: 11.47693 acc: 0.73684 val_loss: 33.07560, val_acc: 0.17647\n",
            "Epoch [5500/10000], loss: 17.67512 acc: 0.75000 val_loss: 24.62233, val_acc: 0.35294\n",
            "Epoch [5510/10000], loss: 9.84560 acc: 0.71053 val_loss: 17.05547, val_acc: 0.43137\n",
            "Epoch [5520/10000], loss: 25.31051 acc: 0.31579 val_loss: 51.45202, val_acc: 0.82353\n",
            "Epoch [5530/10000], loss: 36.95406 acc: 0.26316 val_loss: 59.50019, val_acc: 0.82353\n",
            "Epoch [5540/10000], loss: 43.54691 acc: 0.75000 val_loss: 14.71503, val_acc: 0.80392\n",
            "Epoch [5550/10000], loss: 39.81889 acc: 0.26316 val_loss: 58.80841, val_acc: 0.82353\n",
            "Epoch [5560/10000], loss: 42.15858 acc: 0.75000 val_loss: 14.07154, val_acc: 0.78431\n",
            "Epoch [5570/10000], loss: 35.34797 acc: 0.28947 val_loss: 57.12932, val_acc: 0.82353\n",
            "Epoch [5580/10000], loss: 52.86446 acc: 0.75000 val_loss: 21.79616, val_acc: 0.82353\n",
            "Epoch [5590/10000], loss: 11.24578 acc: 0.72368 val_loss: 34.11198, val_acc: 0.17647\n",
            "Epoch [5600/10000], loss: 72.25607 acc: 0.75000 val_loss: 36.34885, val_acc: 0.82353\n",
            "Epoch [5610/10000], loss: 11.94854 acc: 0.73684 val_loss: 36.56718, val_acc: 0.19608\n",
            "Epoch [5620/10000], loss: 60.78165 acc: 0.75000 val_loss: 27.81279, val_acc: 0.82353\n",
            "Epoch [5630/10000], loss: 41.32356 acc: 0.75000 val_loss: 13.31686, val_acc: 0.78431\n",
            "Epoch [5640/10000], loss: 41.95649 acc: 0.25000 val_loss: 59.04327, val_acc: 0.82353\n",
            "Epoch [5650/10000], loss: 41.68925 acc: 0.75000 val_loss: 13.81284, val_acc: 0.78431\n",
            "Epoch [5660/10000], loss: 26.20334 acc: 0.32895 val_loss: 50.49767, val_acc: 0.82353\n",
            "Epoch [5670/10000], loss: 38.33389 acc: 0.75000 val_loss: 11.75258, val_acc: 0.76471\n",
            "Epoch [5680/10000], loss: 71.49426 acc: 0.75000 val_loss: 35.76217, val_acc: 0.82353\n",
            "Epoch [5690/10000], loss: 11.85347 acc: 0.73684 val_loss: 36.00945, val_acc: 0.19608\n",
            "Epoch [5700/10000], loss: 61.29319 acc: 0.75000 val_loss: 28.18589, val_acc: 0.82353\n",
            "Epoch [5710/10000], loss: 8.14080 acc: 0.69737 val_loss: 9.59783, val_acc: 0.64706\n",
            "Epoch [5720/10000], loss: 32.60236 acc: 0.75000 val_loss: 8.75792, val_acc: 0.68627\n",
            "Epoch [5730/10000], loss: 72.72422 acc: 0.75000 val_loss: 36.33842, val_acc: 0.82353\n",
            "Epoch [5740/10000], loss: 14.72780 acc: 0.75000 val_loss: 33.26122, val_acc: 0.19608\n",
            "Epoch [5750/10000], loss: 73.26284 acc: 0.75000 val_loss: 36.92433, val_acc: 0.82353\n",
            "Epoch [5760/10000], loss: 13.49578 acc: 0.75000 val_loss: 36.73934, val_acc: 0.19608\n",
            "Epoch [5770/10000], loss: 72.41001 acc: 0.75000 val_loss: 36.45798, val_acc: 0.82353\n",
            "Epoch [5780/10000], loss: 11.66996 acc: 0.73684 val_loss: 34.06892, val_acc: 0.17647\n",
            "Epoch [5790/10000], loss: 15.94272 acc: 0.44737 val_loss: 39.94672, val_acc: 0.82353\n",
            "Epoch [5800/10000], loss: 50.74465 acc: 0.75000 val_loss: 19.99238, val_acc: 0.82353\n",
            "Epoch [5810/10000], loss: 31.16509 acc: 0.75000 val_loss: 8.66576, val_acc: 0.66667\n",
            "Epoch [5820/10000], loss: 7.60869 acc: 0.69737 val_loss: 9.87659, val_acc: 0.74510\n",
            "Epoch [5830/10000], loss: 20.23527 acc: 0.75000 val_loss: 18.73204, val_acc: 0.43137\n",
            "Epoch [5840/10000], loss: 43.43360 acc: 0.25000 val_loss: 58.42664, val_acc: 0.82353\n",
            "Epoch [5850/10000], loss: 44.86288 acc: 0.75000 val_loss: 15.21491, val_acc: 0.82353\n",
            "Epoch [5860/10000], loss: 35.63852 acc: 0.26316 val_loss: 59.65203, val_acc: 0.82353\n",
            "Epoch [5870/10000], loss: 44.23880 acc: 0.75000 val_loss: 14.93592, val_acc: 0.82353\n",
            "Epoch [5880/10000], loss: 37.73242 acc: 0.26316 val_loss: 59.21877, val_acc: 0.82353\n",
            "Epoch [5890/10000], loss: 43.28600 acc: 0.75000 val_loss: 14.50907, val_acc: 0.80392\n",
            "Epoch [5900/10000], loss: 40.47913 acc: 0.26316 val_loss: 58.60147, val_acc: 0.82353\n",
            "Epoch [5910/10000], loss: 42.07221 acc: 0.75000 val_loss: 14.00005, val_acc: 0.78431\n",
            "Epoch [5920/10000], loss: 24.45455 acc: 0.32895 val_loss: 50.01341, val_acc: 0.82353\n",
            "Epoch [5930/10000], loss: 69.41599 acc: 0.75000 val_loss: 34.21367, val_acc: 0.82353\n",
            "Epoch [5940/10000], loss: 22.92666 acc: 0.75000 val_loss: 14.84757, val_acc: 0.49020\n",
            "Epoch [5950/10000], loss: 25.73228 acc: 0.75000 val_loss: 11.31764, val_acc: 0.60784\n",
            "Epoch [5960/10000], loss: 33.62616 acc: 0.75000 val_loss: 8.86099, val_acc: 0.76471\n",
            "Epoch [5970/10000], loss: 34.94175 acc: 0.75000 val_loss: 9.28195, val_acc: 0.74510\n",
            "Epoch [5980/10000], loss: 14.17815 acc: 0.75000 val_loss: 35.87186, val_acc: 0.21569\n",
            "Epoch [5990/10000], loss: 74.09187 acc: 0.75000 val_loss: 37.28017, val_acc: 0.82353\n",
            "Epoch [6000/10000], loss: 14.46260 acc: 0.75000 val_loss: 34.54836, val_acc: 0.19608\n",
            "Epoch [6010/10000], loss: 73.24707 acc: 0.75000 val_loss: 36.82254, val_acc: 0.82353\n",
            "Epoch [6020/10000], loss: 13.52159 acc: 0.75000 val_loss: 37.11571, val_acc: 0.19608\n",
            "Epoch [6030/10000], loss: 72.20598 acc: 0.75000 val_loss: 36.21539, val_acc: 0.82353\n",
            "Epoch [6040/10000], loss: 12.25711 acc: 0.75000 val_loss: 38.21246, val_acc: 0.19608\n",
            "Epoch [6050/10000], loss: 50.57088 acc: 0.75000 val_loss: 20.01269, val_acc: 0.82353\n",
            "Epoch [6060/10000], loss: 23.09656 acc: 0.75000 val_loss: 14.70691, val_acc: 0.49020\n",
            "Epoch [6070/10000], loss: 33.92226 acc: 0.28947 val_loss: 56.89517, val_acc: 0.82353\n",
            "Epoch [6080/10000], loss: 41.82909 acc: 0.75000 val_loss: 13.62565, val_acc: 0.78431\n",
            "Epoch [6090/10000], loss: 41.43580 acc: 0.26316 val_loss: 58.43487, val_acc: 0.82353\n",
            "Epoch [6100/10000], loss: 40.78015 acc: 0.75000 val_loss: 13.27372, val_acc: 0.78431\n",
            "Epoch [6110/10000], loss: 68.82059 acc: 0.75000 val_loss: 33.72381, val_acc: 0.82353\n",
            "Epoch [6120/10000], loss: 28.61469 acc: 0.75000 val_loss: 9.68165, val_acc: 0.64706\n",
            "Epoch [6130/10000], loss: 64.70355 acc: 0.75000 val_loss: 30.40362, val_acc: 0.82353\n",
            "Epoch [6140/10000], loss: 43.89831 acc: 0.75000 val_loss: 14.72963, val_acc: 0.80392\n",
            "Epoch [6150/10000], loss: 38.66531 acc: 0.26316 val_loss: 58.97042, val_acc: 0.82353\n",
            "Epoch [6160/10000], loss: 42.94756 acc: 0.75000 val_loss: 14.32362, val_acc: 0.80392\n",
            "Epoch [6170/10000], loss: 41.16096 acc: 0.26316 val_loss: 58.34783, val_acc: 0.82353\n",
            "Epoch [6180/10000], loss: 40.74599 acc: 0.75000 val_loss: 13.24071, val_acc: 0.78431\n",
            "Epoch [6190/10000], loss: 20.17805 acc: 0.75000 val_loss: 19.73570, val_acc: 0.41176\n",
            "Epoch [6200/10000], loss: 17.43265 acc: 0.75000 val_loss: 25.47919, val_acc: 0.33333\n",
            "Epoch [6210/10000], loss: 67.69521 acc: 0.75000 val_loss: 32.54111, val_acc: 0.82353\n",
            "Epoch [6220/10000], loss: 42.31657 acc: 0.75000 val_loss: 13.57235, val_acc: 0.80392\n",
            "Epoch [6230/10000], loss: 37.94734 acc: 0.26316 val_loss: 59.06472, val_acc: 0.82353\n",
            "Epoch [6240/10000], loss: 43.17384 acc: 0.75000 val_loss: 14.39756, val_acc: 0.80392\n",
            "Epoch [6250/10000], loss: 40.62089 acc: 0.26316 val_loss: 58.50357, val_acc: 0.82353\n",
            "Epoch [6260/10000], loss: 42.02970 acc: 0.75000 val_loss: 13.93731, val_acc: 0.78431\n",
            "Epoch [6270/10000], loss: 27.55400 acc: 0.32895 val_loss: 50.51116, val_acc: 0.82353\n",
            "Epoch [6280/10000], loss: 31.40211 acc: 0.75000 val_loss: 9.23032, val_acc: 0.66667\n",
            "Epoch [6290/10000], loss: 14.17564 acc: 0.47368 val_loss: 36.55862, val_acc: 0.82353\n",
            "Epoch [6300/10000], loss: 13.13016 acc: 0.75000 val_loss: 38.17549, val_acc: 0.19608\n",
            "Epoch [6310/10000], loss: 71.75164 acc: 0.75000 val_loss: 35.91403, val_acc: 0.82353\n",
            "Epoch [6320/10000], loss: 10.71438 acc: 0.72368 val_loss: 22.96548, val_acc: 0.37255\n",
            "Epoch [6330/10000], loss: 51.43667 acc: 0.75000 val_loss: 20.55796, val_acc: 0.82353\n",
            "Epoch [6340/10000], loss: 29.58680 acc: 0.30263 val_loss: 53.94931, val_acc: 0.82353\n",
            "Epoch [6350/10000], loss: 10.30811 acc: 0.59211 val_loss: 22.01667, val_acc: 0.82353\n",
            "Epoch [6360/10000], loss: 73.51316 acc: 0.75000 val_loss: 36.90005, val_acc: 0.82353\n",
            "Epoch [6370/10000], loss: 13.85056 acc: 0.75000 val_loss: 36.33118, val_acc: 0.19608\n",
            "Epoch [6380/10000], loss: 72.62868 acc: 0.75000 val_loss: 36.41221, val_acc: 0.82353\n",
            "Epoch [6390/10000], loss: 12.90884 acc: 0.75000 val_loss: 38.71170, val_acc: 0.19608\n",
            "Epoch [6400/10000], loss: 70.97500 acc: 0.75000 val_loss: 35.33754, val_acc: 0.82353\n",
            "Epoch [6410/10000], loss: 8.39261 acc: 0.65789 val_loss: 12.26948, val_acc: 0.78431\n",
            "Epoch [6420/10000], loss: 42.51588 acc: 0.75000 val_loss: 14.12424, val_acc: 0.78431\n",
            "Epoch [6430/10000], loss: 39.88697 acc: 0.27632 val_loss: 57.21712, val_acc: 0.82353\n",
            "Epoch [6440/10000], loss: 19.25102 acc: 0.42105 val_loss: 41.73431, val_acc: 0.82353\n",
            "Epoch [6450/10000], loss: 10.49977 acc: 0.71053 val_loss: 26.95230, val_acc: 0.21569\n",
            "Epoch [6460/10000], loss: 7.54113 acc: 0.71053 val_loss: 8.53823, val_acc: 0.66667\n",
            "Epoch [6470/10000], loss: 14.18017 acc: 0.75000 val_loss: 35.49487, val_acc: 0.19608\n",
            "Epoch [6480/10000], loss: 72.92929 acc: 0.75000 val_loss: 36.55622, val_acc: 0.82353\n",
            "Epoch [6490/10000], loss: 13.23045 acc: 0.75000 val_loss: 38.05011, val_acc: 0.19608\n",
            "Epoch [6500/10000], loss: 71.92960 acc: 0.75000 val_loss: 35.98034, val_acc: 0.82353\n",
            "Epoch [6510/10000], loss: 11.16911 acc: 0.73684 val_loss: 28.71758, val_acc: 0.29412\n",
            "Epoch [6520/10000], loss: 21.83056 acc: 0.35526 val_loss: 46.53865, val_acc: 0.82353\n",
            "Epoch [6530/10000], loss: 38.91074 acc: 0.75000 val_loss: 11.79986, val_acc: 0.78431\n",
            "Epoch [6540/10000], loss: 10.38038 acc: 0.72368 val_loss: 24.74529, val_acc: 0.35294\n",
            "Epoch [6550/10000], loss: 23.49462 acc: 0.32895 val_loss: 50.75235, val_acc: 0.82353\n",
            "Epoch [6560/10000], loss: 46.92734 acc: 0.75000 val_loss: 16.73141, val_acc: 0.82353\n",
            "Epoch [6570/10000], loss: 13.08408 acc: 0.46053 val_loss: 33.54133, val_acc: 0.82353\n",
            "Epoch [6580/10000], loss: 14.61848 acc: 0.75000 val_loss: 34.49471, val_acc: 0.19608\n",
            "Epoch [6590/10000], loss: 73.36895 acc: 0.75000 val_loss: 36.75155, val_acc: 0.82353\n",
            "Epoch [6600/10000], loss: 13.70458 acc: 0.75000 val_loss: 36.97635, val_acc: 0.19608\n",
            "Epoch [6610/10000], loss: 72.49485 acc: 0.75000 val_loss: 36.27157, val_acc: 0.82353\n",
            "Epoch [6620/10000], loss: 12.79534 acc: 0.75000 val_loss: 39.09650, val_acc: 0.19608\n",
            "Epoch [6630/10000], loss: 70.62122 acc: 0.75000 val_loss: 35.02872, val_acc: 0.82353\n",
            "Epoch [6640/10000], loss: 8.33424 acc: 0.65789 val_loss: 12.18094, val_acc: 0.78431\n",
            "Epoch [6650/10000], loss: 32.32969 acc: 0.28947 val_loss: 55.03636, val_acc: 0.82353\n",
            "Epoch [6660/10000], loss: 7.87678 acc: 0.71053 val_loss: 9.16640, val_acc: 0.64706\n",
            "Epoch [6670/10000], loss: 13.40009 acc: 0.75000 val_loss: 37.75101, val_acc: 0.19608\n",
            "Epoch [6680/10000], loss: 72.17104 acc: 0.75000 val_loss: 36.09512, val_acc: 0.82353\n",
            "Epoch [6690/10000], loss: 12.43692 acc: 0.75000 val_loss: 38.45297, val_acc: 0.19608\n",
            "Epoch [6700/10000], loss: 61.47291 acc: 0.75000 val_loss: 28.16040, val_acc: 0.82353\n",
            "Epoch [6710/10000], loss: 50.35627 acc: 0.75000 val_loss: 19.65517, val_acc: 0.82353\n",
            "Epoch [6720/10000], loss: 40.39185 acc: 0.75000 val_loss: 12.64999, val_acc: 0.78431\n",
            "Epoch [6730/10000], loss: 9.41184 acc: 0.60526 val_loss: 17.48025, val_acc: 0.82353\n",
            "Epoch [6740/10000], loss: 7.56909 acc: 0.71053 val_loss: 10.72630, val_acc: 0.78431\n",
            "Epoch [6750/10000], loss: 7.69473 acc: 0.68421 val_loss: 11.23505, val_acc: 0.60784\n",
            "Epoch [6760/10000], loss: 13.74911 acc: 0.75000 val_loss: 37.46034, val_acc: 0.21569\n",
            "Epoch [6770/10000], loss: 73.45324 acc: 0.75000 val_loss: 36.75739, val_acc: 0.82353\n",
            "Epoch [6780/10000], loss: 13.80489 acc: 0.75000 val_loss: 36.85272, val_acc: 0.19608\n",
            "Epoch [6790/10000], loss: 72.61127 acc: 0.75000 val_loss: 36.30181, val_acc: 0.82353\n",
            "Epoch [6800/10000], loss: 12.93242 acc: 0.75000 val_loss: 39.01118, val_acc: 0.19608\n",
            "Epoch [6810/10000], loss: 71.72697 acc: 0.75000 val_loss: 35.81173, val_acc: 0.82353\n",
            "Epoch [6820/10000], loss: 10.69386 acc: 0.72368 val_loss: 24.49643, val_acc: 0.37255\n",
            "Epoch [6830/10000], loss: 19.45535 acc: 0.75000 val_loss: 21.40116, val_acc: 0.37255\n",
            "Epoch [6840/10000], loss: 41.13881 acc: 0.26316 val_loss: 58.35177, val_acc: 0.82353\n",
            "Epoch [6850/10000], loss: 42.17308 acc: 0.75000 val_loss: 13.93985, val_acc: 0.78431\n",
            "Epoch [6860/10000], loss: 30.86268 acc: 0.31579 val_loss: 53.49422, val_acc: 0.82353\n",
            "Epoch [6870/10000], loss: 58.66467 acc: 0.75000 val_loss: 25.93679, val_acc: 0.82353\n",
            "Epoch [6880/10000], loss: 7.98265 acc: 0.68421 val_loss: 12.31711, val_acc: 0.78431\n",
            "Epoch [6890/10000], loss: 10.30672 acc: 0.72368 val_loss: 28.63624, val_acc: 0.19608\n",
            "Epoch [6900/10000], loss: 35.39566 acc: 0.75000 val_loss: 9.70707, val_acc: 0.74510\n",
            "Epoch [6910/10000], loss: 43.94261 acc: 0.75000 val_loss: 14.52241, val_acc: 0.80392\n",
            "Epoch [6920/10000], loss: 38.11860 acc: 0.26316 val_loss: 58.93262, val_acc: 0.82353\n",
            "Epoch [6930/10000], loss: 43.25097 acc: 0.75000 val_loss: 14.28697, val_acc: 0.80392\n",
            "Epoch [6940/10000], loss: 40.28138 acc: 0.26316 val_loss: 58.46518, val_acc: 0.82353\n",
            "Epoch [6950/10000], loss: 42.39223 acc: 0.75000 val_loss: 13.96789, val_acc: 0.78431\n",
            "Epoch [6960/10000], loss: 40.43424 acc: 0.26316 val_loss: 57.75364, val_acc: 0.82353\n",
            "Epoch [6970/10000], loss: 31.83005 acc: 0.75000 val_loss: 9.47470, val_acc: 0.64706\n",
            "Epoch [6980/10000], loss: 35.45979 acc: 0.75000 val_loss: 10.13009, val_acc: 0.74510\n",
            "Epoch [6990/10000], loss: 13.25525 acc: 0.75000 val_loss: 38.28036, val_acc: 0.19608\n",
            "Epoch [7000/10000], loss: 71.98804 acc: 0.75000 val_loss: 35.95841, val_acc: 0.82353\n",
            "Epoch [7010/10000], loss: 12.27390 acc: 0.75000 val_loss: 37.14634, val_acc: 0.19608\n",
            "Epoch [7020/10000], loss: 22.68468 acc: 0.75000 val_loss: 15.57801, val_acc: 0.49020\n",
            "Epoch [7030/10000], loss: 31.18965 acc: 0.30263 val_loss: 54.18228, val_acc: 0.82353\n",
            "Epoch [7040/10000], loss: 66.81171 acc: 0.75000 val_loss: 31.85909, val_acc: 0.82353\n",
            "Epoch [7050/10000], loss: 17.00185 acc: 0.43421 val_loss: 40.17659, val_acc: 0.82353\n",
            "Epoch [7060/10000], loss: 13.06308 acc: 0.47368 val_loss: 33.09695, val_acc: 0.82353\n",
            "Epoch [7070/10000], loss: 7.21182 acc: 0.71053 val_loss: 8.61319, val_acc: 0.76471\n",
            "Epoch [7080/10000], loss: 41.01969 acc: 0.75000 val_loss: 12.43815, val_acc: 0.80392\n",
            "Epoch [7090/10000], loss: 37.31642 acc: 0.26316 val_loss: 58.99282, val_acc: 0.82353\n",
            "Epoch [7100/10000], loss: 43.47115 acc: 0.75000 val_loss: 14.33978, val_acc: 0.80392\n",
            "Epoch [7110/10000], loss: 39.70669 acc: 0.26316 val_loss: 58.55973, val_acc: 0.82353\n",
            "Epoch [7120/10000], loss: 42.61506 acc: 0.75000 val_loss: 14.00294, val_acc: 0.80392\n",
            "Epoch [7130/10000], loss: 41.05230 acc: 0.26316 val_loss: 58.16043, val_acc: 0.82353\n",
            "Epoch [7140/10000], loss: 41.10371 acc: 0.75000 val_loss: 13.34922, val_acc: 0.78431\n",
            "Epoch [7150/10000], loss: 8.09330 acc: 0.69737 val_loss: 10.44134, val_acc: 0.74510\n",
            "Epoch [7160/10000], loss: 13.26188 acc: 0.75000 val_loss: 38.29072, val_acc: 0.19608\n",
            "Epoch [7170/10000], loss: 71.88920 acc: 0.75000 val_loss: 35.88223, val_acc: 0.82353\n",
            "Epoch [7180/10000], loss: 11.39682 acc: 0.72368 val_loss: 32.56129, val_acc: 0.19608\n",
            "Epoch [7190/10000], loss: 22.05997 acc: 0.34211 val_loss: 46.73640, val_acc: 0.82353\n",
            "Epoch [7200/10000], loss: 34.34373 acc: 0.75000 val_loss: 9.57905, val_acc: 0.76471\n",
            "Epoch [7210/10000], loss: 13.57185 acc: 0.75000 val_loss: 37.56444, val_acc: 0.19608\n",
            "Epoch [7220/10000], loss: 72.32409 acc: 0.75000 val_loss: 36.11199, val_acc: 0.82353\n",
            "Epoch [7230/10000], loss: 12.69633 acc: 0.75000 val_loss: 38.99406, val_acc: 0.19608\n",
            "Epoch [7240/10000], loss: 70.50690 acc: 0.75000 val_loss: 34.90997, val_acc: 0.82353\n",
            "Epoch [7250/10000], loss: 14.97492 acc: 0.47368 val_loss: 36.43382, val_acc: 0.82353\n",
            "Epoch [7260/10000], loss: 10.69579 acc: 0.71053 val_loss: 25.37804, val_acc: 0.37255\n",
            "Epoch [7270/10000], loss: 8.13147 acc: 0.69737 val_loss: 9.75343, val_acc: 0.60784\n",
            "Epoch [7280/10000], loss: 72.04851 acc: 0.75000 val_loss: 35.82615, val_acc: 0.82353\n",
            "Epoch [7290/10000], loss: 13.11775 acc: 0.75000 val_loss: 38.57378, val_acc: 0.19608\n",
            "Epoch [7300/10000], loss: 71.99958 acc: 0.75000 val_loss: 35.96696, val_acc: 0.82353\n",
            "Epoch [7310/10000], loss: 12.15188 acc: 0.73684 val_loss: 35.59481, val_acc: 0.19608\n",
            "Epoch [7320/10000], loss: 14.48517 acc: 0.47368 val_loss: 36.41119, val_acc: 0.82353\n",
            "Epoch [7330/10000], loss: 12.57084 acc: 0.75000 val_loss: 38.17448, val_acc: 0.19608\n",
            "Epoch [7340/10000], loss: 61.88798 acc: 0.75000 val_loss: 28.44823, val_acc: 0.82353\n",
            "Epoch [7350/10000], loss: 7.89121 acc: 0.69737 val_loss: 9.49683, val_acc: 0.60784\n",
            "Epoch [7360/10000], loss: 14.71504 acc: 0.75000 val_loss: 34.17569, val_acc: 0.19608\n",
            "Epoch [7370/10000], loss: 72.80405 acc: 0.75000 val_loss: 36.37496, val_acc: 0.82353\n",
            "Epoch [7380/10000], loss: 13.14048 acc: 0.75000 val_loss: 38.52184, val_acc: 0.19608\n",
            "Epoch [7390/10000], loss: 72.02721 acc: 0.75000 val_loss: 35.96686, val_acc: 0.82353\n",
            "Epoch [7400/10000], loss: 11.96791 acc: 0.72368 val_loss: 34.56642, val_acc: 0.17647\n",
            "Epoch [7410/10000], loss: 14.72284 acc: 0.47368 val_loss: 36.45198, val_acc: 0.82353\n",
            "Epoch [7420/10000], loss: 12.58297 acc: 0.75000 val_loss: 38.03888, val_acc: 0.19608\n",
            "Epoch [7430/10000], loss: 61.78455 acc: 0.75000 val_loss: 28.34567, val_acc: 0.82353\n",
            "Epoch [7440/10000], loss: 12.80309 acc: 0.75000 val_loss: 38.49979, val_acc: 0.19608\n",
            "Epoch [7450/10000], loss: 69.59539 acc: 0.75000 val_loss: 34.22888, val_acc: 0.82353\n",
            "Epoch [7460/10000], loss: 13.12991 acc: 0.75000 val_loss: 38.25356, val_acc: 0.19608\n",
            "Epoch [7470/10000], loss: 71.45644 acc: 0.75000 val_loss: 35.60924, val_acc: 0.82353\n",
            "Epoch [7480/10000], loss: 8.13524 acc: 0.68421 val_loss: 10.92552, val_acc: 0.74510\n",
            "Epoch [7490/10000], loss: 37.94754 acc: 0.26316 val_loss: 58.14762, val_acc: 0.82353\n",
            "Epoch [7500/10000], loss: 42.24747 acc: 0.75000 val_loss: 13.93985, val_acc: 0.78431\n",
            "Epoch [7510/10000], loss: 25.77831 acc: 0.32895 val_loss: 50.56797, val_acc: 0.82353\n",
            "Epoch [7520/10000], loss: 29.00091 acc: 0.75000 val_loss: 9.55681, val_acc: 0.64706\n",
            "Epoch [7530/10000], loss: 34.26039 acc: 0.30263 val_loss: 55.36766, val_acc: 0.82353\n",
            "Epoch [7540/10000], loss: 72.54314 acc: 0.75000 val_loss: 36.24860, val_acc: 0.82353\n",
            "Epoch [7550/10000], loss: 12.91799 acc: 0.75000 val_loss: 38.59687, val_acc: 0.19608\n",
            "Epoch [7560/10000], loss: 71.83563 acc: 0.75000 val_loss: 35.89024, val_acc: 0.82353\n",
            "Epoch [7570/10000], loss: 10.31745 acc: 0.72368 val_loss: 22.13526, val_acc: 0.39216\n",
            "Epoch [7580/10000], loss: 35.96188 acc: 0.28947 val_loss: 56.41983, val_acc: 0.82353\n",
            "Epoch [7590/10000], loss: 46.95052 acc: 0.75000 val_loss: 17.10261, val_acc: 0.82353\n",
            "Epoch [7600/10000], loss: 29.81612 acc: 0.75000 val_loss: 9.09539, val_acc: 0.64706\n",
            "Epoch [7610/10000], loss: 9.96283 acc: 0.73684 val_loss: 22.54242, val_acc: 0.37255\n",
            "Epoch [7620/10000], loss: 11.64400 acc: 0.73684 val_loss: 37.08241, val_acc: 0.19608\n",
            "Epoch [7630/10000], loss: 72.35352 acc: 0.75000 val_loss: 36.16137, val_acc: 0.82353\n",
            "Epoch [7640/10000], loss: 12.78851 acc: 0.75000 val_loss: 38.40785, val_acc: 0.19608\n",
            "Epoch [7650/10000], loss: 71.12759 acc: 0.75000 val_loss: 35.40754, val_acc: 0.82353\n",
            "Epoch [7660/10000], loss: 8.36057 acc: 0.65789 val_loss: 13.26346, val_acc: 0.78431\n",
            "Epoch [7670/10000], loss: 10.00522 acc: 0.73684 val_loss: 21.50375, val_acc: 0.39216\n",
            "Epoch [7680/10000], loss: 40.35281 acc: 0.26316 val_loss: 58.35787, val_acc: 0.82353\n",
            "Epoch [7690/10000], loss: 42.23569 acc: 0.75000 val_loss: 14.02071, val_acc: 0.78431\n",
            "Epoch [7700/10000], loss: 24.41244 acc: 0.32895 val_loss: 50.09003, val_acc: 0.82353\n",
            "Epoch [7710/10000], loss: 68.15488 acc: 0.75000 val_loss: 33.18567, val_acc: 0.82353\n",
            "Epoch [7720/10000], loss: 9.09010 acc: 0.61842 val_loss: 15.47253, val_acc: 0.80392\n",
            "Epoch [7730/10000], loss: 14.55760 acc: 0.75000 val_loss: 34.18926, val_acc: 0.17647\n",
            "Epoch [7740/10000], loss: 72.16077 acc: 0.75000 val_loss: 36.12273, val_acc: 0.82353\n",
            "Epoch [7750/10000], loss: 12.60526 acc: 0.75000 val_loss: 37.43701, val_acc: 0.19608\n",
            "Epoch [7760/10000], loss: 60.35801 acc: 0.75000 val_loss: 27.35299, val_acc: 0.82353\n",
            "Epoch [7770/10000], loss: 39.43552 acc: 0.75000 val_loss: 12.40331, val_acc: 0.78431\n",
            "Epoch [7780/10000], loss: 8.77645 acc: 0.68421 val_loss: 11.40387, val_acc: 0.60784\n",
            "Epoch [7790/10000], loss: 42.98338 acc: 0.75000 val_loss: 14.32062, val_acc: 0.80392\n",
            "Epoch [7800/10000], loss: 40.00928 acc: 0.26316 val_loss: 58.39481, val_acc: 0.82353\n",
            "Epoch [7810/10000], loss: 41.42039 acc: 0.75000 val_loss: 13.60396, val_acc: 0.78431\n",
            "Epoch [7820/10000], loss: 45.90376 acc: 0.75000 val_loss: 16.46060, val_acc: 0.80392\n",
            "Epoch [7830/10000], loss: 11.50601 acc: 0.72368 val_loss: 34.07780, val_acc: 0.17647\n",
            "Epoch [7840/10000], loss: 43.63598 acc: 0.75000 val_loss: 14.76367, val_acc: 0.80392\n",
            "Epoch [7850/10000], loss: 39.87874 acc: 0.26316 val_loss: 58.40243, val_acc: 0.82353\n",
            "Epoch [7860/10000], loss: 41.00446 acc: 0.75000 val_loss: 13.34999, val_acc: 0.78431\n",
            "Epoch [7870/10000], loss: 71.77697 acc: 0.75000 val_loss: 35.92182, val_acc: 0.82353\n",
            "Epoch [7880/10000], loss: 8.27153 acc: 0.71053 val_loss: 9.60523, val_acc: 0.64706\n",
            "Epoch [7890/10000], loss: 7.99556 acc: 0.67105 val_loss: 10.22398, val_acc: 0.74510\n",
            "Epoch [7900/10000], loss: 50.32539 acc: 0.75000 val_loss: 19.53508, val_acc: 0.82353\n",
            "Epoch [7910/10000], loss: 36.70075 acc: 0.75000 val_loss: 10.37591, val_acc: 0.74510\n",
            "Epoch [7920/10000], loss: 64.84609 acc: 0.75000 val_loss: 30.40073, val_acc: 0.82353\n",
            "Epoch [7930/10000], loss: 72.68412 acc: 0.75000 val_loss: 36.21455, val_acc: 0.82353\n",
            "Epoch [7940/10000], loss: 13.50311 acc: 0.75000 val_loss: 37.63032, val_acc: 0.19608\n",
            "Epoch [7950/10000], loss: 72.39318 acc: 0.75000 val_loss: 36.17455, val_acc: 0.82353\n",
            "Epoch [7960/10000], loss: 12.88626 acc: 0.75000 val_loss: 38.04671, val_acc: 0.19608\n",
            "Epoch [7970/10000], loss: 71.87968 acc: 0.75000 val_loss: 35.96075, val_acc: 0.82353\n",
            "Epoch [7980/10000], loss: 9.42376 acc: 0.72368 val_loss: 14.07842, val_acc: 0.54902\n",
            "Epoch [7990/10000], loss: 40.24704 acc: 0.75000 val_loss: 12.89001, val_acc: 0.78431\n",
            "Epoch [8000/10000], loss: 39.83850 acc: 0.75000 val_loss: 12.52541, val_acc: 0.78431\n",
            "Epoch [8010/10000], loss: 39.31463 acc: 0.75000 val_loss: 12.08867, val_acc: 0.78431\n",
            "Epoch [8020/10000], loss: 10.19933 acc: 0.59211 val_loss: 20.93620, val_acc: 0.82353\n",
            "Epoch [8030/10000], loss: 33.58617 acc: 0.75000 val_loss: 8.90994, val_acc: 0.76471\n",
            "Epoch [8040/10000], loss: 16.73894 acc: 0.75000 val_loss: 28.07550, val_acc: 0.19608\n",
            "Epoch [8050/10000], loss: 42.89872 acc: 0.75000 val_loss: 13.82447, val_acc: 0.80392\n",
            "Epoch [8060/10000], loss: 39.14153 acc: 0.26316 val_loss: 58.77423, val_acc: 0.82353\n",
            "Epoch [8070/10000], loss: 43.04057 acc: 0.75000 val_loss: 14.16445, val_acc: 0.80392\n",
            "Epoch [8080/10000], loss: 40.04009 acc: 0.26316 val_loss: 58.40342, val_acc: 0.82353\n",
            "Epoch [8090/10000], loss: 42.52587 acc: 0.75000 val_loss: 14.06118, val_acc: 0.80392\n",
            "Epoch [8100/10000], loss: 39.33444 acc: 0.26316 val_loss: 58.13709, val_acc: 0.82353\n",
            "Epoch [8110/10000], loss: 34.36181 acc: 0.75000 val_loss: 9.92060, val_acc: 0.76471\n",
            "Epoch [8120/10000], loss: 36.73186 acc: 0.75000 val_loss: 10.85006, val_acc: 0.74510\n",
            "Epoch [8130/10000], loss: 22.49515 acc: 0.32895 val_loss: 48.45078, val_acc: 0.82353\n",
            "Epoch [8140/10000], loss: 63.36960 acc: 0.75000 val_loss: 29.39891, val_acc: 0.82353\n",
            "Epoch [8150/10000], loss: 72.36098 acc: 0.75000 val_loss: 36.13574, val_acc: 0.82353\n",
            "Epoch [8160/10000], loss: 12.89796 acc: 0.75000 val_loss: 38.10116, val_acc: 0.19608\n",
            "Epoch [8170/10000], loss: 72.04631 acc: 0.75000 val_loss: 36.07241, val_acc: 0.82353\n",
            "Epoch [8180/10000], loss: 10.49086 acc: 0.72368 val_loss: 23.65905, val_acc: 0.37255\n",
            "Epoch [8190/10000], loss: 66.66299 acc: 0.75000 val_loss: 31.98542, val_acc: 0.82353\n",
            "Epoch [8200/10000], loss: 10.37060 acc: 0.59211 val_loss: 21.04831, val_acc: 0.82353\n",
            "Epoch [8210/10000], loss: 40.59903 acc: 0.75000 val_loss: 12.59978, val_acc: 0.78431\n",
            "Epoch [8220/10000], loss: 39.90533 acc: 0.26316 val_loss: 58.40942, val_acc: 0.82353\n",
            "Epoch [8230/10000], loss: 42.55934 acc: 0.75000 val_loss: 14.08909, val_acc: 0.80392\n",
            "Epoch [8240/10000], loss: 39.01514 acc: 0.26316 val_loss: 57.97472, val_acc: 0.82353\n",
            "Epoch [8250/10000], loss: 31.74302 acc: 0.75000 val_loss: 9.40623, val_acc: 0.66667\n",
            "Epoch [8260/10000], loss: 40.31807 acc: 0.75000 val_loss: 12.75356, val_acc: 0.78431\n",
            "Epoch [8270/10000], loss: 15.03929 acc: 0.75000 val_loss: 32.88273, val_acc: 0.17647\n",
            "Epoch [8280/10000], loss: 37.60270 acc: 0.75000 val_loss: 10.89831, val_acc: 0.76471\n",
            "Epoch [8290/10000], loss: 7.89269 acc: 0.71053 val_loss: 13.77271, val_acc: 0.50980\n",
            "Epoch [8300/10000], loss: 43.23357 acc: 0.75000 val_loss: 14.21496, val_acc: 0.80392\n",
            "Epoch [8310/10000], loss: 39.78391 acc: 0.26316 val_loss: 58.44884, val_acc: 0.82353\n",
            "Epoch [8320/10000], loss: 42.61133 acc: 0.75000 val_loss: 14.03249, val_acc: 0.80392\n",
            "Epoch [8330/10000], loss: 39.47411 acc: 0.26316 val_loss: 58.40387, val_acc: 0.82353\n",
            "Epoch [8340/10000], loss: 40.99371 acc: 0.75000 val_loss: 13.29924, val_acc: 0.78431\n",
            "Epoch [8350/10000], loss: 71.79795 acc: 0.75000 val_loss: 35.89318, val_acc: 0.82353\n",
            "Epoch [8360/10000], loss: 8.20587 acc: 0.71053 val_loss: 9.52696, val_acc: 0.66667\n",
            "Epoch [8370/10000], loss: 8.45690 acc: 0.68421 val_loss: 11.46374, val_acc: 0.60784\n",
            "Epoch [8380/10000], loss: 36.56495 acc: 0.75000 val_loss: 10.51249, val_acc: 0.74510\n",
            "Epoch [8390/10000], loss: 72.32516 acc: 0.75000 val_loss: 36.14040, val_acc: 0.82353\n",
            "Epoch [8400/10000], loss: 12.92342 acc: 0.75000 val_loss: 37.55354, val_acc: 0.19608\n",
            "Epoch [8410/10000], loss: 69.81344 acc: 0.75000 val_loss: 34.41098, val_acc: 0.82353\n",
            "Epoch [8420/10000], loss: 69.00411 acc: 0.75000 val_loss: 33.73621, val_acc: 0.82353\n",
            "Epoch [8430/10000], loss: 40.31324 acc: 0.75000 val_loss: 12.70475, val_acc: 0.78431\n",
            "Epoch [8440/10000], loss: 67.37574 acc: 0.75000 val_loss: 32.44746, val_acc: 0.82353\n",
            "Epoch [8450/10000], loss: 10.08946 acc: 0.59211 val_loss: 20.67507, val_acc: 0.82353\n",
            "Epoch [8460/10000], loss: 32.86008 acc: 0.75000 val_loss: 8.67353, val_acc: 0.74510\n",
            "Epoch [8470/10000], loss: 38.83807 acc: 0.26316 val_loss: 58.58091, val_acc: 0.82353\n",
            "Epoch [8480/10000], loss: 42.88286 acc: 0.75000 val_loss: 14.06284, val_acc: 0.80392\n",
            "Epoch [8490/10000], loss: 39.52664 acc: 0.26316 val_loss: 58.42142, val_acc: 0.82353\n",
            "Epoch [8500/10000], loss: 42.59607 acc: 0.75000 val_loss: 14.11022, val_acc: 0.80392\n",
            "Epoch [8510/10000], loss: 37.55963 acc: 0.28947 val_loss: 56.66514, val_acc: 0.82353\n",
            "Epoch [8520/10000], loss: 36.04225 acc: 0.28947 val_loss: 55.96900, val_acc: 0.82353\n",
            "Epoch [8530/10000], loss: 72.32129 acc: 0.75000 val_loss: 36.18532, val_acc: 0.82353\n",
            "Epoch [8540/10000], loss: 12.70658 acc: 0.73684 val_loss: 36.66306, val_acc: 0.19608\n",
            "Epoch [8550/10000], loss: 46.17702 acc: 0.75000 val_loss: 16.61223, val_acc: 0.80392\n",
            "Epoch [8560/10000], loss: 31.93981 acc: 0.75000 val_loss: 9.05386, val_acc: 0.68627\n",
            "Epoch [8570/10000], loss: 46.52628 acc: 0.75000 val_loss: 16.63810, val_acc: 0.82353\n",
            "Epoch [8580/10000], loss: 72.30862 acc: 0.75000 val_loss: 36.01210, val_acc: 0.82353\n",
            "Epoch [8590/10000], loss: 13.03788 acc: 0.75000 val_loss: 37.85671, val_acc: 0.19608\n",
            "Epoch [8600/10000], loss: 72.27408 acc: 0.75000 val_loss: 36.16049, val_acc: 0.82353\n",
            "Epoch [8610/10000], loss: 12.37900 acc: 0.73684 val_loss: 35.61190, val_acc: 0.17647\n",
            "Epoch [8620/10000], loss: 14.62188 acc: 0.75000 val_loss: 33.95371, val_acc: 0.17647\n",
            "Epoch [8630/10000], loss: 9.75081 acc: 0.73684 val_loss: 20.41012, val_acc: 0.41176\n",
            "Epoch [8640/10000], loss: 64.49481 acc: 0.75000 val_loss: 30.19757, val_acc: 0.82353\n",
            "Epoch [8650/10000], loss: 42.25319 acc: 0.75000 val_loss: 13.62927, val_acc: 0.80392\n",
            "Epoch [8660/10000], loss: 39.34071 acc: 0.26316 val_loss: 58.43453, val_acc: 0.82353\n",
            "Epoch [8670/10000], loss: 42.63375 acc: 0.75000 val_loss: 14.12520, val_acc: 0.80392\n",
            "Epoch [8680/10000], loss: 37.64422 acc: 0.28947 val_loss: 56.82092, val_acc: 0.82353\n",
            "Epoch [8690/10000], loss: 17.44339 acc: 0.46053 val_loss: 38.93903, val_acc: 0.82353\n",
            "Epoch [8700/10000], loss: 47.21460 acc: 0.75000 val_loss: 17.20164, val_acc: 0.82353\n",
            "Epoch [8710/10000], loss: 16.23657 acc: 0.75000 val_loss: 29.42715, val_acc: 0.17647\n",
            "Epoch [8720/10000], loss: 36.15435 acc: 0.75000 val_loss: 10.02749, val_acc: 0.74510\n",
            "Epoch [8730/10000], loss: 60.13012 acc: 0.75000 val_loss: 26.75594, val_acc: 0.82353\n",
            "Epoch [8740/10000], loss: 42.95710 acc: 0.75000 val_loss: 14.03346, val_acc: 0.80392\n",
            "Epoch [8750/10000], loss: 39.32168 acc: 0.26316 val_loss: 58.40751, val_acc: 0.82353\n",
            "Epoch [8760/10000], loss: 42.69574 acc: 0.75000 val_loss: 14.09321, val_acc: 0.80392\n",
            "Epoch [8770/10000], loss: 38.62019 acc: 0.26316 val_loss: 58.20331, val_acc: 0.82353\n",
            "Epoch [8780/10000], loss: 36.29838 acc: 0.75000 val_loss: 10.69294, val_acc: 0.74510\n",
            "Epoch [8790/10000], loss: 64.25665 acc: 0.75000 val_loss: 30.07432, val_acc: 0.82353\n",
            "Epoch [8800/10000], loss: 21.93453 acc: 0.75000 val_loss: 16.62045, val_acc: 0.43137\n",
            "Epoch [8810/10000], loss: 8.75132 acc: 0.72368 val_loss: 19.32438, val_acc: 0.43137\n",
            "Epoch [8820/10000], loss: 16.25928 acc: 0.43421 val_loss: 38.54612, val_acc: 0.82353\n",
            "Epoch [8830/10000], loss: 7.68955 acc: 0.71053 val_loss: 15.03465, val_acc: 0.49020\n",
            "Epoch [8840/10000], loss: 36.94754 acc: 0.75000 val_loss: 10.20188, val_acc: 0.76471\n",
            "Epoch [8850/10000], loss: 10.31328 acc: 0.71053 val_loss: 35.08801, val_acc: 0.19608\n",
            "Epoch [8860/10000], loss: 72.65922 acc: 0.75000 val_loss: 36.15222, val_acc: 0.82353\n",
            "Epoch [8870/10000], loss: 13.11934 acc: 0.75000 val_loss: 38.17730, val_acc: 0.19608\n",
            "Epoch [8880/10000], loss: 72.35472 acc: 0.75000 val_loss: 36.09865, val_acc: 0.82353\n",
            "Epoch [8890/10000], loss: 12.99697 acc: 0.75000 val_loss: 37.55439, val_acc: 0.19608\n",
            "Epoch [8900/10000], loss: 70.83408 acc: 0.75000 val_loss: 35.12052, val_acc: 0.82353\n",
            "Epoch [8910/10000], loss: 31.50209 acc: 0.31579 val_loss: 53.19096, val_acc: 0.82353\n",
            "Epoch [8920/10000], loss: 72.31313 acc: 0.75000 val_loss: 36.13765, val_acc: 0.82353\n",
            "Epoch [8930/10000], loss: 12.59564 acc: 0.73684 val_loss: 36.15997, val_acc: 0.19608\n",
            "Epoch [8940/10000], loss: 30.38327 acc: 0.75000 val_loss: 9.37449, val_acc: 0.66667\n",
            "Epoch [8950/10000], loss: 8.74865 acc: 0.71053 val_loss: 13.70009, val_acc: 0.54902\n",
            "Epoch [8960/10000], loss: 42.54859 acc: 0.75000 val_loss: 14.08939, val_acc: 0.78431\n",
            "Epoch [8970/10000], loss: 31.55793 acc: 0.31579 val_loss: 53.04965, val_acc: 0.82353\n",
            "Epoch [8980/10000], loss: 64.65023 acc: 0.75000 val_loss: 30.38499, val_acc: 0.82353\n",
            "Epoch [8990/10000], loss: 34.74454 acc: 0.75000 val_loss: 9.57871, val_acc: 0.74510\n",
            "Epoch [9000/10000], loss: 7.83773 acc: 0.69737 val_loss: 12.88699, val_acc: 0.54902\n",
            "Epoch [9010/10000], loss: 14.72703 acc: 0.75000 val_loss: 34.35579, val_acc: 0.19608\n",
            "Epoch [9020/10000], loss: 72.43849 acc: 0.75000 val_loss: 36.04523, val_acc: 0.82353\n",
            "Epoch [9030/10000], loss: 13.08102 acc: 0.75000 val_loss: 37.52528, val_acc: 0.19608\n",
            "Epoch [9040/10000], loss: 72.33590 acc: 0.75000 val_loss: 36.14224, val_acc: 0.82353\n",
            "Epoch [9050/10000], loss: 12.24519 acc: 0.73684 val_loss: 35.58590, val_acc: 0.19608\n",
            "Epoch [9060/10000], loss: 14.55931 acc: 0.75000 val_loss: 34.28387, val_acc: 0.17647\n",
            "Epoch [9070/10000], loss: 33.43632 acc: 0.30263 val_loss: 53.78315, val_acc: 0.82353\n",
            "Epoch [9080/10000], loss: 13.10152 acc: 0.75000 val_loss: 37.34460, val_acc: 0.19608\n",
            "Epoch [9090/10000], loss: 72.08678 acc: 0.75000 val_loss: 36.01296, val_acc: 0.82353\n",
            "Epoch [9100/10000], loss: 9.61041 acc: 0.72368 val_loss: 17.82307, val_acc: 0.43137\n",
            "Epoch [9110/10000], loss: 24.82798 acc: 0.32895 val_loss: 52.03524, val_acc: 0.82353\n",
            "Epoch [9120/10000], loss: 21.47979 acc: 0.35526 val_loss: 46.82239, val_acc: 0.82353\n",
            "Epoch [9130/10000], loss: 36.25496 acc: 0.75000 val_loss: 10.13594, val_acc: 0.74510\n",
            "Epoch [9140/10000], loss: 65.01239 acc: 0.75000 val_loss: 30.46916, val_acc: 0.82353\n",
            "Epoch [9150/10000], loss: 38.56332 acc: 0.26316 val_loss: 58.35041, val_acc: 0.82353\n",
            "Epoch [9160/10000], loss: 42.73471 acc: 0.75000 val_loss: 14.02039, val_acc: 0.80392\n",
            "Epoch [9170/10000], loss: 38.65615 acc: 0.26316 val_loss: 58.45617, val_acc: 0.82353\n",
            "Epoch [9180/10000], loss: 41.76633 acc: 0.75000 val_loss: 13.66200, val_acc: 0.78431\n",
            "Epoch [9190/10000], loss: 8.94847 acc: 0.63158 val_loss: 15.17664, val_acc: 0.80392\n",
            "Epoch [9200/10000], loss: 29.25093 acc: 0.75000 val_loss: 9.40664, val_acc: 0.60784\n",
            "Epoch [9210/10000], loss: 32.18003 acc: 0.30263 val_loss: 53.76403, val_acc: 0.82353\n",
            "Epoch [9220/10000], loss: 12.20975 acc: 0.73684 val_loss: 36.80786, val_acc: 0.19608\n",
            "Epoch [9230/10000], loss: 72.36218 acc: 0.75000 val_loss: 36.16613, val_acc: 0.82353\n",
            "Epoch [9240/10000], loss: 12.59604 acc: 0.73684 val_loss: 35.89852, val_acc: 0.19608\n",
            "Epoch [9250/10000], loss: 32.87702 acc: 0.75000 val_loss: 9.25241, val_acc: 0.70588\n",
            "Epoch [9260/10000], loss: 35.04102 acc: 0.75000 val_loss: 9.66697, val_acc: 0.74510\n",
            "Epoch [9270/10000], loss: 38.70891 acc: 0.26316 val_loss: 58.33028, val_acc: 0.82353\n",
            "Epoch [9280/10000], loss: 42.72413 acc: 0.75000 val_loss: 14.03534, val_acc: 0.80392\n",
            "Epoch [9290/10000], loss: 38.15292 acc: 0.26316 val_loss: 58.21616, val_acc: 0.82353\n",
            "Epoch [9300/10000], loss: 37.46016 acc: 0.75000 val_loss: 11.15327, val_acc: 0.74510\n",
            "Epoch [9310/10000], loss: 68.13361 acc: 0.75000 val_loss: 33.05241, val_acc: 0.82353\n",
            "Epoch [9320/10000], loss: 8.97741 acc: 0.72368 val_loss: 16.36384, val_acc: 0.43137\n",
            "Epoch [9330/10000], loss: 8.38613 acc: 0.71053 val_loss: 14.69400, val_acc: 0.52941\n",
            "Epoch [9340/10000], loss: 42.49166 acc: 0.75000 val_loss: 13.84457, val_acc: 0.80392\n",
            "Epoch [9350/10000], loss: 38.18953 acc: 0.26316 val_loss: 58.32897, val_acc: 0.82353\n",
            "Epoch [9360/10000], loss: 40.53391 acc: 0.75000 val_loss: 12.89604, val_acc: 0.78431\n",
            "Epoch [9370/10000], loss: 20.17925 acc: 0.39474 val_loss: 42.80930, val_acc: 0.82353\n",
            "Epoch [9380/10000], loss: 10.00297 acc: 0.60526 val_loss: 20.21667, val_acc: 0.82353\n",
            "Epoch [9390/10000], loss: 36.70952 acc: 0.75000 val_loss: 10.22941, val_acc: 0.76471\n",
            "Epoch [9400/10000], loss: 45.13010 acc: 0.75000 val_loss: 15.36601, val_acc: 0.82353\n",
            "Epoch [9410/10000], loss: 38.20122 acc: 0.26316 val_loss: 58.16282, val_acc: 0.82353\n",
            "Epoch [9420/10000], loss: 42.71511 acc: 0.75000 val_loss: 13.92749, val_acc: 0.80392\n",
            "Epoch [9430/10000], loss: 38.37274 acc: 0.26316 val_loss: 58.39483, val_acc: 0.82353\n",
            "Epoch [9440/10000], loss: 41.95997 acc: 0.75000 val_loss: 13.69052, val_acc: 0.78431\n",
            "Epoch [9450/10000], loss: 12.79940 acc: 0.47368 val_loss: 32.94677, val_acc: 0.82353\n",
            "Epoch [9460/10000], loss: 45.93404 acc: 0.75000 val_loss: 16.20791, val_acc: 0.82353\n",
            "Epoch [9470/10000], loss: 72.30196 acc: 0.75000 val_loss: 36.01304, val_acc: 0.82353\n",
            "Epoch [9480/10000], loss: 12.89344 acc: 0.73684 val_loss: 36.38163, val_acc: 0.19608\n",
            "Epoch [9490/10000], loss: 67.02625 acc: 0.75000 val_loss: 32.19614, val_acc: 0.82353\n",
            "Epoch [9500/10000], loss: 37.23750 acc: 0.28947 val_loss: 56.71067, val_acc: 0.82353\n",
            "Epoch [9510/10000], loss: 8.72650 acc: 0.63158 val_loss: 15.15039, val_acc: 0.80392\n",
            "Epoch [9520/10000], loss: 42.74474 acc: 0.75000 val_loss: 14.02572, val_acc: 0.80392\n",
            "Epoch [9530/10000], loss: 37.60131 acc: 0.26316 val_loss: 57.87833, val_acc: 0.82353\n",
            "Epoch [9540/10000], loss: 37.44314 acc: 0.75000 val_loss: 11.11868, val_acc: 0.74510\n",
            "Epoch [9550/10000], loss: 64.04237 acc: 0.75000 val_loss: 29.93592, val_acc: 0.82353\n",
            "Epoch [9560/10000], loss: 51.62157 acc: 0.75000 val_loss: 20.49601, val_acc: 0.82353\n",
            "Epoch [9570/10000], loss: 22.84664 acc: 0.75000 val_loss: 15.22952, val_acc: 0.47059\n",
            "Epoch [9580/10000], loss: 17.77687 acc: 0.75000 val_loss: 25.31890, val_acc: 0.27451\n",
            "Epoch [9590/10000], loss: 29.64893 acc: 0.75000 val_loss: 8.83489, val_acc: 0.62745\n",
            "Epoch [9600/10000], loss: 7.84475 acc: 0.64474 val_loss: 13.95792, val_acc: 0.80392\n",
            "Epoch [9610/10000], loss: 38.38907 acc: 0.26316 val_loss: 58.10931, val_acc: 0.82353\n",
            "Epoch [9620/10000], loss: 42.63704 acc: 0.75000 val_loss: 13.85299, val_acc: 0.80392\n",
            "Epoch [9630/10000], loss: 38.28041 acc: 0.26316 val_loss: 58.39088, val_acc: 0.82353\n",
            "Epoch [9640/10000], loss: 42.45803 acc: 0.75000 val_loss: 13.97876, val_acc: 0.78431\n",
            "Epoch [9650/10000], loss: 30.85121 acc: 0.31579 val_loss: 52.58639, val_acc: 0.82353\n",
            "Epoch [9660/10000], loss: 13.63894 acc: 0.47368 val_loss: 35.15987, val_acc: 0.82353\n",
            "Epoch [9670/10000], loss: 12.79654 acc: 0.73684 val_loss: 36.15747, val_acc: 0.19608\n",
            "Epoch [9680/10000], loss: 66.08690 acc: 0.75000 val_loss: 31.51673, val_acc: 0.82353\n",
            "Epoch [9690/10000], loss: 56.59318 acc: 0.75000 val_loss: 24.26487, val_acc: 0.82353\n",
            "Epoch [9700/10000], loss: 11.99975 acc: 0.73684 val_loss: 36.74466, val_acc: 0.19608\n",
            "Epoch [9710/10000], loss: 71.44529 acc: 0.75000 val_loss: 35.49119, val_acc: 0.82353\n",
            "Epoch [9720/10000], loss: 8.84036 acc: 0.71053 val_loss: 14.24195, val_acc: 0.52941\n",
            "Epoch [9730/10000], loss: 40.44608 acc: 0.75000 val_loss: 12.86015, val_acc: 0.78431\n",
            "Epoch [9740/10000], loss: 37.77819 acc: 0.26316 val_loss: 58.19222, val_acc: 0.82353\n",
            "Epoch [9750/10000], loss: 40.04452 acc: 0.75000 val_loss: 12.59353, val_acc: 0.78431\n",
            "Epoch [9760/10000], loss: 34.74615 acc: 0.75000 val_loss: 9.71987, val_acc: 0.76471\n",
            "Epoch [9770/10000], loss: 52.12338 acc: 0.75000 val_loss: 20.77834, val_acc: 0.82353\n",
            "Epoch [9780/10000], loss: 46.27128 acc: 0.75000 val_loss: 16.32121, val_acc: 0.82353\n",
            "Epoch [9790/10000], loss: 66.19193 acc: 0.75000 val_loss: 31.28285, val_acc: 0.82353\n",
            "Epoch [9800/10000], loss: 16.75860 acc: 0.43421 val_loss: 38.54539, val_acc: 0.82353\n",
            "Epoch [9810/10000], loss: 7.39987 acc: 0.68421 val_loss: 10.82615, val_acc: 0.76471\n",
            "Epoch [9820/10000], loss: 20.33855 acc: 0.75000 val_loss: 19.33391, val_acc: 0.41176\n",
            "Epoch [9830/10000], loss: 62.09497 acc: 0.75000 val_loss: 27.93688, val_acc: 0.82353\n",
            "Epoch [9840/10000], loss: 36.05502 acc: 0.75000 val_loss: 9.40374, val_acc: 0.76471\n",
            "Epoch [9850/10000], loss: 8.71434 acc: 0.61842 val_loss: 17.67481, val_acc: 0.82353\n",
            "Epoch [9860/10000], loss: 23.81086 acc: 0.32895 val_loss: 53.24274, val_acc: 0.82353\n",
            "Epoch [9870/10000], loss: 36.70643 acc: 0.75000 val_loss: 9.62376, val_acc: 0.76471\n",
            "Epoch [9880/10000], loss: 23.84025 acc: 0.32895 val_loss: 53.40887, val_acc: 0.82353\n",
            "Epoch [9890/10000], loss: 36.87385 acc: 0.75000 val_loss: 9.71299, val_acc: 0.76471\n",
            "Epoch [9900/10000], loss: 23.76268 acc: 0.32895 val_loss: 53.49808, val_acc: 0.82353\n",
            "Epoch [9910/10000], loss: 36.96025 acc: 0.75000 val_loss: 9.76540, val_acc: 0.76471\n",
            "Epoch [9920/10000], loss: 23.71404 acc: 0.32895 val_loss: 53.54214, val_acc: 0.82353\n",
            "Epoch [9930/10000], loss: 36.98577 acc: 0.75000 val_loss: 9.78926, val_acc: 0.76471\n",
            "Epoch [9940/10000], loss: 23.68132 acc: 0.32895 val_loss: 53.54661, val_acc: 0.82353\n",
            "Epoch [9950/10000], loss: 36.96265 acc: 0.75000 val_loss: 9.78885, val_acc: 0.76471\n",
            "Epoch [9960/10000], loss: 23.65322 acc: 0.32895 val_loss: 53.52430, val_acc: 0.82353\n",
            "Epoch [9970/10000], loss: 36.91116 acc: 0.75000 val_loss: 9.77341, val_acc: 0.76471\n",
            "Epoch [9980/10000], loss: 23.62069 acc: 0.32895 val_loss: 53.48781, val_acc: 0.82353\n",
            "Epoch [9990/10000], loss: 36.84533 acc: 0.75000 val_loss: 9.74939, val_acc: 0.76471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EBJibG_YzMah"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 確認ポイント"
      ],
      "metadata": {
        "id": "0HzQ3K_DORVK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGnDSJReB8wV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "974211e8-7875-41f8-ca1d-d9c9a0f60a36"
      },
      "source": [
        "# 損失と精度の確認\n",
        "\n",
        "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
        "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "初期状態: 損失: 22.65546 精度: 0.82353\n",
            "最終状態: 損失: 9.74939 精度: 0.76471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4NJkJDJB8wV"
      },
      "source": [
        "# 学習曲線の表示 (損失)\n",
        "\n",
        "# plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
        "# plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
        "# plt.xlabel('繰り返し回数')\n",
        "# plt.ylabel('損失')\n",
        "# plt.title('学習曲線(損失)')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZPEkfLJB8wW"
      },
      "source": [
        "# 学習曲線の表示 (精度)\n",
        "\n",
        "# plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
        "# plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
        "# plt.xlabel('繰り返し回数')\n",
        "# plt.ylabel('精度')\n",
        "# plt.title('学習曲線(精度)')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwXP0yeKB8wK"
      },
      "source": [
        "## NLLLoss損失関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg7-oAJ4B8wL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad644b1-d182-4d7d-eaed-0aa55b8e40f0"
      },
      "source": [
        "# 入力変数の準備\n",
        "\n",
        "# 擬似的な出力データ\n",
        "outputs_np = np.array(range(1, 13)).reshape((4,3))\n",
        "# 擬似的な正解データ\n",
        "labels_np = np.array([0, 1, 2, 0])\n",
        "\n",
        "# Tensor化\n",
        "outputs_dummy = torch.tensor(outputs_np).float()\n",
        "labels_dummy = torch.tensor(labels_np).long()\n",
        "\n",
        "# 結果確認\n",
        "print(outputs_dummy.data)\n",
        "print(labels_dummy.data)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  2.,  3.],\n",
            "        [ 4.,  5.,  6.],\n",
            "        [ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n",
            "tensor([0, 1, 2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf68l_reB8wL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c774000a-70d1-4127-fb9f-fb3172577241"
      },
      "source": [
        "# NLLLoss関数の呼び出し\n",
        "\n",
        "nllloss = nn.NLLLoss()\n",
        "loss = nllloss(outputs_dummy, labels_dummy)\n",
        "print(loss.item())"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-6.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_faCAG1B8wY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48688cb3-29b1-4125-c84b-4188c23e03bb"
      },
      "source": [
        "# モデル出力値\n",
        "# w = outputs[:5,:].data.numpy()\n",
        "w = outputs[:15000,:].data.numpy()\n",
        "print(w)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1480.2146 1396.2743 1303.1752 1303.1752]\n",
            " [1576.3903 1552.2025 1418.0916 1418.0916]\n",
            " [1173.0944 1170.7985 1054.6677 1054.6677]\n",
            " [ 944.0222  932.0771  848.1976  848.1976]\n",
            " [1387.8431 1322.3164 1225.783  1225.783 ]\n",
            " [1486.3779 1414.9115 1319.1411 1319.1411]\n",
            " [1177.4863 1139.8732 1056.8455 1056.8455]\n",
            " [ 969.5756  953.5034  877.2573  877.2573]\n",
            " [1355.827  1266.6798 1181.4961 1181.4961]\n",
            " [1341.9615 1327.636  1206.3785 1206.3785]\n",
            " [1237.1031 1243.8317 1118.2532 1118.2532]\n",
            " [1187.9658 1194.5836 1074.1896 1074.1896]\n",
            " [1540.9366 1469.8065 1366.8466 1366.8466]\n",
            " [1422.3772 1364.3035 1260.576  1260.576 ]\n",
            " [1101.8536 1089.6002 1000.2455 1000.2455]\n",
            " [1305.4236 1276.9457 1164.2637 1164.2637]\n",
            " [1152.2296 1099.3362 1012.9576 1012.9576]\n",
            " [1454.1733 1381.2651 1280.5594 1280.5594]\n",
            " [1279.928  1237.7366 1139.1655 1139.1655]\n",
            " [1279.6292 1301.8224 1166.8923 1166.8923]\n",
            " [1512.1401 1500.2405 1363.7649 1363.7649]\n",
            " [1417.1259 1346.8274 1254.1449 1254.1449]\n",
            " [1158.7518 1132.7756 1029.7847 1029.7847]\n",
            " [1383.6359 1295.0836 1213.2104 1213.2104]\n",
            " [1178.343  1142.3694 1045.7411 1045.7411]\n",
            " [1254.7034 1241.1204 1124.2417 1124.2417]\n",
            " [1228.4215 1192.0901 1093.6575 1093.6575]\n",
            " [ 983.765   992.5364  895.5092  895.5092]\n",
            " [1091.107  1045.8798  965.2288  965.2288]\n",
            " [1225.5343 1197.9904 1096.6963 1096.6963]\n",
            " [1375.8859 1331.2291 1229.0792 1229.0792]\n",
            " [1211.9454 1179.0643 1076.3732 1076.3732]\n",
            " [1274.299  1262.7783 1143.7456 1143.7456]\n",
            " [1125.9315 1129.0394 1015.4761 1015.4761]\n",
            " [1180.7795 1185.8127 1065.0151 1065.0151]\n",
            " [1338.7438 1304.8268 1193.9722 1193.9722]\n",
            " [1055.6329 1042.191   942.0122  942.0122]\n",
            " [1331.2526 1264.5023 1174.7754 1174.7754]\n",
            " [1011.9125  997.5068  913.8278  913.8278]\n",
            " [1340.6575 1273.0842 1182.6621 1182.6621]\n",
            " [1312.8573 1248.0282 1156.8761 1156.8761]\n",
            " [ 867.1676  822.8746  769.8964  769.8964]\n",
            " [1221.8015 1202.5171 1092.4854 1092.4854]\n",
            " [1334.4973 1293.981  1191.7673 1191.7673]\n",
            " [1205.6915 1196.2094 1083.2311 1083.2311]\n",
            " [1609.3965 1536.0822 1425.2434 1425.2434]\n",
            " [1171.8584 1149.6256 1045.6776 1045.6776]\n",
            " [1219.4103 1216.3885 1096.9843 1096.9843]\n",
            " [1053.7589 1038.4152  954.4404  954.4404]\n",
            " [1285.4952 1244.2584 1143.8776 1143.8776]\n",
            " [1329.8976 1236.623  1159.4192 1159.4192]\n",
            " [1433.006  1384.1829 1275.2495 1275.2495]\n",
            " [1416.783  1335.6813 1246.4276 1246.4276]\n",
            " [1312.7325 1303.7224 1178.3129 1178.3129]\n",
            " [1318.8773 1282.0504 1171.2866 1171.2866]\n",
            " [1401.0133 1356.5613 1245.6515 1245.6515]\n",
            " [1185.0363 1131.3412 1043.5277 1043.5277]\n",
            " [1165.1611 1176.5109 1053.9468 1053.9468]\n",
            " [1418.414  1363.9069 1256.7871 1256.7871]\n",
            " [1006.0197  965.6088  900.0814  900.0814]\n",
            " [1198.2806 1144.2198 1055.6191 1055.6191]\n",
            " [1098.705  1086.1913  979.4017  979.4017]\n",
            " [1291.3601 1230.9773 1139.8147 1139.8147]\n",
            " [1184.6798 1191.1124 1070.9243 1070.9243]\n",
            " [1114.2864 1108.8947  997.5002  997.5002]\n",
            " [1515.87   1451.9276 1345.2765 1345.2765]\n",
            " [1364.7032 1323.8954 1214.5742 1214.5742]\n",
            " [1169.4802 1091.2306 1027.7886 1027.7886]\n",
            " [1183.3368 1149.353  1062.2281 1062.2281]\n",
            " [1662.6587 1574.04   1467.7367 1467.7367]\n",
            " [1373.8417 1308.9828 1214.3994 1214.3994]\n",
            " [1279.8455 1260.2528 1143.2456 1143.2456]\n",
            " [1538.9471 1468.6204 1366.5576 1366.5576]\n",
            " [1418.5419 1333.1392 1245.1538 1245.1538]\n",
            " [1506.9386 1461.4045 1342.8973 1342.8973]\n",
            " [1331.4508 1304.5547 1189.609  1189.609 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = pd.DataFrame(w)\n",
        "\n",
        "df_f.head(1)"
      ],
      "metadata": {
        "id": "GUKXxEl3-6zO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "2504e1c7-fe09-480c-baff-0e5ca6aa1084"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0            1            2            3\n",
              "0  1480.2146  1396.274292  1303.175171  1303.175171"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33c0ad8c-cd1d-43ed-b537-b332d6895351\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1480.2146</td>\n",
              "      <td>1396.274292</td>\n",
              "      <td>1303.175171</td>\n",
              "      <td>1303.175171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33c0ad8c-cd1d-43ed-b537-b332d6895351')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33c0ad8c-cd1d-43ed-b537-b332d6895351 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33c0ad8c-cd1d-43ed-b537-b332d6895351');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_f['ans'] = df_f.idxmax(axis=1)"
      ],
      "metadata": {
        "id": "mnGgq9eSB7Qo"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_f.head(5)"
      ],
      "metadata": {
        "id": "bmqLzJLnCCxh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "adabcf87-d447-43e8-bd35-900770ec0ba3"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0            1            2            3  ans\n",
              "0  1480.214600  1396.274292  1303.175171  1303.175171    0\n",
              "1  1576.390259  1552.202515  1418.091553  1418.091553    0\n",
              "2  1173.094360  1170.798462  1054.667725  1054.667725    0\n",
              "3   944.022156   932.077087   848.197632   848.197632    0\n",
              "4  1387.843140  1322.316406  1225.782959  1225.782959    0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a17f0d06-394a-41b2-92a2-2724967d4272\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>ans</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1480.214600</td>\n",
              "      <td>1396.274292</td>\n",
              "      <td>1303.175171</td>\n",
              "      <td>1303.175171</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1576.390259</td>\n",
              "      <td>1552.202515</td>\n",
              "      <td>1418.091553</td>\n",
              "      <td>1418.091553</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1173.094360</td>\n",
              "      <td>1170.798462</td>\n",
              "      <td>1054.667725</td>\n",
              "      <td>1054.667725</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>944.022156</td>\n",
              "      <td>932.077087</td>\n",
              "      <td>848.197632</td>\n",
              "      <td>848.197632</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1387.843140</td>\n",
              "      <td>1322.316406</td>\n",
              "      <td>1225.782959</td>\n",
              "      <td>1225.782959</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a17f0d06-394a-41b2-92a2-2724967d4272')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a17f0d06-394a-41b2-92a2-2724967d4272 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a17f0d06-394a-41b2-92a2-2724967d4272');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=\"ans\", data=df_f)"
      ],
      "metadata": {
        "id": "ckCeRHG6Cdxt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "b6831174-7a0a-4e78-e7a5-1991ad5ccdff"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f783743e850>"
            ]
          },
          "metadata": {},
          "execution_count": 177
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAF5CAYAAACbRI0pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVNElEQVR4nO3df7DldX3f8eeLXbMSJARKvLK7LKsx0dIoHb2pbseWCyHZIjFpRafRIQIt3Zi0ECldqjCiRWohEX8kceKsNihEnTZ1CCDN6hC4amMa3KVEy1QCjYC710R2zeqIFFb33T/O2Xg+dw+yd+/e7/fuvc/HzJm99/v5fs++mbmzT873e8/3pKqQJGm/o/oeQJK0uBgGSVLDMEiSGoZBktQwDJKkhmGQJDVW9j3A4XDiiSfW+vXr+x5Dko4o27dv31VVPzZ7+5IIw/r169m2bVvfY0jSESXJw+O2d3IqKcnaJDvGPB5P8kfDfVYluTbJg0lmktySZE0X80mSvq+TMFTVjqpaO/oAfgr4DnD9cLf3AxuASWAd8ACwNcmSeFUjSUeKPi8+vxn4k6q6I8k64EJgc1XtqarvAlcAJwGv6nFGSVp2eglDkpOAi4Erh5tOB3ZX1d3796mqJ4FPAWd3P6EkLV99naa5FLirqr40/H4NMDNmvxng1HFPkGQTsAlgYmKC6enpBRhTkpafzsOQ5EeBNwK/MLJ5L7BvzO4FZNzzVNUWYAvA5ORkTU1NHd5BJWmZ6uNU0nnALuAzI9t2AKvH7Lsa2NnFUJKkgT7C8C+Bm6r9IIg7gROSvGT/huFvI50JbO14Pkla1joNQ5IXAH8fuH10e1U9CtwAXJ/kuCQrgHcCe4Bbu5xRkpa7rl8xnMPgH/txb1O+BLgXuI/BqaUXAhuram9340mSshQ+2nNycrK8JYYkzU2S7VU1OXu7d1eVJDUMgySp4X2Ihl66+ca+R9Ais/0339D3CFIvfMUgSWoYBklSwzBIkhqGQZLUMAySpIZhkCQ1DIMkqWEYJEkNwyBJahgGSVLDMEiSGoZBktQwDJKkhmGQJDUMgySpYRgkSQ3DIElqGAZJUsMwSJIahkGS1DAMkqSGYZAkNQyDJKlhGCRJDcMgSWoYBklSwzBIkhqGQZLUMAySpIZhkCQ1DIMkqdFZGJI8N8ktSXYm+VqS/5pk9cj6qiTXJnkwycxw3zVdzSdJGugkDEl+FJgGbgfWAs8DngTeNLLb+4ENwCSwDngA2JpkZRczSpIGuvpH91LgvqraMvz+8STnV9X3AJKsAy4ENlTVnuG2K4ALgFcBN3c0pyQte12dSvoF4I9GN+yPwtDpwO6quntk/UngU8DZnUwoSQK6C8NPAH+T5ANJ/jLJl5JcleQZw/U1wMyY42aGa5KkjnR1KmkFcCXwa8CvAj8JfAL4O8CvA3uBfWOOKyDjnjDJJmATwMTEBNPT0/Ma8KLTjpnX8Vp65vszJR2pugrDI8CHququ4ff3J3kH8LsMwrADWD3muNXAznFPOLxesQVgcnKypqam5jXgZZtvnNfxWnq2n3du3yNIvejqVNLngFVjtj85/PNO4IQkL9m/MPxtpDOBrQs/niRpv67CcC3wb5KcAZDkFOAq4PcAqupR4Abg+iTHJVkBvBPYA9za0YySJDoKQ1U9CPwScG2SrzN4hfBfgLeN7HYJcC9wH4NTSy8ENlbV3i5mlCQNdPbmsar6LPCyH7D+BIP3O1za1UySpAN5ryRJUsMwSJIahkGS1DAMkqSGYZAkNQyDJKlhGCRJDcMgSWoYBklSwzBIkhqGQZLUMAySpIZhkCQ1DIMkqWEYJEkNwyBJahgGSVLDMEiSGoZBktQwDJKkhmGQJDUMgySpYRgkSQ3DIElqGAZJUsMwSJIahkGS1DAMkqSGYZAkNQyDJKlhGCRJDcMgSWoYBklSwzBIkhqGQZLU6CQMSVYn2Zdkx6zHJcP1JNmc5P4kO5PcleTULmaTJLVWdvT3nAw8VFXPe4r1K4HXA2cAXwMuAe5I8veq6m86mlGSRHenkk4GvjpuIcnRwOXA26tqpgbeB+wCLuhoPknSUJdh2PEUa5PAscDts7bfBpy9kENJkg7U5amkVUk+BvwD4DHgY8D1wBrgm1X12KxjZoZrYyXZBGwCmJiYYHp6el4DXnTaMfM6XkvPfH+mpCNVV2E4Cng28CvAl4EXAP8NOBH4n8C+MccUkKd6wqraAmwBmJycrKmpqXkNeNnmG+d1vJae7eed2/cIUi86CUNVvWnWpi8neQfwOwwCcXySo6vq8ZF9VgM7u5hPkvR9nb2PIcns//vfH6V7gEc58HrCRmDrQs8lSWp19T6Gm4D/nOS44fcvAK4CPlhVe4H3AFcnWT1cvxhYB3y4i/kkSd/X1TWGS4FrgC8m+SHgCQb/6L9juH4dsAL4fJJVwP3AWVW1u6P5JElDXV1j2AW88Qes72MQjmu6mEeS9NS8V5IkqWEYJEkNwyBJahgGSVLDMEiSGoZBktQwDJKkhmGQJDUMgySpYRgkSQ3DIElqGAZJUsMwSJIahkGS1DAMkqSGYZAkNQyDJKlhGCRJDcMgSWoYBklSwzBIkhqGQZLUMAySpIZhkCQ1DIMkqWEYJEkNwyBJahgGSVLDMEiSGoZBktQwDJKkhmGQJDUMgySpYRgkSQ3DIElq9BKGJKck2ZPkwyPbViW5NsmDSWaS3JJkTR/zSdJy1nkYkhwF3AQ8PGvp/cAGYBJYBzwAbE2ystsJJWl56+MVwxXAt4Gb929Isg64ENhcVXuq6rvD/U4CXtXDjJK0bHUahiQvA94E/OqspdOB3VV19/4NVfUk8Cng7O4mlCR1dpomybOAjwKXVtXDSUaX1wAzYw6bAU59iufbBGwCmJiYYHp6el7zXXTaMfM6XkvPfH+mpCNVl+fvfwfYXlU3jVnbC+wbs72AjNlOVW0BtgBMTk7W1NTUvIa7bPON8zpeS8/2887tewSpF52EIclrgZ8BXvwUu+wAVo/ZvhrYuVBzSZIOdNDXGJJcOGbbs5K88iAOPwdYC3wjSSUp4G3A+cOv9wEnJHnJyHOvBM4Eth7sjJKk+ZvLxef/MGbb48B7n+7AqrqgqjL6GD7fR4bf/wFwA3B9kuOSrADeCewBbp3DjJKkeXraU0lJ/i3wLOBHklw1a/nZwOG6ansJcC1wH7AC+AKwsar2HqbnlyQdhIO5xvAt4EXDfZ87a+07wCFdoauqt8/6/gng0uFDktSTpw1DVX0I+FCSr1bV7FcMkqQl5qCvMRgFSVoeDvrXVZM8H7iOwWmlZ46uVdW6wzyXJKknc3kfw0eAXcC7gCcWZhxJUt/mEoYfB15RVbVQw0iS+jeX9zHMAMcu1CCSpMVhLmG4Evh4kpOTHDX6WKjhJEndm8uppBuB44CHxqytOCzTSJJ6N5cwvGbBppAkLRoHHYaq+sxCDiJJWhzm8j6GM59qraruPDzjSJL6NpdTSXeM2fYk8A3Gf5aCJOkINJdbYhw1+gCeB3wGOOBzGiRJR65D/lXTqnoIeB2Dz02QJC0R830Pwh48jSRJS8pcLj7/i1mbngGczeCDdSRJS8RcLj6/ddb3/w/4cwafvCZJWiLm8j6G2Z/eJklagubyigGAJGuB9cAjVfXIYZ9IktSrg774nOQZSX4feAT4LPCVJH+QZNWCTSdJ6txcfivpCuC5wEuBY4CfBiY48NqDJOkINpcwvA74xar6X1X1eFXdA7wa+OcLM5okqQ9zCcMPV9Wu0Q3D75/5FPtLko5AcwnDA0nOG92Q5PXA/z28I0mS+jSX30q6HPhskl8Cvgz8JHAWcPpCDCZJ6sdcbqK3HXg5g89+fjHwdeAfVtUXFmg2SVIP5nJLjJOBa4BXV9X3kqwE/izJ66rqLxZsQklSp+ZyjeG3gXuq6nsAVfVd4F3Aby3EYJKkfswlDC8Frh7dUFUfB049rBNJkno1lzB8Dzh6dEOS4w7vOJKkvs0lDJ8GPpbkxwCSnAh8BPjkQgwmSerHXMJwOYNbYPxVkl3AXwPPBt6yEINJkvoxl9tu7wE2JHkFsA54uKr+ZMEmkyT1Ys633a6q/7EQg0iSFof5fubzQUtyfJIPJnlk+Nie5NUj66uSXJvkwSQzSW5Jsqar+SRJA52FAbiFwW82/d2qWsfgmsVNSTYM198PbAAmGZyqegDYOnwjnSSpI13+o/sa4BvDN8ZRVX+c5EHgFUl2AhcCG4bXMkhyBXAB8Crg5g7nlKRlrbNXDFX19f1RSPLMJL8CvJDBp8GdDuyuqrtH9n8S+BRwdlczSpK6PZW0/zrCDuA7wBuB11TVnwFrGNycb7aZ4ZokqSOdnr+vqieAtUlOAC4Dzk9yJ7AX2DfuECDjnivJJmATwMTEBNPT0/Oa7aLTjpnX8Vp65vszJR2pUlX9/eXJ5xlclH4IeF9VPWfW+u8Dj1fVv/pBzzM5OVnbtm2b1ywv3XzjvI7X0rP9N9/Q9wjSgkqyvaomZ2/v5FRSkpVJzhmztBs4CbgTOCHJS0aPAc4EtnYxoyRpoKtrDCcBNyZ5c5IfAkjySuDngNuq6lHgBuD6JMclWQG8E9gD3NrRjJIkOgpDVX2Vwae/TQJ/mWSGwYf+/HJV/fFwt0uAe4H7gB0MfmNpY1Xt7WJGSdJAZxefq+oBBu9leKr1J4BLhw9JUk86/XVVSdLiZxgkSQ3DIElqGAZJUsMwSJIahkGS1DAMkqSGYZAkNQyDJKlhGCRJDcMgSWoYBklSwzBIkhqGQZLUMAySpIZhkCQ1DIMkqWEYJEkNwyBJahgGSVLDMEiSGoZBktQwDJKkhmGQJDUMgySpYRgkSQ3DIElqGAZJUsMwSJIahkGS1DAMkqSGYZAkNQyDJKlhGCRJDcMgSWp0FoYkb0jyxSQ7kzyQ5C1JVoysJ8nmJPcP97kryaldzSdJGugkDEleD/wGcEFVrQHOAt4AXD6y25XAhcAZwFrgD4E7khzfxYySpIGuXjFsAN5SVfcAVNXDwO8CrwVIcjSDSLy9qmZq4H3ALuCCjmaUJNFRGKrq4qq6YdbmFwPfGn49CRwL3D5rn9uAsxd4PEnSiJVd/4VJjgLeCvwycM5w8xrgm1X12KzdZ4Zr455nE7AJYGJigunp6XnNddFpx8zreC098/2Zko5UnYYhyUnAR4HnAWdV1eeGS3uBfWMOKSDjnquqtgBbACYnJ2tqampes122+cZ5Ha+lZ/t55/Y9gtSLLn8r6UXAduDLwE+NRAFgB3D88FrDqNXAzo5GlCTR3W8lrQU+Dfz7qvq1qvr2rF3uAR7lwOsJG4GtHYwoSRrq6hXDB4Dfq6qbxi1W1V7gPcDVSVYDJLkYWAd8uKMZJUl0d43hHOCnk5w/e6Gq1g6/vA5YAXw+ySrgfgbXIXZ3NKMkiY7CUFVjLyDP2mcfcM3wIUnqifdKkiQ1DIMkqWEYJEkNwyBJahgGSVLDMEiSGoZBktQwDJKkhmGQJDUMgySpYRgkSQ3DIElqGAZJUsMwSJIahkGS1DAMkqSGYZAkNQyDJKlhGCRJDcMgSWoYBklSwzBIkhqGQZLUMAySpIZhkCQ1DIMkqWEYJEkNwyBJahgGSVLDMEiSGoZBktQwDJKkhmGQJDUMgySpYRgkSY3OwpDkqCQvT/LuJLuTXDRrPUk2J7k/yc4kdyU5tav5JEkDXb5i2AS8F3gM2Ddm/UrgQuAMYC3wh8AdSY7vbEJJUndhqKoPVNXLq+qtDOLwt5IcDVwOvL2qZmrgfcAu4IKuZpQkLZ5rDJPAscDts7bfBpzd/TiStHyt7HuAoTXAN6vqsVnbZ4ZrB0iyicHpKSYmJpienp7XABeddsy8jtfSM9+fKelItVjCsJfx1x0KyLgDqmoLsAVgcnKypqam5jXAZZtvnNfxWnq2n3du3yNIvVgsp5J2AMcPrzWMWg3s7GEeSVq2FksY7gEe5cDrCRuBrd2PI0nL16IIQ1XtBd4DXJ1kNUCSi4F1wId7HE2Slp3Fco0B4DpgBfD5JKuA+4Gzqmp3v2NJ0vLSSxiqav2YbfuAa4YPSVJPFsWpJEnS4mEYJEmNxXSNQdIYj1z9or5H0CK07qovLdhz+4pBktQwDJKkhmGQJDUMgySpYRgkSQ3DIElqGAZJUsMwSJIahkGS1DAMkqSGYZAkNQyDJKlhGCRJDcMgSWoYBklSwzBIkhqGQZLUMAySpIZhkCQ1DIMkqWEYJEkNwyBJahgGSVLDMEiSGoZBktQwDJKkhmGQJDUMgySpYRgkSQ3DIElqGAZJUmPRhSHJBUn+d5IdSb6Q5BV9zyRJy8miCkOS84BrgddW1drh17cn+fF+J5Ok5WNRhQF4G/Duqvo/AFX1CeAzwCW9TiVJy8iiCUOSk4HnA5+ctXQbcHb3E0nS8rRowgCsGf45M2v7zMiaJGmBrex7gBF7h3/um7W9gMzeOckmYNPw228nuX8BZ1tuTgR29T1E3/Ku8/seQQfyZ3O/tx3wz+KhOGXcxsUUhh3DP1cD3xrZvhrYOXvnqtoCbOlgrmUnybaqmux7Dmk2fza7sWhOJVXVXwN/Drxy1tJGYGv3E0nS8rRowjB0HfDvkrwAIMk/Bf4J8Nu9TiVJy8hiOpVEVX08yY8An0xyDINTSD9fVX/R82jLjafotFj5s9mBVFXfM0iSFpHFdipJktQzw6C/5X2qtBglOSrJy5O8O8nuJBf1PdNSZxgEeJ8qLWqbgPcCj3Hg+5y0ALzGIACSPAB8sKp+Y2TbrcBXqurX+5tM+r4kDwHXVNWH+p5lKfMVg7xPlaSGYRB4nypJIwyDYI73qZK0tBkGQXufqlFj71MlaWkzDPI+VZIahkH7eZ8qScAiu1eS+uN9qiTt5/sYJEkNTyVJkhqGQZLUMAySpIZhkCQ1DIMkqWEYJEkNwyBJahgGSVLDMEiSGoZBOkRJnpPkE0lmknw1yTuG29cnqSQ/k+RPk/xVki8mednIsT+b5EtJvpbk3iQ/399/idQyDNKh+0/A14F1wD8C/nWSc0bW/yPwmqp6DvA54AMjazcBb6qqk4CLgWd1M7L09LxXkjQPSVZW1XeHX98MbAM+CnwFOKOqpodrGxl8VOqqqqok24B7gauqavYn50m98hWDdIiS/BxwS5IHkzwM/CzwjJFddox8/cRwbcXw+43AN4EvJPn0/tudS4uBYZAOQZK1wH8fPl5cVacAtx/s8VW1u6ouA04B7gZuXpBBpUNgGKRDczSD//v/06r6TpJ/DJwF/PDTHZjk2CS/leT5w9NQnwOOW9hxpYPnB/VIh6CqHkhyKXBrEoC7gDcD/+wgDv828Ajw6SRHA7uA8xdqVmmuvPgsSWp4KkmS1DAMkqSGYZAkNQyDJKlhGCRJDcMgSWoYBklSwzBIkhqGQZLU+P8wC82ZVjkoYgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}